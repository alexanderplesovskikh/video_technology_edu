# Сети и потоки

# Сжатие

В этом курсе тема про сжатие -- одна из многих. На самом деле это мог бы быть отдельный курс, про это написаны книги, это богатая тема для изучения и исследований.

Поскольку курс видеотехнологий по сути является продолжением курса компьютерной графики, где уже работали со сжатием и изображений, и видео, здесь мы долго задерживаться не будем, лишь освежим в памяти то, что пригодится непосредственно в работе.

Если вы не изучали предыдущий курс компьютерной графики, пожалуйста, пройдите его, хотя бы третий модуль, посвященный сжатию графики и видео.

# Повторение основ

* В природе все сигналы -- аналоговые, то есть, непрерывные во времени и по уровню. Цифровыми их ещё предстоит сделать, а работать нам предстоит с оцифрованным сигналом.
* Непрерывный сигнал - значит бесконечно подробный. Хранить бесконечно много информации мы не можем, поэтому ещё на этапе оцифровки аналогового сигнала нужно определиться с тем, насколько подробно мы готовы описывать его в цифровом виде.

Для наглядности возьмём три источника: изображение, кино и звук.

* Изображением в аналоговом мире будем считать плоский прямоугольный объект, например, фотографию.
* Кино -- это последовательность изображений на пленке. Я намеренно не привожу в пример видео, потому что там возникает много вариантов, а в кино каждый кадр -- статическое изображение, проецируемое лучом света через плёнку на экран.
* Звук -- изменяющаяся во времени  по амплитуде и частоте механическая волна. Частоты -- в диапазоне звуковых волн (16 - 20 000 Гц).

  ![Рисунок 1. Дискретизация изображения и звука.](.attachments.55430/image.png)

В чем выражается подробность каждого из этих источников?

* Для изображения: пространственное разрешение и глубина цвета.  То есть, цветовое и яркостное разрешение. Еще на аппаратном уровне можно добавить соответственно динамический диапазон и охват -- в нашем случае это длины шкал яркости и цветового пространства.
* Для кино актуально всё сказанное про изображение, к этому добавляется шкала времени, а во времени подробность описывается частотой кадров.  
  Помните из истории: сначала снимали 18 кадров в секунду и вроде бы хватало, но стали записывать звук на кинопленку и оказалось, что надо увеличить частоту кадров? Это уже про информационную ёмкость носителя.
* Для звука актуальна шкала времени, как и в кино, а значит -- подробность описания изменений амплитуды звуковой волны (частота дискретизации). Не менее важна подробность описания каждого отсчета -- количество уровней квантования. Динамический диапазон как размер шкалы, разумеется, тоже актуален, это также относится к аппаратной реализации системы, на этот раз -- звуковой.

По сути, при оцифровке мы выполняем два процесса, просто с разным количеством величин:

1. Дискретизация. Разделение непрерывной величины в пространстве и времени. Вместо одного непрерывного потока получается множество замеров.
2. Квантование. Разделение уровня дискретной величины в каждом замере. Момент времени или точку в пространстве выбрали на предыдущем шаге, теперь надо определиться, с какой точностью измеряем величину. Это может быть значение амплитуды звукового сигнала или яркость в определенной точке. Или напряжение, как в примере с вольтметром. Выделите 2 бита, будет 4 градации, например, яркости, выделите 8 -- будет 256. И так далее.

Сигнал, который прошел дискретизацию, но его значения остались не квантованными, называется дискретным.

Если вернуться к вольтметру: стрелочный показывает аналоговые значения, а цифровой – не только дискретные, но и квантованные, то есть, с заданным шагом, поэтому он и называется цифровым.

![Рисунок 2. Аналоговый, дискретный и цифровой сигналы.](.attachments.55430/image%20%282%29.png)

> Вопрос на понимание: есть кино, есть аналоговое телевидение. Как работает то и другое, мы уже разобрали. Какой из способов демонстрации движущегося изображения по сути аналоговый, а какой дискретный?

# Теорема Найквиста - Шеннона - Котельникова

Есть теорема, которая обосновывает значения частоты дискретизации -- теорема Котельникова. Там же фигурируют фамилии Найквеста и Шеннона. Во вкладе каждого из этих ученых мы здесь разбираться не будем, а суть теоремы, если упрощенно, такая:

::: info
Для сигнала, представленного последовательностью дискретных отсчетов, точное восстановление возможно, только если частота дискретизации более чем в 2 раза превышает максимальную частоту в спектре сигнала.

:::

Отсюда следует, что восстановить без искажений можно только сигнал, спектр которого ограничен по частоте. Эту частоту называют частотой Найквиста, Fmax.

Теоретически все реальные сигналы имеют бесконечные спектры. Например, в акустике есть понятия обертонов -- они имеют кратно более высокую частоту относительно основного тона. Конечно, это не бесконечно большая частота, но спектр естественного сигнала обычно весьма широкий. Для того чтобы при дискретизации избежать искажений из-за потери высокочастотной части спектра, сигнал перед оцифровкой пропускают через фильтр, подавляющий в нем частоты выше значения Fmax.

Из этой теоремы должно стать понятно, почему при спектре слышимого звука с верхней границей 20 кГц звук обычно записывают с дискретизацией 44 кГц, а то и 48, а в студиях даже 96.

44 кГц вдвое перекрывает слышимый звук, а 96 -- еще и ближайшие гармоники.

Можно в прямом смысле увидеть, как несоблюдение условий этой теоремы влияет на изображение и на движение.

Вы же видели в кино, когда едет машина или телега или паровоз, а колеса у него крутятся в сторону, обратную движению? Или пропеллер самолета или вертолета в воздухе то крутится еле-еле, то вообще останавливается? Как они не падают?

![Рисунок 3. Иллюзия обратного вращения колеса в кино.](.attachments.55430/image%20%283%29.png)

С колесами и пропеллерами на самом деле всё в порядке, они крутятся как надо. Но при съемке угловая скорость этих крутящихся предметов такая, что при повороте лопасти или спицы колеса на угол, где находится соседняя лопасть или спица, проходит слишком мало времени, чтобы киноаппарат или видеокамера зафиксировали промежуточные положения. Если лопасти вертолета в полете стоят на месте, значит скорость вращения винта такая, что угол поворота до положения любой другой лопасти винт проходит за один кадр. Если же скорость чуть ниже, то в записи будет иллюзия обратного хода винта, если чуть больше -- медленное движение вперед. То же самое с колесами телег, паровозов и автомобилей.

Другой пример -- обычные изображения. Возьмите штрих-код, сфотографируйте на телефон. Телефон же у вас современный? Значит вас есть фотография на много мегапикселей. Получается совершенно не содержательная картинка, давайте ее уменьшим.

До какого размера можно уменьшить штрих-код, чтобы он сохранил читаемость?

Чтобы не усложнять объяснение, просто возьмем две картинки размером 320х240 пикселей с полосами по 2 и по 3 пикселя шириной. Уменьшим ее до 256x192.

![Рисунок 4. Муар при недостаточном разрешении изображения.](.attachments.55430/image%20%284%29.png)

Считаем, сколько пикселей описывают одну полосу?

Если было два пикселя, то осталось 1,6. Если три, тогда осталось 2,4. В обоих случаях число дробное и в полутоновом изображении будет применяться антиалайзинг, но смотрите: на первой картинке полосы стали сливаться и образовывать какой-то новый рисунок. Это называется муар. Мы потеряли читаемость исходной картинки. А на правой полосы благополучно читаются.

Про это нас и предупреждает теорема Котельникова.

# Квантование и динамический диапазон

Эта тема нас отсылает ко второму модулю курса компьютерной графики -- освежите его в памяти, здесь мы не будем углубляться в подробности.

::: info
Квантование -- это разбиение непрерывного значения величины значений в отсчётах, полученных при дискретизации на дискретные величины этих отсчётов.

:::

При дискретизации мы выбрали, как часто во времени или пространстве будем измерять, а квантование -- это про то, сколько значений будет на шкале. Заметим, это ничего не говорит о длине шкалы, только о том, на сколько частей ее поделим.

Например, мы записываем звук. Насколько детально будет описана звуковая волна? Сколько вариантов значений мы готовы записать? Выделим 8 бит, будет 256 значений, выделим 16 бит -- будет 65535. Восьмибитный звук для музыки вам не понравится, а в телефоне мы его как-то терпим. Кодек, который используется в телефонной связи, как раз восьмибитный.

В изображениях квантование -- это количество градаций по компонентам цветовой модели. Если это шкала серого, то сколько будет оттенков серого между черным и белым.

При этом, черный и белый на телевизоре, экране проектора, бумаге -- они совсем разные по интенсивности. Мозг для нас их называет черным и белым, но их абсолютная яркость и разница яркости между крайними значениями будут существенно отличаться.

Длина шкалы между максимальным и минимальным значениями -- это динамический диапазон. Это логарифмическая шкала.

Тут важно, что вы можете выделить много памяти, но зафиксировать узкий диапазон. Будет очень подробно, но то, что вышло за пределы этого диапазона, будет потеряно. Например, в фотографии контрастных сцен может получиться черный провал в тени и белый блик вместо солнца и его окрестностей на небе.

Применительно к телевидению полезно знать, что там есть особенности, пришедшие к нам из истории. Зря мы что ли про нее вспоминали?

В совершенно цифровом мире цветоразностной модели YCbCr внезапно оказывается, что уровни яркости считаются не от 0 до 255, а от 16 до 235. Зачем так сделали? “Так принято” -- это пошло от электронно-лучевых трубок, там уровень 0 -- это “гасящий импульс”, то есть, чернее чёрного. Когда луч доходил до низа экрана, ему нужно было перейти вверх, его нужно было погасить совсем и переместить наверх. Количество градаций уровня яркости в телевидении меньше, чем в используемой им же цветовой модели.

Также вспомним, что в графике и видео обычно яркости уделяют больше внимания и памяти, чем цветности. В курсе компьютерной графики разбиралось понятие цветовой субдискретизации и рассказывалось про алгоритм JPEG.

# Психофизика сжатия

За счет чего возможно сжатие изображений и видео? Кто помнит курс компьютерной графики, сразу ответят -- мы устраняем избыточность. Какая бывает избыточность?

1. Приоритет в восприятии человеком яркости над цветностью. Цветовая субдискретизация -- как раз про это: “разрешение” цветовых каналов делают меньше, чем у канала яркости.
2. Схожесть областей изображения. Близкие по цвету и яркости области можно описать не попиксельно, а группой. Совсем одинаковые области сжимаются алгоритмами без потерь, а “похожие” -- алгоритмами с потерями.
3. Межкадровая схожесть -- это уже про видео. Записывается не полный кадр, а разница между кадрами. Опять же: в GIF-анимации, которая сжимает условно без потерь, сравнивается точное совпадение цвета, в кодеках с потерями сравнение более гибкое.

Сжатие звука также во многом опирается на особенности восприятия информации человеком.

* Тихие звуки практически не воспринимаются на слух. В интервалах молчания в записи можно задать длительность интервала "тишины" и ничего не передавать;
* Громкие звуки снижают чувствительность уха. Их кодируют с меньшей детализацией и по квантованию, и по дискретизации.
* После громкого звука чувствительность к тихим восстанавливается не сразу. Можно некоторое время экономить на детализации следующих звуков. Это называют "маскированием" звука во времени;
* Мощные частотные составляющие маскируют восприятие своих более слабых соседей по спектру. Эти эффекты локализованы внутри конкретных частотных полос, которые названы критическими (их всего 25). Кроме того от полосы частот зависит чувствительность слуха.

В курсе компьютерной графики мы изучали модель “стандартного наблюдателя” XYZ и соответствующий ей цветовой охват, относительно которого рассчитываются цветовые модели. Для описания акустических особенностей человеческого слуха существует психоакустическая модель, которая активно используется для эффективного сжатия звука.

---

# Материалы по теме

1. Теорема Найквиста-Шеннона-Котельникова. Digital Music Academy. \\nНа этом сайте много коротких статей по базовым темам курса, относящимся ко звуку, звукотехнике и MIDI.
2. Профили и уровни в H.264 В таблицах и цифрах -- что такое baseline, main, high и более редкие профили, а также что за численные обозначения уровней в настройках кодека H.264.

Кодек PCM (Pulse Code Modulation) — это метод цифрового представления аналогового сигнала путем дискретизации и квантования амплитуды сигнала. В отличие от других форматов, таких как MP3 или AAC, PCM является несжатым аудиоформатом, который сохраняет все данные исходного сигнала без потерь.

### Основные параметры:

- Частота дискретизации: Обычно варьируется от 8 кГц до 192 кГц. Стандартные частоты включают 44.1 кГц (CD-качество), 48 кГц (стандарт для видео) и 96 кГц/192 кГц (высококачественное аудио).
- Разрядность: От 8 бит до 32 бит. Наиболее распространенные значения — 16 бит (для CD-аудио) и 24 бита (для профессионального аудио). Чем больше разрядность, тем выше точность представления амплитуды звука.
- Каналы: Моно (один канал), стерео (два канала) и многоканальные конфигурации (например, 5.1 или 7.1).

### Области применения:

- Профессиональная звукозапись: Благодаря отсутствию потерь при сжатии, PCM часто используется в студийной работе, где важно сохранить максимальную верность оригиналу.
- Цифровое вещание: PCM применяется в системах передачи цифрового аудио, включая Blu-ray диски, DVD-Audio и цифровые радиосистемы DAB/DVB.
- Потоковая передача данных: В некоторых случаях, когда требуется максимальная точность воспроизведения, может использоваться потоковый формат PCM, особенно в локальных сетях или высокоскоростных соединениях.

### Сравнение с другими кодеками:

- MP3/AAC: Эти кодеки используют алгоритмы сжатия с потерями, удаляя части звукового спектра, которые считаются малозначительными для человеческого слуха. Они обеспечивают значительное уменьшение размера файла, но за счет качества звука.
- FLAC/WAVPACK: Кодеки без потерь, которые позволяют сжимать файлы PCM без потери информации. FLAC обеспечивает компрессию примерно на 50–60%, сохраняя оригинальную точность.

### Принцип работы:

PCM работает следующим образом:

1. Дискретизация: Аналоговый сигнал разбивается на отдельные временные отсчеты (samples) с определенной частотой (частотой дискретизации).
2. Квантование: Каждый отсчет преобразуется в цифровую форму путем присвоения ему ближайшего возможного уровня (кванта) из диапазона значений, определяемого разрядностью.
3. Кодирование: Полученные значения сохраняются в цифровой форме, представляя собой последовательность чисел.

### Пример кодирования через FFmpeg:

Для конвертации WAV-файла в PCM с помощью FFmpeg можно использовать следующую команду:

```bash
ffmpeg -i input.wav -acodec pcm_s16le output.pcm
```

Где:

- input.wav — входной файл,
- pcm_s16le — формат PCM с 16-битным разрешением и little-endian байтовым порядком,
- output.pcm — выходной файл.

### Пример использования GStreamer:

В GStreamer можно создать конвейер для записи PCM-потока с микрофона:

```bash
gst-launch-1.0 alsasrc ! audioconvert ! audio/x-raw,format=S16LE,channels=2,rate=44100 ! filesink location=output.pcm
```

Здесь:

- alsasrc — источник звука (микрофон),
- audioconvert — преобразователь формата аудио,
- filesink — запись в файл.

Таким образом, PCM является простым и эффективным способом хранения и передачи высококачественного аудио, хотя он требует значительно большего объема памяти по сравнению с кодеками с потерями.

Алгоритм кодирования звука в PCM (Pulse Code Modulation) включает три этапа обработки аналогового сигнала для преобразования его в цифровую форму.

### Шаг 1: Дискретизация

На этом этапе непрерывный аналоговый сигнал разбивается на отдельные временные отсчеты (сэмплы). Частота дискретизации определяет количество этих отсчетов в секунду. Например, стандартная частота дискретизации для компакт-дисков составляет 44.1 кГц, то есть выполняется 44,100 измерений амплитуды сигнала каждую секунду.

Формула для расчета количества отсчетов N за период времени T:

![Формула 1.](.attachments.57229/image.png)

где F — частота дискретизации.

### Шаг 2: Квантование

Каждый полученный отсчет амплитуды сигнала необходимо представить в виде конечного числа уровней. Этот процесс называется квантованием. Количество возможных уровней определяется разрядностью (количеством бит) каждого отсчета. Например, при использовании 16-битного квантования возможно представление 2^16 различных уровней амплитуды.

Ошибка квантования возникает из-за того, что реальная амплитуда сигнала округляется до ближайшего доступного уровня. Эта ошибка приводит к шуму квантования, который становится менее заметен при увеличении разрядности.

### Шаг 3: Кодирование

После квантования каждый уровень амплитуды представляется двоичным числом, соответствующим выбранному уровню. Например, в случае 16-битного квантования каждому уровню соответствует 16-битное число.

### Формат данных

Каждому отсчету присваивается определенное количество бит, которое зависит от разрядности. Для 16-битного PCM каждый отсчет занимает 2 байта, а для 24-битного — 3 байта.

### Байтовый порядок

Важно учитывать порядок следования байтов в файле. Существует два основных порядка:

- Big-endian: Старший байт идет первым.
- Little-endian: Младший байт идет первым.

### Пример

Рассмотрим простой пример для 4-битного PCM с частотой дискретизации 10 Гц. Пусть у нас есть следующий аналоговый сигнал:

![Формула 2.](.attachments.57229/image%20%282%29.png)

За период T = 1 секунда выполним 10 измерений (дискретизацию):

![](.attachments.57229/image%20%283%29.png)

Вычислим значения функции в эти моменты времени:

![](.attachments.57229/image%20%284%29.png)

Теперь выполним квантование с использованием 4-битного представления (2^4 = 16 уровней). Допустим, уровни равномерно распределены между -1 и +1. Тогда шаг квантования будет равен 2/15.

Получаем следующие квантованные значения:

![](.attachments.57229/image%20%285%29.png)

Эти значения затем кодируются в двоичную форму:

![](.attachments.57229/image%20%286%29.png)

Это и есть итоговый PCM-кодированный сигнал.

### Кодеки G.711 и G.722

Эти кодеки называют "телефонными" -- они используются в телефонной связи и не претендуют на качество звука для передачи музыки. Их основная задача -- разборчивая передача речи.

#### Общие сведения:

G.711 – стандарт ITU-T, представляющий собой алгоритм кодирования речевого сигнала, разработанный в 1972 году. Он обеспечивает преобразование аналогового аудиосигнала в цифровой формат с частотой дискретизации 8 кГц и разрядностью 16 бит. Стандарт поддерживает два метода компандирования: A-law (европейский стандарт) и μ-law (американский стандарт). Эти методы позволяют уменьшить динамический диапазон сигнала без значительного ухудшения качества звука.

G.722 – также стандарт ITU-T, но он был принят позже, в 1988 году. Этот кодек работает с широкополосным аудио (7 кГц), обеспечивая более высокое качество звука за счет увеличенной частоты дискретизации до 16 кГц при той же разрядности 16 бит. В отличие от G.711, который использует импульсно-кодовую модуляцию (PCM), G.722 основан на адаптивной дифференциальной импульсно-кодовой модуляции (ADPCM).

#### Основные параметры:

##### G.711:

- Частота дискретизации: 8 кГц
- Разрядность: 16 бит
- Битрейт: 64 Кбит/с (для каждого канала)
- Алгоритмы компрессии: A-law и μ-law
- Поддержка монофонического аудио

##### G.722:

- Частота дискретизации: 16 кГц
- Разрядность: 14 бит
- Битрейт: 48–64 Кбит/с (в зависимости от настроек)
- Алгоритм компрессии: ADPCM
- Поддержка стереофонического аудио

#### Лицензионная информация:

Оба стандарта (G.711 и G.722) являются открытыми спецификациями, доступными для использования без лицензионных отчислений. Однако некоторые реализации этих стандартов могут включать проприетарные компоненты, требующие лицензий.

#### Применение:

G.711: Широко используется в телефонных сетях, системах VoIP, а также в мультимедийных приложениях, где требуется высокая надежность передачи голоса с минимальной задержкой. Из-за низкой сложности алгоритма и малого объема вычислений этот кодек подходит для устройств с ограниченными ресурсами.

G.722: Применяется там, где необходимо обеспечить более высокое качество звука, например, в конференц-связи, IP-телефонии высокого класса, радиовещании и мультимедиа, требующих широкополосного аудио.

#### Сравнение с другими кодеками:

- G.729: Более современный кодек, обеспечивающий высокую степень сжатия (до 8 Кбит/с), однако требует значительно больше вычислительной мощности. Подходит для приложений с ограниченным каналом связи.
- Opus: Современный открытый кодек, поддерживающий широкий спектр частот и битрейтов. Он превосходит G.711 и G.722 по качеству звука при аналогичных битрейтах, особенно в условиях потерь пакетов.

#### Совместимость с ПО:

Оба кодека широко поддерживаются различными программными платформами и библиотеками, такими как:

- FFmpeg
- GStreamer
- WebRTC
- Libav
- Asterisk

Это позволяет легко интегрировать их в существующие системы и приложения.

#### Принцип работы:

##### G.711:

Использует метод компандирования (логарифмическое сжатие амплитуды сигнала):

- A-law: Используется в Европе и странах СНГ. Коэффициент компрессии составляет примерно 87,6 дБ.
- μ-law: Применяется в Северной Америке и Японии. Коэффициент компрессии около 85,3 дБ.

Принцип заключается в том, что сигнал разбивается на сегменты, каждый из которых сжимается логарифмически. Это уменьшает динамический диапазон сигнала, делая его менее чувствительным к шумам.

##### G.722:

Основан на ADPCM, который включает следующие этапы:

1. Преобразование входного сигнала в разностную форму.
2. Квантование разностей с использованием предсказателя и квантизатора.
3. Передача квантов на приемную сторону.
4. Декодирование и восстановление исходного сигнала.

Этот подход позволяет достичь высокой степени сжатия при сохранении хорошего качества звука.

#### Примеры использования:

##### FFmpeg:

```bash
ffmpeg -i input.wav -acodec g722 output.g722
```

##### GStreamer:

```python
pipeline = Gst.Pipeline()
source = Gst.ElementFactory.make("filesrc", "source")
decoder = Gst.ElementFactory.make("decodebin", "decoder")
encoder = Gst.ElementFactory.make("audioconvert", "converter")
sink = Gst.ElementFactory.make("filesink", "sink")

# Настройка параметров
source.set_property("location", "input.wav")
sink.set_property("location", "output.g722")

# Сборка пайплайна
pipeline.add(source, decoder, encoder, sink)
Gst.element_link_many(source, decoder, encoder, sink)

# Запуск пайплайна
pipeline.set_state(Gst.State.PLAYING)
```

Таким образом, кодеки G.711 и G.722 представляют собой эффективные инструменты для обработки и передачи аудиосигналов в различных сетевых и мультимедийных приложениях.

Алгоритм кодирования G.711 представляет собой процесс преобразования аналогового аудиосигнала в цифровую форму с использованием методов компандирования (логарифмической компрессии амплитуды сигнала). Давайте рассмотрим этот процесс шаг за шагом.

### Шаг 1: Дискретизация

Сначала аналоговый аудиосигнал подвергается процессу дискретизации с частотой 8000 Гц (то есть каждые 125 мкс). Это означает, что сигнал будет представлен последовательностью отсчетов, взятых через равные промежутки времени.

### Шаг 2: Квантование

Каждый отсчет сигнала затем квантуется, то есть преобразуется в целое число, соответствующее уровню сигнала. В случае G.711 используются 256 уровней (8 бит), что соответствует диапазону значений от -127 до +128.

### Шаг 3: Компандирование

На этом этапе применяется логарифмическая компрессия амплитуды сигнала. Существует две версии компандирования: A-law и μ-law.

#### A-law (Европейская версия)

Формула для A-law компандирования выглядит следующим образом:

![Формула 1.](.attachments.57142/image.png)

где x — нормализованный уровень сигнала, y — сжатый уровень сигнала, A — коэффициент компрессии (обычно равен 87,6).

#### μ-law (Американская версия)

Формула для μ-law компандирования имеет вид:

![Формула 2.](.attachments.57142/image%20%282%29.png)

где x — нормализованный уровень сигнала, y — сжатый уровень сигнала.

### Шаг 4: Кодирование

После компандирования полученные значения квантуются и кодируются в двоичный формат. Для этого используется 8-битное представление, где старший бит является знаком числа, а остальные биты — абсолютной величиной.

### Пример кодирования

Рассмотрим пример кодирования одного отсчета сигнала с помощью μ-law:

Пусть у нас есть отсчет x = 0,75  Тогда:

![Формула 3.](.attachments.57142/image%20%283%29.png)

Теперь нужно перевести значение y обратно в 8-битное представление. Предположим, что мы используем линейное квантование:

![Формула 4.](.attachments.57142/image%20%284%29.png)

Таким образом, отсчет x = 0,75 будет закодирован как 8-битное число 119.

### Заключение

Кодек G.711 является простым и эффективным способом кодирования голосовых сигналов благодаря использованию логарифмической компрессии. Его низкая сложность и минимальные требования к вычислительным ресурсам делают его идеальным выбором для приложений реального времени, таких как телефония и VoIP.

MP3 (MPEG-1 Audio Layer III) – это формат аудиокодека, разработанный группой Moving Picture Experts Group (MPEG). Он стал популярным благодаря своей способности эффективно сжимать аудиофайлы без значительной потери качества звука. Рассмотрим ключевые аспекты MP3:

### Области применения

1. Цифровая музыка: Музыка, распространяемая через интернет-магазины, музыкальные сервисы потокового вещания (Spotify, Apple Music), а также файлы, хранящиеся локально на устройствах пользователей.
2. Радиовещание: Используется в цифровом радиовещании, особенно в системах DAB (Digital Audio Broadcasting).
3. Переносные устройства: Широко применяется в портативных плеерах, смартфонах и других мобильных устройствах.
4. Интернет-трансляции: Потоковая передача аудио через интернет-сервисы, такие как подкасты и онлайн-радио.

### Лицензия

Формат MP3 был защищен патентами до 2017 года. Основные патенты, касающиеся алгоритмов сжатия, принадлежали Fraunhofer IIS и Thomson Multimedia. В настоящее время срок действия этих патентов истек, поэтому использование формата MP3 стало свободным от лицензионных отчислений.

### Сравнение с другими кодеками

#### Эффективность сжатия

- MP3: При битрейте 128 кбит/с обеспечивает приемлемое качество звука для большинства слушателей. Однако при таком битрейте могут возникать артефакты, особенно на сложных музыкальных фрагментах.
- AAC (Advanced Audio Coding): Обычно считается более эффективным при одинаковом битрейте, обеспечивая лучшее качество звука за счет использования более современных технологий обработки сигнала.
- Opus: Современный кодек, который предлагает высокую эффективность сжатия даже при низких битрейтах (например, 48–64 кбит/с). Особенно эффективен для передачи речи и музыки через интернет.

#### Совместимость с ПО

- Поддерживается большинством медиа-плееров, включая VLC, Windows Media Player, iTunes, Winamp и другие.
- Интеграция в операционные системы: Поддерживается всеми основными ОС, такими как Windows, macOS, Linux, Android и iOS.
- Потоковые платформы: Используемый формат для многих стриминговых сервисов, таких как Spotify, YouTube Music, Tidal и др.

### Принцип сжатия

Алгоритм сжатия MP3 основан на психоакустической модели восприятия звука человеком. Этот метод использует особенности человеческого слуха, чтобы уменьшить объем данных, сохраняя при этом восприятие качества звука.

Основные этапы сжатия включают:

1. Преобразование времени в частоту: Входной сигнал преобразуется из временной области в частотную с помощью модифицированного дискретного косинусного преобразования (MDCT).
2. Психоакустический\*\* анализ\*\*: Анализируется спектр сигнала, чтобы определить, какие частоты наиболее важны для восприятия человеческим ухом. На основе этой информации вычисляются пороговые значения маскировки.
3. Квантование и энтропийное кодирование: Частоты, которые менее значимы для восприятия, квантуются с меньшей точностью, что позволяет сократить количество битов, необходимых для их представления. Затем используется энтропийное кодирование (например, Хаффмана) для дальнейшего уменьшения объема данных.
4. Упаковка в фреймы: Данные упаковываются в блоки (фреймы), каждый из которых содержит информацию о квантованных коэффициентах и заголовке, содержащем параметры кодирования.

### Кодирование через FFmpeg и GStreamer

#### Пример кодирования через FFmpeg

```bash
ffmpeg -i input.wav -b:a 192k output.mp3
```

Здесь input.wav — исходный файл, output.mp3 — выходной файл, а параметр -b:a 192k устанавливает битрейт на уровне 192 кбит/с.

#### Пример кодирования через GStreamer

```python
import gi
gi.require_version('Gst', '1.0')
from gi.repository import Gst

Gst.init(None)

pipeline = Gst.Pipeline.new("mp3-conversion")

# Создаем элементы
filesrc = Gst.ElementFactory.make("filesrc", None)
wavparse = Gst.ElementFactory.make("wavparse", None)
audioconvert = Gst.ElementFactory.make("audioconvert", None)
lame = Gst.ElementFactory.make("lamemp3enc", None)
filesink = Gst.ElementFactory.make("filesink", None)

# Устанавливаем свойства элементов
filesrc.set_property("location", "input.wav")
filesink.set_property("location", "output.mp3")

# Добавляем элементы в пайплайн
pipeline.add(filesrc)
pipeline.add(wavparse)
pipeline.add(audioconvert)
pipeline.add(lame)
pipeline.add(filesink)

# Связываем элементы между собой
filesrc.link(wavparse)
wavparse.link(audioconvert)
audioconvert.link(lame)
lame.link(filesink)

# Запускаем пайплайн
pipeline.set_state(Gst.State.PLAYING)

# Ожидаем завершения работы пайплайна
bus = pipeline.get_bus()
msg = bus.timed_pop_filtered(Gst.CLOCK_TIME_NONE, Gst.MessageType.ERROR | Gst.MessageType.EOS)

if msg:
    t = msg.type
    if t == Gst.MessageType.ERROR:
        err, debug = msg.parse_error()
        print(f"Ошибка: {err}")
    elif t == Gst.MessageType.EOS:
        print("Конвертация завершена.")
    else:
        print(f"Произошло неожиданное событие: {t}")

pipeline.set_state(Gst.State.NULL)
```

Этот скрипт создает GStreamer-пайплайн для конвертации WAV-файла (input.wav) в MP3-файл (output.mp3), используя элемент lamemp3enc.

Алгоритм кодирования MP3 включает несколько этапов, начиная с анализа входящего звукового сигнала и заканчивая упаковкой сжатых данных в формате MP3. Вот подробная информация об основных этапах процесса кодирования:

### 1. Преобразование времени в частоту

На первом этапе входящий звуковой сигнал преобразуется из временной области в частотную область. Для этого используется модифицированное дискретное косинусное преобразование (MDCT, Modified Discrete Cosine Transform). MDCT разбивает звук на короткие сегменты и применяет к каждому сегменту математическое преобразование, которое переводит временные данные в частотные компоненты.

### 2. Психоакустическая модель

После того как сигнал представлен в частотном спектре, вступает в силу психоакустическая модель. Эта модель основана на особенностях восприятия звука человеческим слухом. Она определяет, какие части спектра являются важными для восприятия, а какие можно убрать или существенно снизить точность их представления без заметной потери качества.

Психоакустика учитывает два ключевых эффекта:

- Маскирование частот: Когда одна частота сильно доминирует над другой, близлежащей частотой, то слабую частоту можно удалить или представить с меньшей точностью, так как она будет замаскирована сильной частотой.
- Маскирование времени: Если громкий звук следует сразу после тихого, то тихий звук может быть удалён или передан с меньшей точностью, поскольку он будет замаскирован громким звуком.

Эти эффекты позволяют значительно сократить объём передаваемых данных, убирая ненужные компоненты звука.

### 3. Квантование и энтропийное кодирование

После применения психоакустического анализа частоты, которые были определены как важные, подвергаются процессу квантования. Квантование — это процесс округления значений амплитуд сигналов до ближайших допустимых уровней. Чем меньше уровней квантования, тем больше экономия места, но и тем сильнее потеря качества.

Затем данные проходят этап энтропийного кодирования, обычно с использованием метода Хаффмана. Энтропийное кодирование позволяет ещё больше сократить размер файла, заменяя часто встречающиеся символы короткими кодовыми словами, а редко встречающиеся — длинными.

### 4. Упаковка в фреймы

После всех предыдущих шагов данные упаковываются в блоки, называемые фреймами. Каждый фрейм состоит из заголовка и полезной нагрузки. Заголовок содержит метаданные, такие как номер фрейма, битрейт, частота дискретизации и другая служебная информация. Полезная нагрузка содержит сами сжатые данные.

### Итоговый результат

В результате всех этих операций получается файл MP3, который занимает гораздо меньший объём памяти по сравнению с исходными данными, но сохраняет достаточно высокое качество звучания для большинства приложений.

### Пример реализации

Для примера рассмотрим реализацию простого MP3-кодера на Python с использованием библиотеки pydub, которая предоставляет интерфейс к FFmpeg:

```python
from pydub import AudioSegment

# Открываем аудиофайл
sound = AudioSegment.from_file("input.wav", format="wav")

# Конвертируем в MP3 с битрейтом 320 kbps
sound.export("output.mp3", format="mp3", bitrate="320k")
```

Это простой пример, демонстрирующий базовую функциональность кодирования MP3. Более сложные сценарии могут включать дополнительные настройки, такие как выбор частоты дискретизации, настройка параметров квантования и применение различных фильтров.

### Кодек AAC (Advanced Audio Coding)

Области применения:  
AAC используется для потоковой передачи аудио в интернете, вещании цифрового радио, а также в мобильных устройствах и цифровых плеерах. Он широко применяется в стриминговых платформах и технике (например, в камерах и кодерах) благодаря своей высокой степени сжатия при сохранении качества звука.

Лицензия:  
AAC является патентованным стандартом, который был разработан MPEG (Moving Picture Experts Group). Для коммерческого использования могут потребоваться лицензионные отчисления за использование патентов, связанных с AAC. Однако для некоммерческого использования или разработки программного обеспечения под лицензией GPLv2 или выше обычно не требуется платить роялти.

Технические характеристики:

- Частота дискретизации: от 8 кГц до 96 кГц.
- Битрейт: от 16 кбит/с до 576 кбит/с.
- Каналы: моно, стерео, 5.1, 7.1.
- Форматы: MP4, ADTS, ADIF, 3GP, MKV.
- Алгоритмы сжатия: MDCT (Modified Discrete Cosine Transform), PNS (Perceptual Noise Substitution), TNS (Temporal Noise Shaping).

Эффективность сжатия:  
По сравнению с другими популярными аудиокодеками, такими как MP3:

- AAC обеспечивает лучшее качество звука при одинаковом битрейте.
- При одинаковом качестве звука AAC требует меньшего битрейта, чем MP3.
- Например, при битрейте 128 кбит/с AAC звучит лучше, чем MP3 того же битрейта.

Совместимость с ПО:  
AAC поддерживается большинством современных медиа-плееров и платформ, включая:

- Windows Media Player, VLC, QuickTime, iTunes.
- Браузеры: Chrome, Firefox, Safari, Edge.

#### Принцип сжатия

Кодек AAC использует несколько методов для достижения высокого уровня сжатия без значительной потери качества:

1. MDCT (Modified Discrete Cosine Transform):  
   Этот метод преобразует временные сигналы в частотную область, позволяя эффективно сжимать данные. В отличие от традиционного DCT, MDCT позволяет избежать артефактов на границах блоков данных.
2. PNS (Perceptual Noise Substitution):  
   PNS заменяет высокочастотные компоненты сигнала шумоподобными сигналами, которые менее заметны человеческому уху. Это позволяет уменьшить количество передаваемых данных без значительного ухудшения восприятия.
3. TNS (Temporal Noise Shaping):  
   TNS уменьшает искажения, вызванные квантованием, путем временного распределения шума квантования таким образом, чтобы он был менее заметен слушателю.
4. Психоакустическая модель:  
   AAC использует психоакустические модели для определения тех частей звукового спектра, которые наименее важны для человеческого слуха. Эти части затем удаляются или сильно сжаты, что приводит к уменьшению размера файла без заметной потери качества.

#### Примеры кодирования

##### Через FFmpeg:

```bash
ffmpeg -i input.mp3 -c:a aac -b:a 192k output.m4a
```

Этот пример конвертирует файл input.mp3 в формат AAC с битрейтом 192 кбит/с и сохраняет результат в файл output.m4a.

##### Через GStreamer:

```bash
gst-launch-1.0 filesrc location=input.mp3 ! decodebin ! audioconvert ! faac ! mp4mux ! filesink location=output.m4a
```

Здесь файл input.mp3 декодируется, конвертируется в формат AAC с помощью кодека FAAC и сохраняется в контейнере MP4 (output.m4a).

#### Отличительные особенности относительно MP3

1. Более гибкая частота дискретизации:  
   AAC поддерживает более широкий диапазон частот дискретизации (от 8 кГц до 96 кГц), тогда как MP3 ограничен диапазоном от 32 кГц до 48 кГц. Это дает возможность сохранять больше деталей исходного сигнала.
2. Лучшее качество при низком битрейте:  
   Благодаря использованию более сложных алгоритмов сжатия, AAC обеспечивает значительно лучшее качество звука при низких битрейтах по сравнению с MP3. Например, при битрейте 64–96 кбит/с AAC заметно превосходит MP3 по качеству.
3. Поддержка большего количества каналов:  
   AAC поддерживает многоканальные конфигурации, такие как 5.1 и 7.1, что делает его предпочтительным выбором для работы с пространственным звуком в кино и телевидении.
4. Улучшенная обработка высоких частот:  
   Применение PNS и TNS позволяет AAC более эффективно обрабатывать высокие частоты, обеспечивая более чистое звучание даже после сильной компрессии.

### Принципы сжатия AAC

AAC (Advanced Audio Coding) – это аудиокодек, разработанный для замены MP3 и улучшения качества звучания при том же уровне сжатия. Основные принципы сжатия AAC включают в себя несколько ключевых этапов обработки аудиосигнала, направленных на уменьшение избыточности информации и удаление несущественных для восприятия человеком компонентов звука.

### Алгоритм кодирования звука в AAC

Для понимания процесса кодирования звука в формате AAC важно учитывать следующие этапы обработки аудиосигнала:

1. Разделение на фреймы: Входящий аудиосигнал разбивается на небольшие фрагменты (фреймы), каждый из которых обрабатывается отдельно. Обычно длина фрейма составляет 1024 или 2048 выборок.
2. Модифицированное косинусное преобразование (MDCT): Каждый фрейм подвергается MDCT, которое преобразует временные данные в частотные коэффициенты. Формула MDCT выглядит следующим образом:

![Формула 1.](.attachments.57284/image.png)

где X(k) — коэффициент частотного спектра, x(n) — значение выборки во временной области, N — размер окна (обычно 1024 или 2048).

1. Анализ психоакустики: На этом этапе применяются психоакустические модели для анализа частотных составляющих сигнала. Целью является определение тех частот, которые являются малозаметными для человеческого слуха. Такие частоты могут быть удалены или ослаблены без существенного влияния на восприятие.
2. Перцептивная замена шума (PNS): Высокие частоты, которые трудно передать точно, заменяются шумоподобными сигналами. Это позволяет сэкономить битовый ресурс без заметного ухудшения качества звука. Математически это выражается через замену части частотного спектра случайным белым шумом.
3. Квантование: Квантование — это процесс округления численных значений до ближайших допустимых уровней. В случае AAC применяется адаптивное квантование, когда шаг квантования выбирается индивидуально для каждой частотной полосы. Шаг квантования определяется на основании психоакустического анализа и требуемого битрейта.
4. Темпоральная формация шума (TNS): Чтобы минимизировать влияние ошибок квантования на восприятие, TNS перераспределяет эти ошибки по времени таким образом, чтобы они становились менее заметными. Это достигается путем фильтрации остаточного сигнала после квантования.
5. Энтропийное кодирование: Заключительный этап включает применение энтропийного кодирования, такого как Хаффмановское кодирование, для дальнейшей оптимизации объема данных. Энтропийное кодирование позволяет эффективно упаковывать информацию, используя переменную длину кода для различных символов.

### Псевдокод алгоритма

```python
def encode_aac(audio_signal):
    # Разбиваем сигнал на фреймы
    frames = split_into_frames(audio_signal)
    
    for frame in frames:
        # Применяем MDCT
        frequency_coefficients = mdct(frame)
        
        # Проводим психоакустический анализ
        perceptually_important_bands = psychoacoustic_analysis(frequency_coefficients)
        
        # Применяем PNS
        pns_applied_coefficients = apply_pns(perceptually_important_bands)
        
        # Квантуем коэффициенты
        quantized_coefficients = adaptive_quantization(pns_applied_coefficients)
        
        # Применяем TNS
        tns_processed_coefficients = temporal_noise_shaping(quantized_coefficients)
        
        # Применяем энтропийное кодирование
        encoded_data = entropy_coding(tns_processed_coefficients)
        
        # Сохраняем закодированные данные
        save_encoded_frame(encoded_data)
```

Этот псевдокод иллюстрирует основные шаги процесса кодирования звука в формате AAC. Реализация конкретных функций, таких как mdct, psychoacoustic_analysis, apply_pns, adaptive_quantization, temporal_noise_shaping и entropy_coding, зависит от конкретной библиотеки или реализации, которую вы используете.

Кодек Opus

Opus – это открытый аудиокодек, разработанный для передачи высококачественного звука через интернет и другие сетевые среды. Он был создан консорциумом IETF (Internet Engineering Task Force) и стандартизирован в RFC 6716. Основные особенности:

### Области применения

- VoIP: Опус широко используется в приложениях VoIP благодаря своей низкой задержке и высокой устойчивости к потерям пакетов.
- Стриминг аудио: Применяется в стриминговых сервисах, таких как YouTube, Twitch и Spotify, обеспечивая высокое качество звука при минимальных битрейтах.
- Игры: Используется в онлайн-играх для голосового чата между игроками.
- Видеоконференции: Включение в системы видеосвязи, такие как Zoom, Google Meet и Microsoft Teams.

### Лицензия

Опус лицензируется под BSD-like лицензией, которая позволяет использовать кодек без ограничений в коммерческих и некоммерческих проектах. Кодек является свободным от патентных отчислений.

### Эффективность

Опус поддерживает широкий диапазон битрейтов: от 6 до 510 кбит/с. При этом он обеспечивает высокую устойчивость к потере данных за счет встроенных механизмов восстановления сигнала. Кодек использует технологию CELP (Code Excited Linear Prediction), что позволяет достичь высокого качества звука даже при низких битрейтах.

#### Сравнение с другими кодеками

- MP3: Opus превосходит MP3 по качеству звука при одинаковых битрейтах, особенно на низких битрейтах (ниже 64 кбит/с).
- AAC: Opus также лучше AAC на низких битрейтах, но на высоких битрейтах разница менее заметна.
- Vorbis: Opus имеет меньшую задержку и лучшую устойчивость к потерям пакетов по сравнению с Vorbis.

Чаще всего этот кодек сравнивают с более распространенными MP3 и AAC. Выделим основные пользовательские отличия:

1. Задержка: Opus имеет значительно меньшую задержку. Это достигается за счет использования коротких окон преобразования и адаптивного выбора длины кадра.
2. Качество на низких битрейтах: На низких битрейтах (менее 48 кбит/с) Opus превосходит MP3 и AAC по качеству звучания. Это связано с использованием более эффективных методов квантования и кодирования.
3. Устойчивость к потерям: Opus обладает встроенными механизмами восстановления потерянных данных, что делает его более устойчивым к ошибкам передачи.
4. Поддержка переменного битрейта: Opus поддерживает переменный битрейт (VBR), что позволяет адаптироваться к изменяющимся условиям канала связи и сохранять высокое качество звука.

### Совместимость с ПО

Опус поддерживается большинством современных медиа-плееров и браузеров, включая Firefox, Chrome, Edge, VLC и MPlayer. Также он интегрирован в популярные фреймворки для работы с мультимедиа, такие как FFmpeg и GStreamer.

### Примеры использования

#### Кодирование через FFmpeg

```bash
ffmpeg -i input.wav -c:a libopus -b:a 96k output.opus
```

Этот пример показывает, как закодировать WAV-файл в формат Opus с битрейтом 96 кбит/с.

#### Кодирование через GStreamer

```python
import gi
gi.require_version('Gst', '1.0')
from gi.repository import Gst

Gst.init(None)

pipeline = Gst.Pipeline.new("audio-conversion")
src = Gst.ElementFactory.make("filesrc", None)
src.set_property("location", "input.wav")
decode = Gst.ElementFactory.make("wavparse", None)
encode = Gst.ElementFactory.make("opusenc", None)
sink = Gst.ElementFactory.make("filesink", None)
sink.set_property("location", "output.opus")

pipeline.add(src)
pipeline.add(decode)
pipeline.add(encode)
pipeline.add(sink)

src.link(decode)
decode.link(encode)
encode.link(sink)

pipeline.set_state(Gst.State.PLAYING)
bus = pipeline.get_bus()
msg = bus.timed_pop_filtered(Gst.CLOCK_TIME_NONE, Gst.MessageType.ERROR | Gst.MessageType.EOS)

if msg:
    t = msg.type
    if t == Gst.MessageType.ERROR:
        err, debug = msg.parse_error()
        print("Error: %s" % err, debug)
    elif t == Gst.MessageType.EOS:
        print("End of stream reached.")
    else:
        pass

pipeline.set_state(Gst.State.NULL)
```

Этот пример демонстрирует использование библиотеки GStreamer для декодирования WAV-файла и последующего кодирования его в формат Opus.

Алгоритм сжатия звука в кодеке Opus основан на гибридной схеме, сочетающей технологии LPC (Linear Predictive Coding) и MDCT (Modified Discrete Cosine Transform). Этот подход позволяет эффективно сжимать звуковые данные, сохраняя высокое качество при различных битрейтах и условиях передачи.

### Принцип сжатия звука алгоритмом Opus

1. Анализ входного сигнала: Входной сигнал анализируется на предмет наличия речевых компонентов и музыкальных элементов. Для речевого контента применяется технология LPC, а для музыки — MDCT.
2. LPC-анализ: Если сигнал содержит речь, то выполняется линейный предсказательный анализ. Этот метод моделирует вокальные тракты говорящего и позволяет точно предсказывать последующие выборки на основе предыдущих. После анализа формируется остаточный сигнал, который затем подвергается дальнейшему сжатию.
3. MDCT-анализ: Когда сигнал больше похож на музыку, используется модифицированное дискретное косинусное преобразование (MDCT). Оно разбивает сигнал на частотные компоненты, позволяя сжать их с учетом психоакустических особенностей восприятия человеком.
4. Квантование и энтропийное кодирование: Квантованные коэффициенты подвергаются энтропийному кодированию, чтобы уменьшить избыточность информации. Для этого используются методы, такие как арифметическое кодирование или Хаффман-кодирование.
5. Потеря пакетов и восстановление: Опус включает механизмы защиты от потерь пакетов, что делает его идеальным для передачи звука по ненадежным каналам связи. В случае потери пакета система может восстановить часть утраченной информации, используя предыдущие кадры.

### Алгоритм сжатия звука на техническом уровне

1. Разбиение на кадры: Входной звуковой поток делится на кадры длиной 10 мс (480 выборок при частоте дискретизации 48 кГц). Каждый кадр обрабатывается независимо.
2. Предсказание: Выполняется линейная предсказательная фильтрация (LPC) для каждого кадра. Коэффициенты фильтра вычисляются методом Левинсона-Дарбина.
3. Остаточное кодирование: Остаточные сигналы после предсказания квантуются и кодируются с помощью арифметического кодера.
4. Частотно-временное преобразование: Если сигнал больше напоминает музыкальный, то применяется модифицированное дискретное косинусное преобразование (MDCT). Полученные спектральные коэффициенты квантуются и кодируются.
5. Энтропийное кодирование: Квантованные коэффициенты сжимаются с использованием метода Хаффмана или арифметического кодирования.
6. Формирование выходного потока: Все сжатые данные объединяются в единый выходной поток, включающий заголовки кадров, информацию о конфигурации и сами данные.
7. Передача и декомпрессия: Передаваемый поток принимается на стороне получателя, где происходит обратная последовательность операций: декомпрессия, восстановление исходного сигнала и воспроизведение.

Vorbis – свободный аудиокодек, разработанный организацией Xiph.Org Foundation и являющийся частью проекта Ogg. Он предназначен для эффективного сжатия аудио без потерь качества при высоких битрейтах, но также поддерживает переменный битрейт (VBR). Кодек был выпущен под лицензией BSD, что делает его доступным для использования в коммерческих проектах без лицензионных отчислений.

### Основные характеристики:

- Частота дискретизации: от 8 кГц до 192 кГц.
- Битовая глубина: 16–32 бита.
- Каналы: моно, стерео, многоканальный звук (до 255 каналов).
- Алгоритм сжатия: психоакустический анализ, основанный на преобразовании Фурье и модифицированном дискретном косинусном преобразовании (MDCT), что позволяет эффективно сжимать аудиосигнал, сохраняя высокое качество звука.

### Области применения:

- Потоковое вещание (интернет-радио, стриминговые сервисы).
- Хранение музыки в цифровых библиотеках.
- Игры и мультимедийные приложения.
- Видеоконференции и VoIP-приложения благодаря низкому задержке декодера.

### Лицензия:

- Лицензия BSD предоставляет свободу использовать кодек в любых целях, включая коммерческие проекты, без необходимости выплачивать роялти.

### Сравнение с другими кодеками:

- MP3: Vorbis обеспечивает лучшее качество звука при одинаковом битрейте по сравнению с MP3, особенно на низких битрейтах (ниже 128 kbps). Также Vorbis поддерживает переменное количество каналов и частоту дискретизации, тогда как MP3 ограничен двумя каналами и частотой до 48 кГц.
- AAC: AAC имеет схожие показатели качества со Vorbis, однако Vorbis является полностью свободным и открытым стандартом, а AAC требует лицензирования.
- Opus: Opus считается преемником Vorbis и предлагает еще большую эффективность сжатия и меньшую задержку, особенно для голосовых приложений. Однако Vorbis остается популярным выбором для музыкальных приложений.

### Совместимость с ПО:

- Поддерживается большинством популярных медиа-плееров, таких как VLC, Winamp, foobar2000, Audacious.
- Интеграция с фреймворками для работы с мультимедиа, такими как FFmpeg, GStreamer, Libav.
- Широко используется в играх и приложениях на базе OpenAL и SDL.

### Принцип сжатия:

1. Психоакустическая модель: Vorbis использует психоакустические модели для анализа аудиосигнала и удаления тех частей спектра, которые человеческое ухо не способно различить.
2. Преобразование Фурье: Аудиопоток разбивается на короткие временные окна, после чего применяется быстрое преобразование Фурье (FFT) для перехода из временной области в частотную.
3. Модифицированное дискретное косинусное преобразование (MDCT): Используется для уменьшения количества данных за счет преобразования сигнала в коэффициенты, которые затем квантуются и кодируются.
4. Квантование и энтропийное кодирование: Коэффициенты MDCT квантуются и подвергаются энтропийному кодированию (например, Хаффмана), чтобы уменьшить избыточность информации.
5. Формат контейнера Ogg: Для хранения сжатых данных обычно используется контейнерный формат Ogg, который позволяет передавать метаданные вместе с аудиофайлом.

### Пример кодирования через FFmpeg:

```bash
ffmpeg -i input.wav -c:a libvorbis -qscale:a 6 output.ogg
```

Параметр -qscale:a управляет качеством выходного файла (чем меньше значение, тем выше качество):

- 10 — минимальное качество,
- 0 — максимальное качество.

### Пример кодирования через GStreamer:

```python
import gi
gi.require_version('Gst', '1.0')
from gi.repository import Gst

Gst.init(None)

pipeline = Gst.Pipeline.new("audio-conversion")
source = Gst.ElementFactory.make("filesrc", None)
decoder = Gst.ElementFactory.make("wavparse", None)
encoder = Gst.ElementFactory.make("vorbisenc", None)
muxer = Gst.ElementFactory.make("oggmux", None)
sink = Gst.ElementFactory.make("filesink", None)

source.set_property("location", "input.wav")
sink.set_property("location", "output.ogg")

pipeline.add(source, decoder, encoder, muxer, sink)
Gst.element_link_many(source, decoder, encoder, muxer, sink)

pipeline.set_state(Gst.State.PLAYING)
bus = pipeline.get_bus()
msg = bus.timed_pop_filtered(Gst.CLOCK_TIME_NONE, Gst.MessageType.ERROR | Gst.MessageType.EOS)

if msg:
    t = msg.type
    if t == Gst.MessageType.ERROR:
        err, debug = msg.parse_error()
        print(f"Error: {err}", debug)
    elif t == Gst.MessageType.EOS:
        print("End of stream reached.")
    else:
        pass

pipeline.set_state(Gst.State.NULL)
```

Этот скрипт конвертирует WAV-файл в OGG/Vorbis с использованием библиотеки GStreamer.

### Шаг 1: Преобразование времени в спектр

1. Разбиение на блоки: Входной сигнал делится на блоки фиксированной длины (обычно 256, 512, 1024 или 2048 отсчетов).
2. Окно Хэннинга: К каждому блоку применяется окно Хэннинга для сглаживания краев блока и предотвращения эффекта Гиббса.
3. БПФ (Быстрое преобразование Фурье): Применяется БПФ для перевода временного представления сигнала в спектральное представление.

### Шаг 2: Психоакустическое моделирование

1. Анализ критических полос слуха: Спектр разбивается на критические полосы слуха, каждая из которых соответствует определенной частоте восприятия человеческого уха.
2. Вычисление маскирующих порогов: Определяется уровень шума, который может быть замаскирован полезным сигналом в каждой полосе.

### Шаг 3: Квантование и кодирование

1. Квантование: Значения амплитуд спектральных компонент квантуются с учетом их важности для восприятия человеком.
2. Кодирование Хаффмана: Квантованные значения кодируются с помощью кода Хаффмана для минимизации объема данных.

### Шаг 4: Упаковка и запись

1. Упаковка: Все данные упаковываются в пакеты формата Ogg.
2. Запись: Пакеты записываются в выходной файл.

Теперь рассмотрим каждый шаг подробнее.

#### Шаг 1: Преобразование времени в спектр

1. Разбиение на блоки

   ```python
   def split_into_blocks(signal, block_size=1024):
       blocks = []
       for i in range(0, len(signal), block_size):
           block = signal[i:i+block_size]
           blocks.append(block)
       return blocks
   ```
2. Применение окна Хэннинга

   ```python
   def apply_hann_window(block):
       window = np.hanning(len(block))
       return block * window
   ```
3. Быстрое преобразование Фурье

   ```python
   def fft(block):
       return np.fft.rfft(block)
   ```

#### Шаг 2: Психоакустическое моделирование

1. Анализ критических полос слуха

   ```python
   def critical_bands(fft_values, sample_rate):
       # Разделение спектра на критические полосы
       bands = []
       return bands
   ```
2. Вычисление маскирующих порогов

   ```python
   def calculate_masking_thresholds(bands):
       thresholds = []
       return thresholds
   ```

#### Шаг 3: Квантование и кодирование

1. Квантование

   ```python
   def quantize(spectrum, thresholds):
       quantized_spectrum = []
       return quantized_spectrum
   ```
2. Кодирование Хаффмана

   ```python
   def huffman_coding(quantized_spectrum):
       encoded_data = []
       return encoded_data
   ```

#### Шаг 4: Упаковка и запись

1. Упаковка

   ```python
   def pack_into_ogg(encoded_data):
       ogg_packets = []
       return ogg_packets
   ```
2. Запись

   ```python
   def write_to_file(ogg_packets, filename):
       with open(filename, 'wb') as file:
           for packet in ogg_packets:
               file.write(packet)
   ```

### Полная реализация

```python
def encode_vorbis(signal, sample_rate, block_size=1024):
    blocks = split_into_blocks(signal, block_size)
    
    processed_blocks = []
    for block in blocks:
        windowed_block = apply_hann_window(block)
        spectrum = fft(windowed_block)
        
        bands = critical_bands(spectrum, sample_rate)
        thresholds = calculate_masking_thresholds(bands)
        
        quantized_spectrum = quantize(spectrum, thresholds)
        encoded_data = huffman_coding(quantized_spectrum)
        
        processed_blocks.append(encoded_data)
    
    ogg_packets = pack_into_ogg(processed_blocks)
    write_to_file(ogg_packets, 'output.ogg')
```

Этот алгоритм представляет собой упрощенную версию процесса кодирования звука в формате Vorbis. Реальные реализации могут включать дополнительные оптимизации и улучшения, такие как адаптивное квантование и использование переменного битрейта.

FLAC (Free Lossless Audio Codec) – это аудиокодек, предназначенный для сжатия цифровых аудиофайлов без потерь качества. Он широко используется в профессиональных аудиоинженерных приложениях, архивировании музыки высокого разрешения и системах потоковой передачи данных.

### Основные характеристики:

- Тип сжатия: Без потерь (lossless).
- Формат контейнера: .flac.
- Лицензия: Бесплатная лицензия BSD, что позволяет использовать кодек в коммерческих продуктах без ограничений.
- Поддержка битрейтов: Поддерживает до 24 бит/32 бита при частоте дискретизации от 1 Гц до 655350 Гц.
- Эффективность сжатия: В среднем сжатие составляет около 50–70% от исходного размера файла без потери качества звука.

### Области применения:

- Архивирование музыкальных коллекций в высоком качестве.
- Профессиональная работа со звуком (звукозапись, мастеринг).
- Потоковая передача аудиоданных высокого качества.
- Аудиосистемы Hi-Fi и Hi-End.

### Сравнение с другими кодеками:

- MP3\*\* (с потерями)\*\*: MP3 обеспечивает значительно меньший размер файлов за счет ухудшения качества звука. FLAC же сохраняет качество полностью, но файлы получаются больше.
- ALAC (Apple Lossless): Также является lossless-кодеком, однако менее популярен и имеет чуть худшую поддержку на разных платформах.
- WAV\*\* (несжатый формат)\*\*: WAV хранит звук без сжатия (PCM), поэтому файлы занимают гораздо больше места, чем FLAC.

### Совместимость с ПО:

- VLC Media Player, Winamp, foobar2000 – поддерживают воспроизведение FLAC-файлов.
- Audacity, Adobe Audition – позволяют редактировать и экспортировать аудиофайлы в формате FLAC.
- ffmpeg, gstreamer – инструменты командной строки для работы с FLAC.

### Принцип сжатия:

FLAC использует комбинацию методов сжатия без потерь:

1. Разностное кодирование: Разница между соседними отсчетами вычисляется и сохраняется вместо самих значений.
2. Прогнозирующее кодирование: Используется линейный предсказатель для определения следующего значения на основе предыдущих.
3. Энтропийное кодирование: Применяется метод Гафмана для уменьшения избыточности информации.
4. Разделение на блоки: Данные разбиваются на блоки фиксированной длины, каждый блок сжимается независимо.

### Пример кодирования через ffmpeg:

```bash
ffmpeg -i input.wav -c:a flac output.flac
```

Этот пример показывает, как конвертировать несжатый файл .wav в сжатый файл .flac.

### Пример кодирования через gstreamer:

```bash
gst-launch-1.0 filesrc location=input.wav ! wavparse ! audioconvert ! flacenc ! filesink location=output.flac
```

Здесь происходит аналогичная операция с использованием инструмента gstreamer.

Алгоритм кодирования звука в формате FLAC состоит из нескольких этапов, включающих разностное кодирование, прогнозирующее кодирование и энтропийное кодирование. Вот пошаговый алгоритм процесса кодирования:

### Шаг 1: Разбиение на кадры

На первом этапе входной аудиопоток делится на кадры фиксированного размера. Каждый кадр содержит определенное количество выборок. Размер кадра обычно выбирается так, чтобы минимизировать накладные расходы на заголовки, но при этом обеспечить эффективное сжатие.

### Шаг 2: Разностное кодирование

Для каждого кадра выполняется разностное кодирование. Вместо хранения абсолютных значений каждой выборки, сохраняются разницы между текущим значением и предыдущими. Это уменьшает амплитуду значений, что упрощает дальнейшее сжатие.

### Шаг 3: Прогнозирующее кодирование

После разностного кодирования применяется прогнозирующее кодирование. Для этого используется линейный предсказатель, который пытается предсказать следующее значение на основании предыдущих. Ошибка предсказания (разница между реальным и предсказанным значениями) затем сохраняется.

#### Формула линейного предсказателя:

![A](.attachments.57342/image.png)

где:

- 

![image (2).png](.attachments.57342/image%20%282%29.png)

Коэффициенты предсказания могут быть найдены методом наименьших квадратов или другими методами оптимизации.

### Шаг 4: Энтропийное кодирование

Следующим шагом является применение энтропийного кодирования к ошибкам предсказания. Обычно используется кодирование методом Хаффмана или арифметическое кодирование. Эти методы позволяют эффективно сжимать данные, уменьшая их избыточность.

#### Кодирование Хаффманом:

Каждому символу присваивается код переменной длины, причем чаще встречающиеся символы получают короткие коды, а реже встречающиеся — длинные. Это позволяет уменьшить общий объем данных.

### Шаг 5: Упаковка данных

Все полученные данные упаковываются в структуру кадра FLAC. Кадр включает в себя заголовок, содержащий информацию о размере кадра, количестве выборок, частоте дискретизации и других параметрах, а также сами сжатые данные.

### Шаг 6: Запись в выходной файл

Кадры записываются последовательно в выходной файл формата FLAC. Файл может содержать несколько блоков метаданных, таких как информация об исполнителе, альбоме, названии трека и т.д.

### Итоговый алгоритм:

1. Разбить аудиопоток на кадры.
2. Выполнить разностное кодирование для каждого кадра.
3. Применить прогнозирующее кодирование с помощью линейного предсказателя.
4. Использовать энтропийное кодирование (например, Хаффман) для ошибок предсказания.
5. Упаковать данные в структуру кадра FLAC.
6. Записать кадры в выходной файл.

Таким образом, процесс кодирования в FLAC представляет собой сочетание различных методов сжатия без потерь, позволяющее сохранить высокое качество звука при значительном уменьшении объема данных.

В работе с видео, в отличие от работы с изображениями, крайне редко встречаются кодеки без потери качества (lossless). Тем не менее, есть ситуации, когда размер файла не имеет решающего значения, но крайне важно обеспечить сохранение качества изображения при многократном сохранении. Это в первую очередь относится к области профессионального, в т.ч. кинематографического, производства, работе с эффектами и компьютерной графикой для кино.

На этой странице приводятся примеры кодеков с полным сохранением качества (не путайте с RAW, где сохраняется вся информация, получаемая с камеры). Lossless видеокодеки обеспечивают полное восстановление исходного видео без потерь качества.

#### HuffYUV

HuffYUV – один из первых lossless видеокодеков, разработанный Microsoft Research. Он использует комбинацию методов сжатия без потерь, таких как Huffman coding и Differential Pulse Code Modulation (DPCM).

- Алгоритм:  
  Использует предсказание пикселей на основе соседних пикселей и последующую компрессию разностей с помощью Huffman coding. Это позволяет значительно уменьшить объем данных за счет того, что различия между соседними пикселями обычно невелики.
- Формат:  
  Поддерживает RGB24, YUY2, UYVY и другие форматы.
- Пример использования в FFmpeg:

  ```bash
  ffmpeg -i input.mp4 -c:v huffyuv output.avi
  ```
- Пример использования в GStreamer:

  ```bash
  gst-launch-1.0 filesrc location=input.mp4 ! decodebin ! videoconvert ! avenc_huffyuv ! avimux ! filesink location=output.avi
  ```

#### Lagarith

Lagarith – еще один популярный lossless видеокодек, который обеспечивает высокую степень компрессии благодаря использованию арифметического кодирования.

- Алгоритм:  
  кодек основан на предсказании значений пикселей, используя информацию о предыдущих кадрах. Для хранения остаточных ошибок применяется arithmetic encoding, которое может достигать высокой степени сжатия.
- Формат:  
  Поддержка RGB24, YUY2, YV12 и других форматов.
- Пример использования в FFmpeg:

  ```bash
  ffmpeg -i input.mp4 -c:v lagarith output.avi
  ```
- Пример использования в GStreamer:

  ```bash
  gst-launch-1.0 filesrc location=input.mp4 ! decodebin ! videoconvert ! avenc_lagarith ! avimux ! filesink location=output.avi
  ```

#### MSU Lossless Video Codec

MSU Lossless Video Codec – разработка Московского государственного университета. Этот кодек оптимизирован для работы с большими потоками данных и предлагает высокую скорость декомпрессии.

- Алгоритм:  
  Основан на использовании предсказания и последующего применения адаптивного арифметического кодера. Алгоритм также включает использование различных фильтров для улучшения предсказаний.
- Формат:  
  Поддерживается широкий спектр форматов, включая RGB24, YUY2, YV12 и многие другие.
- Пример использования в FFmpeg:

  ```bash
  ffmpeg -i input.mp4 -c:v msvideo1 output.avi
  ```
- Пример использования в GStreamer:

  ```bash
  gst-launch-1.0 filesrc location=input.mp4 ! decodebin ! videoconvert ! avenc_msvideo1 ! avimux ! filesink location=output.avi
  ```

#### Сравнение

Основные отличия этих кодеков заключаются в используемых методах сжатия и скорости обработки.

- HuffYUV быстрее, но менее эффективен в плане сжатия.
- Lagarith медленнее, но дает лучшую компрессию.
- MSU Lossless находится посередине, предлагая баланс между скоростью и качеством сжатия.

### RAW-видео

RAW-видео – это формат видеозаписи, который сохраняет необработанные данные прямо с сенсора камеры без сжатия или обработки. Он предоставляет максимальную гибкость при постобработке, так как содержит всю доступную информацию о цвете, яркости и других характеристиках изображения.

#### Применение:

- Кинематография: Используется профессионалами для создания высококачественного контента, требующего глубокой постобработки цвета и экспозиции.
- Научная визуализация: Применяется там, где требуется высокая точность данных, например, в астрономии или медицине.

#### Характеристики:

- Разрешение: Поддерживает любые разрешения, включая 4K, 8K и выше.
- Цветовая глубина: Обычно 10 бит или больше (например, 12 бит), что обеспечивает значительно большее количество оттенков цветов по сравнению с обычными 8-битными форматами.
- Битрейт: Из-за отсутствия сжатия может достигать десятков гигабайт в минуту записи.
- Размер файла: Один час RAW-видео в разрешении 4K может занимать до нескольких терабайт дискового пространства.

#### Совместимость с ПО:

- Профессиональные видеоредакторы: DaVinci Resolve, Adobe Premiere Pro, Final Cut Pro X.
- Форматы файлов: DNG (Digital Negative), CinemaDNG, ARRIRAW, REDCODE RAW.

#### Ограничения:

- Высокие требования к хранилищу данных и производительности системы.
- Большие файлы затрудняют передачу и работу с ними в реальном времени.
- Необходимость специализированного оборудования для захвата и воспроизведения.

#### Алгоритм кодирования:

RAW-видео не использует традиционного алгоритма кодирования, поскольку оно представляет собой исходный поток байтов, полученных непосредственно с матрицы камеры. Тем не менее, некоторые форматы RAW могут включать минимальные формы сжатия без потерь, такие как Bayer-сжатие (используется в некоторых камерах Canon).

#### Отличия от lossless-кодеков:

- ProRes 4444: Хотя ProRes 4444 также является lossless-контейнером, он уже подвергся некоторому сжатию и обработке, что делает его менее гибким для постобработки, но значительно меньшим по размеру.
- DNxHR: Аналогично, DNxHR предлагает lossless-сжатие, но с меньшей гибкостью и большими размерами файлов по сравнению с RAW.

#### Пример кодирования через FFmpeg:

```bash
ffmpeg -i input.mov -c:v rawvideo output.raw
```

Этот пример конвертирует входной файл input.mov в несжатый RAW-файл output.raw.

#### Пример использования GStreamer:

```bash
gst-launch-1.0 filesrc location=input.mov ! decodebin ! videoconvert ! videorate ! video/x-raw,format=RGB,width=1920,height=1080,framerate=24/1 ! filesink location=output.raw
```

Здесь мы декодируем input.mov, преобразуем его в RGB-формат с разрешением 1920x1080 и частотой кадров 24 fps, а затем сохраняем результат в output.raw.

### Видеокодек Motion JPEG (MJPEG)

Motion JPEG (MJPEG) – это метод сжатия видео, основанный на последовательном применении алгоритмов сжатия изображений JPEG к каждому кадру видео. Он был популярен до появления более эффективных методов компрессии, таких как H.264/AVC и HEVC/H.265.

#### Основные характеристики:

- Тип сжатия: Без потерь внутри каждого кадра, но потери между кадрами.
- Алгоритм сжатия: JPEG (Joint Photographic Experts Group).
- Контейнеры: AVI, MOV, MP4.
- Совместимые форматы файлов: .avi, .mov, .mpg, .mjpeg.

#### Применение:

- Видеонаблюдение: Из-за простоты реализации и возможности передачи данных без задержек, MJPEG широко используется в системах видеонаблюдения, особенно в камерах высокого разрешения.
- Медицинская визуализация: Применяется в медицинских устройствах благодаря поддержке высокого качества изображения и отсутствия межкадрового сжатия.
- Редактирование видео: MJPEG часто используется при монтаже видео, так как каждый кадр независим, что упрощает редактирование.

#### Совместимость с ПО:

- Кодеки: Поддерживается большинством популярных медиа-плееров и редакторов видео, включая VLC, QuickTime, Adobe Premiere Pro.
- Потоковые платформы: Может использоваться в потоковых сервисах, поддерживающих передачу видеопотоков в формате MJPEG.

#### Ограничения:

- Высокий битрейт: По сравнению с современными кодеками, такими как H.264, MJPEG требует значительно больше полосы пропускания для передачи видео того же качества.
- Ограниченная поддержка аппаратного ускорения: Аппаратная поддержка MJPEG менее распространена, чем у других современных кодеков.

#### Уникальные особенности:

- Простота декодирования: Каждый кадр может быть декодирован независимо, что делает этот формат удобным для приложений, требующих быстрого доступа к отдельным кадрам.
- Отсутствие артефактов: Отсутствие межкадровой зависимости позволяет избежать накопления ошибок и артефактов, характерных для других кодеков.

#### Алгоритм кодирования:

- Разбиение на блоки: Кадр разбивается на блоки размером 8x8 пикселей.
- Преобразование DCT: К каждому блоку применяется дискретное косинусное преобразование (DCT), которое переводит пространственные данные в частотную область.
- Квантование: Полученные коэффициенты квантуются, чтобы уменьшить количество информации.
- Энтропийное кодирование: Квантованные коэффициенты подвергаются энтропийному кодированию (например, Хаффмана) для дальнейшей компрессии.

#### Отличие от других кодеков:

- H.264/AVC: В отличие от MJPEG, H.264 использует межкадровое предсказание и компенсацию движения, что позволяет достичь гораздо большей степени сжатия при сохранении высокого качества.
- HEVC/H.265: Еще более современный стандарт, который обеспечивает еще большую степень сжатия за счет использования более сложных алгоритмов предсказания и компенсации движения.

#### Примеры кодирования:

##### Через FFmpeg:

```bash
ffmpeg -i input.mp4 -c:v mjpeg output.mjpeg
```

##### Через GStreamer:

```bash
gst-launch-1.0 filesrc location=input.mp4 ! decodebin ! videoconvert ! jpegenc ! avimux ! filesink location=output.mjpeg
```

Эти примеры показывают базовую процедуру кодирования видео в формат MJPEG с использованием инструментов командной строки FFmpeg и GStreamer.

DV (Digital Video) – это стандарт цифрового видео, разработанный в середине 1990-х годов консорциумом ведущих производителей электроники, включая Sony, Panasonic, JVC и Philips. Кодек предназначен для сжатия и записи высококачественного видео на цифровые носители, такие как MiniDV кассеты, DVCAM и Digital8.

### Основные характеристики:

- Разрешение: PAL/NTSC, 720x576 (PAL) / 720x480 (NTSC)
- Частота кадров: 25 fps (PAL), 29.97 fps (NTSC)
- Битрейт: 25 Мбит/с (PAL), 28.8 Мбит/с (NTSC)
- Цветовая субдискретизация: 4:2:0 (для NTSC) и 4:1:1 (для PAL)
- Тип компрессии: Интра-кадровая компрессия (внутрикадровое сжатие)
- Алгоритм сжатия: DCT (Discrete Cosine Transform) + квантование

### Применение:

DV широко использовался в профессиональной и полупрофессиональной видеосъемке до начала массового перехода на HD-форматы. Этот формат был популярен среди операторов, журналистов, создателей документальных фильмов и телевизионных студий благодаря относительно высокому качеству при умеренном битрейте. Формат поддерживался многими камерами и устройствами захвата видео, такими как Panasonic AG-DVX100, Canon XL1 и Sony DSR-PD150.

### Совместимость с ПО:

DV поддерживается большинством профессиональных видеоредакторов, таких как Adobe Premiere Pro, Final Cut Pro, Avid Media Composer и другими. Также он хорошо интегрируется с open-source инструментами, такими как FFmpeg и GStreamer.

### Ограничения и уникальные особенности:

- Ограничение по разрешению: DV поддерживает только SD-разрешение (Standard Definition). Это ограничивает его применение в эпоху HD и UHD контента.
- Внутрикадровый метод сжатия: Каждый кадр сжимается независимо, что делает DV менее эффективным по сравнению с современными межкадровыми методами сжатия, но упрощает редактирование и монтаж.
- Четкость изображения: Благодаря высокой частоте дискретизации цвета (4:1:1 для PAL и 4:2:0 для NTSC) DV обеспечивает высокое качество цветопередачи.

### Алгоритмы кодирования:

DV использует алгоритм сжатия на основе DCT (Discrete Cosine Transform). Вкратце, этот процесс включает следующие шаги:

1. Разбиение кадра на блоки размером 8x8 пикселей.
2. Преобразование каждого блока в частотную область с помощью DCT.
3. Квантование коэффициентов DCT для уменьшения количества данных.
4. Упаковка и запись сжатых данных.

Этот подход схож с JPEG-сжатием изображений. В DV используется внутрикадровое сжатие, что позволяет избежать артефактов движения между кадрами.

### Сравнение с другими кодеками:

- MPEG-2: MPEG-2 также использует DCT, но добавляет межкадровое сжатие, что улучшает эффективность сжатия за счет предсказания движения. Однако MPEG-2 требует больше ресурсов для декодирования и сложнее в монтаже.
- H.264/AVC: H.264 значительно превосходит DV по эффективности сжатия благодаря использованию более сложных методов предсказания движения и компенсации ошибок. Он также поддерживает HD и выше разрешения.
- ProRes: Apple ProRes является альтернативным профессиональным форматом, который предлагает лучшее соотношение качества и размера файла, особенно для пост-продакшн задач.

### Примеры использования в FFmpeg и GStreamer:

#### FFmpeg:

```bash
ffmpeg -i input.mpg -c:v dvvideo -pix_fmt yuv420p output.dv
```

#### GStreamer:

```python
#!/usr/bin/env python3

import gi
gi.require_version('Gst', '1.0')
from gi.repository import Gst

Gst.init(None)

pipeline = Gst.Pipeline.new("dv_pipeline")
source = Gst.ElementFactory.make("filesrc", None)
decoder = Gst.ElementFactory.make("decodebin", None)
encoder = Gst.ElementFactory.make("dvvideoenc", None)
sink = Gst.ElementFactory.make("filesink", None)

source.set_property("location", "input.mp4")
sink.set_property("location", "output.dv")

pipeline.add(source)
pipeline.add(decoder)
pipeline.add(encoder)
pipeline.add(sink)

source.link(decoder)
decoder.connect("pad-added", lambda src, pad: decoder.link(encoder))
encoder.link(sink)

pipeline.set_state(Gst.State.PLAYING)
bus = pipeline.get_bus()
msg = bus.timed_pop_filtered(Gst.CLOCK_TIME_NONE, Gst.MessageType.ERROR | Gst.MessageType.EOS)

if msg:
    t = msg.type
    if t == Gst.MessageType.ERROR:
        err, debug = msg.parse_error()
        print(f"Error: {err.message}")
    elif t == Gst.MessageType.EOS:
        print("End of stream reached.")
    else:
        pass

pipeline.set_state(Gst.State.NULL)
```

DV -- устаревший, но все еще важный стандарт для цифровой видеозаписи для работы с архивным материалом и ретрооборудованием.

MPEG-4 – это стандарт видеокомпрессии, разработанный Moving Picture Experts Group (MPEG), который был впервые опубликован в 1998 году. Он стал значительным шагом вперед после предшественников, таких как MPEG-2, благодаря внедрению новых методов сжатия видео и поддержки различных типов мультимедийного контента.

#### Основные характеристики:

- Формат файла: .mp4, .m4v
- Тип компрессии: Гибридная компрессия, включающая межкадровое предсказание и внутрикадровую компрессию.
- Контейнеры: MP4, AVI, MOV, MKV
- Потоковая передача: Поддержка потоковой передачи через HTTP, RTSP, RTP/RTCP
- Поддерживаемые форматы: AVC (H.264), HEVC (H.265)

#### Применение:

- Интернет-видео: YouTube, Vimeo, социальные сети (Facebook, Instagram).
- Цифровое телевидение: IPTV, кабельное ТВ, спутниковое вещание.
- Мобильные устройства: Смартфоны, планшеты, игровые консоли.
- Видео-конференц-связь: Zoom, Skype, Google Meet.

#### Почему MPEG-4 все еще используется?

Несмотря на появление более современных стандартов, таких как H.264 и HEVC, MPEG-4 продолжает использоваться благодаря следующим причинам:

1. Совместимость: Широкая поддержка среди устройств и программного обеспечения.
2. Эффективность при низких битрейтах: Хорошо подходит для передачи видео в условиях ограниченной пропускной способности.
3. Простота реализации: Легче реализовать и поддерживать, чем более сложные стандарты.
4. Широкий спектр применения: Подходит для различных сценариев использования, включая интернет-видео, цифровое телевидение и мобильные устройства.

#### Сравнение с другими кодеками:

##### MPEG-2 vs. MPEG-4:

- MPEG-2 использовался для DVD-дисков и цифрового телевидения. Он имеет меньшую эффективность сжатия по сравнению с MPEG-4.
- MPEG-4 предлагает лучшую производительность при низком битрейте и поддерживает больше форматов данных.

##### H.264 vs. MPEG-4:

- H.264 (также известный как AVC) является преемником MPEG-4 и обеспечивает значительно лучшее качество изображения при том же битрейте.
- MPEG-4 проще в реализации и лучше подходит для приложений с ограниченными ресурсами.

##### HEVC (H.265) vs. MPEG-4:

- HEVC представляет собой следующий шаг в развитии видеокомпрессии, предлагая вдвое большую эффективность сжатия по сравнению с H.264.
- MPEG-4 менее эффективен, но легче реализуется и поддерживается.

#### Совместимость с ПО:

- Операционные системы: Windows, macOS, Linux
- Программное обеспечение: VLC, QuickTime, Windows Media Player, FFmpeg, GStreamer
- SDK и библиотеки: libavcodec, x264, x265

#### Ограничения:

- Низкая эффективность при высоких разрешениях: По сравнению с современными кодеками, такими как H.264 и HEVC, MPEG-4 менее эффективен при работе с высоким разрешением.
- Отсутствие поддержки некоторых современных функций: Например, HDR, 10-битный цвет.

#### Уникальные особенности:

- Объектно-ориентированное кодирование: Позволяет кодировать отдельные объекты в кадре независимо друг от друга.
- Поддержка интерактивных мультимедийных приложений: Включает возможность взаимодействия с пользователем через меню и гиперссылки.

#### Алгоритм кодирования:

Алгоритм кодирования MPEG-4 включает следующие этапы:

1. Преобразование цвета: Из YCbCr в RGB.
2. Разбиение на макроблоки: Кадр разбивается на блоки размером 16x16 пикселей.
3. Внутрикадровая компрессия: Использование дискретного косинусного преобразования (DCT) для уменьшения избыточности внутри каждого блока.
4. Межкадровое предсказание: Использование предыдущих кадров для предсказания текущего кадра.
5. Квантование: Уменьшение количества уровней яркости и цвета для дальнейшего сжатия.
6. Энтропийное кодирование: Использование Хаффмана или арифметического кодирования для минимизации размера данных.

#### Отличие от других кодеков:

- MPEG-2: Меньшая эффективность сжатия, отсутствие объектно-ориентированного кодирования.
- H.264: Более сложная структура блоков, улучшенное предсказание движения, поддержка большего числа режимов квантования.
- HEVC: Еще более высокая эффективность сжатия за счет использования больших блоков и улучшенных методов предсказания.

#### Пример кодирования через FFmpeg:

```bash
ffmpeg -i input.mp4 -c:v mpeg4 -b:v 1M -c:a aac output.mpg
```

#### Пример кодирования через GStreamer:

```python
#!/usr/bin/env python3

import gi
gi.require_version('Gst', '1.0')
from gi.repository import Gst

Gst.init(None)

pipeline = Gst.Pipeline.new("test-pipeline")

source = Gst.ElementFactory.make("filesrc", "source")
source.set_property("location", "input.mp4")

decoder = Gst.ElementFactory.make("decodebin", "decoder")

encoder = Gst.ElementFactory.make("mpeg4videoparse", "encoder")
encoder.set_property("bitrate", 1000000)

muxer = Gst.ElementFactory.make("matroskamux", "muxer")

sink = Gst.ElementFactory.make("filesink", "sink")
sink.set_property("location", "output.mkv")

pipeline.add(source, decoder, encoder, muxer, sink)

link_elements = [
    source.link(decoder),
    encoder.link(muxer),
    muxer.link(sink)
]

if not all(link_elements):
    print("Elements could not be linked.")
else:
    pipeline.set_state(Gst.State.PLAYING)
    Gst.debug_bin_to_dot_file(pipeline, Gst.DebugGraphDetails.ALL, "pipeline")
    bus = pipeline.get_bus()
    msg = bus.timed_pop_filtered(Gst.CLOCK_TIME_NONE, Gst.MessageType.ERROR | Gst.MessageType.EOS)
    
    if msg:
        t = msg.type
        if t == Gst.MessageType.ERROR:
            err, debug = msg.parse_error()
            print(f"Error: {err.message}")
            print(f"Debugging information: {debug}")
        elif t == Gst.MessageType.EOS:
            print("End of stream reached.")
        else:
            print(f"Unexpected message received: {msg}")

    pipeline.set_state(Gst.State.NULL)
```

H.266/VVC (Versatile Video Coding) – это стандарт сжатия видео, разработанный ITU-T Video Coding Experts Group (VCEG) и MPEG. Утвержден в июле 2020 года. Основные цели разработки стандарта заключались в улучшении эффективности сжатия по сравнению с предшественниками, такими как H.264/AVC и H.265/HEVC, при сохранении высокого качества видео.

### Характеристики:

- Эффективность сжатия: По оценкам разработчиков, VVC обеспечивает снижение битрейта на 40–50% по сравнению с HEVC при том же качестве видео. Это достигается за счет использования новых инструментов кодирования, таких как адаптивные матрицы квантования, улучшенные предсказания движения и дополнительные блоки преобразования.
- Разрешение: Поддерживает разрешение до 8K UHD (7680x4320), а также может работать с форматами HDR10 и Dolby Vision.
- Частота кадров: До 120 fps.
- Битовая глубина: Поддержка 10-битного и 12-битного цвета.
- Совместимость с предыдущими поколениями: Хотя VVC предлагает значительные улучшения, он не является обратно совместимым с H.265/HEVC или другими старыми стандартами.

### Применение:

- Потоковые сервисы: Потенциальная замена для существующих сервисов потокового вещания, которые используют H.265/HEVC.
- Телевидение высокой четкости: Ультра-HD телевидение, включая спутниковые трансляции и кабельные системы.
- Виртуальная реальность и дополненная реальность: Высокая эффективность сжатия делает VVC привлекательным для приложений VR/AR, требующих передачи больших объемов данных.
- Интернет вещей (IoT): Камеры видеонаблюдения и другие устройства IoT могут использовать VVC для уменьшения объема передаваемых данных без потери качества.

### Сравнение с другими кодеками:

#### H.265/HEVC

- Сжатие: VVC достигает большей степени сжатия, чем HEVC, примерно на 30–50%.
- Производительность: Требует больше вычислительной мощности для декодирования и кодирования по сравнению с HEVC.
- Патенты: Лицензионный пул VVC еще формируется, но ожидается, что стоимость лицензий будет выше, чем у HEVC.

#### AV1

- Открытый исходный код: AV1 разрабатывается Альянсом открытых медиа (AOMedia) и доступен бесплатно. VVC имеет патентованные технологии и требует лицензионных отчислений.
- Качество: AV1 демонстрирует схожую степень сжатия с VVC, однако последний все же считается немного эффективнее.
- Поддержка аппаратной части: На момент написания AV1 поддерживается меньшим количеством устройств и платформ по сравнению с VVC.

#### VP9

- Предыдущая версия: VP9 был выпущен Google как открытый стандарт и широко используется в YouTube. Однако VP9 уступает по эффективности сжатия как VVC, так и AV1.
- Аппаратная поддержка: Широко поддерживаемый кодек, но менее эффективен по сравнению с новыми решениями.

### Уникальные особенности:

- Многоуровневое кодирование: Позволяет разбивать видео на несколько уровней с различными разрешениями и качеством, что удобно для адаптивного стриминга.
- Улучшенная обработка блоков: VVC использует различные размеры блоков для кодирования, что позволяет лучше обрабатывать сложные сцены.
- Инструменты для работы с HDR: Поддержка широкого динамического диапазона (HDR) и высокая точность цветопередачи делают VVC подходящим для контента с высоким разрешением и контрастностью.

### Ограничения:

- Высокая сложность реализации: Требуется значительное количество ресурсов для кодирования и декодирования, что может затруднять внедрение на устройствах с ограниченными ресурсами.
- Стоимость лицензий: Ожидается, что лицензии на использование VVC будут дороже, чем на предыдущие стандарты.

### Алгоритм кодирования:

Основной алгоритм кодирования VVC включает следующие этапы:

1. Предсказание движения: Использование межкадрового предсказания для минимизации избыточности между кадрами.
2. Трансформация: Применение различных типов преобразований (например, DCT) к блокам пикселей для сокращения информации.
3. Квантование: Квантизация коэффициентов преобразования для дальнейшего снижения размера данных.
4. Энтропийное кодирование: Использование энтропийных методов кодирования (например, CABAC) для дополнительной компрессии.
5. Фильтрация: Применение фильтров для удаления артефактов и повышения качества изображения.
6. Контроль скорости передачи данных: Адаптивное управление битрейтом для поддержания заданного уровня качества.

### Пример кодирования через FFmpeg:

```bash
ffmpeg -i input.mp4 -c:v libvvc -b:v 5000k output.mp4
```

Этот пример показывает базовую команду для кодирования видео с использованием библиотеки libvvc и битрейтом 5000 kbps.

### Пример кодирования через GStreamer:

```bash
gst-launch-1.0 filesrc location=input.mp4 ! decodebin ! videoconvert ! vvcenc ! mp4mux ! filesink location=output.mp4
```

Здесь мы используем элемент vvcenc для кодирования видео в формате VVC и сохранения результата в MP4-контейнер.

Таким образом, H.266/VVC представляет собой современный стандарт сжатия видео, который значительно улучшает качество и эффективность по сравнению с предыдущими поколениями кодеков, хотя и требует значительных вычислительных ресурсов и имеет высокие лицензионные затраты.

# Дополнительные материалы

- 10 фактов о новом кодеке VVC

### Кодек Theora

Theora – это открытый видео-кодек, разработанный Xiph.Org Foundation, который основан на стандарте VP3 от On2 Technologies. Он предназначен для сжатия видео с потерями и используется в основном для потоковой передачи мультимедиа через интернет.

#### Основные характеристики:

- Формат контейнера: Ogg (чаще всего).
- Поддержка профилей: Three profiles: Theora I, II, III.
- Тип сжатия: Сжатие с потерями.
- Частота кадров: До 60 FPS.
- Разрешение: Поддерживает до 4K.
- Цветовая субдискретизация: YCbCr 4:2:0.
- Битрейт: Переменный битрейт (VBR), постоянный битрейт (CBR).
- Алгоритм сжатия: Основан на DCT (Discrete Cosine Transform) и предсказании движения.

#### Применение:

- Потоковая передача медиа: Theora часто используется для стриминга видео через веб-приложения благодаря своей поддержке формата Ogg и возможности работы с переменным битрейтом.
- Видеоконференции и VoIP: Благодаря низкому задержке и эффективному сжатию, Theora может использоваться в системах видеосвязи.
- Архивирование видео: Открытый формат делает Theora удобным для долгосрочного хранения данных без привязки к проприетарным решениям.

#### Совместимость с ПО:

- FFmpeg: Полная поддержка кодека для декодирования и кодирования.
- GStreamer: Интеграция через элемент theoradec для декодирования и theoraenc для кодирования.
- VLC Media Player: Поддерживается для воспроизведения и конвертации файлов.
- HTML5 Video: Работает в браузерах, поддерживающих тег <video> с контейнером Ogg.

#### Ограничения:

- Качество сжатия: Хотя Theora обеспечивает хорошее качество при умеренных битрейтах, она уступает современным кодекам, таким как H.264/AVC и HEVC/H.265, особенно при высоких разрешениях и битрейтах.
- Производительность: Процессорное потребление выше, чем у некоторых современных решений, таких как AV1.
- Не поддерживается аппаратными ускорителями: Большинство современных графических процессоров не поддерживают аппаратную акселерацию для Theora.

#### Уникальные особенности:

- Открытая лицензия: Лицензия BSD позволяет использовать кодек без лицензионных отчислений.
- Ограниченная патентная защита: Поскольку кодек был создан до того, как многие современные патенты были поданы, он менее подвержен рискам связанных с патентованием.

#### Алгоритм кодирования:

Theora использует блоковую структуру и метод предсказания движения, аналогичный тому, что используется в MPEG-4 Part 2. Основные этапы включают:

1. Преобразование цвета: Изображение преобразуется из RGB в YCbCr.
2. Блокировка: Кадр разбивается на блоки размером 8x8 пикселей.
3. DCT-преобразование: Применяется дискретное косинусное преобразование (DCT) для каждого блока.
4. Квантование: Коэффициенты DCT квантуются для уменьшения количества информации.
5. Кодирование энтропии: Используются методы Хаффмана и арифметического кодирования для дальнейшего сжатия.
6. Предсказание движения: Для межкадрового сжатия используются макроблоки и векторы движения.
7. Фильтрация: Опционально применяются фильтры для улучшения качества изображения.

#### Пример кодирования через FFmpeg:

```bash
ffmpeg -i input.mp4 -c:v libtheora -qscale:v 10 output.ogv
```

Параметр -qscale:v 10 устанавливает качество видео (чем меньше значение, тем лучше качество). Диапазон значений обычно составляет от 1 до 31.

#### Пример кодирования через GStreamer:

```python
import gi
gi.require_version('Gst', '1.0')
from gi.repository import Gst

Gst.init(None)

pipeline = Gst.Pipeline.new("test-pipeline")

source = Gst.ElementFactory.make("filesrc", "source")
source.set_property("location", "input.mp4")

decoder = Gst.ElementFactory.make("decodebin", "decoder")

encoder = Gst.ElementFactory.make("theoraenc", "encoder")
encoder.set_property("bitrate", 2000000) # Установить битрейт 2 Мбит/с

muxer = Gst.ElementFactory.make("oggmux", "muxer")
sink = Gst.ElementFactory.make("filesink", "sink")
sink.set_property("location", "output.ogv")

pipeline.add(source, decoder, encoder, muxer, sink)

link_elements = [
    source.link(decoder),
    encoder.link(muxer),
    muxer.link(sink)
]

if not all(link_elements):
    print("Failed to link elements!")
else:
    pipeline.set_state(Gst.State.PLAYING)
    Gst.debug_bin_to_dot_file(pipeline, Gst.DebugGraphDetails.ALL, "gstreamer-graph")
    bus = pipeline.get_bus()
    msg = bus.timed_pop_filtered(Gst.CLOCK_TIME_NONE, Gst.MessageType.ERROR | Gst.MessageType.EOS)
    
    if msg:
        t = msg.type
        if t == Gst.MessageType.ERROR:
            err, debug = msg.parse_error()
            print(f"Error: {err.message}")
        elif t == Gst.MessageType.EOS:
            print("End of stream reached.")
        else:
            print(f"Unexpected message of type {t}.")

    pipeline.set_state(Gst.State.NULL)
```

Этот скрипт создает конвейер GStreamer для декодирования входного файла MP4, кодирования его с помощью Theora и сохранения результата в файл OGV.

VP8 – это открытый видеокодек, разработанный компанией On2 Technologies и приобретенный Google в 2010 году. Он стал основой для формата WebM, который используется для передачи видео в интернете. Основные цели разработки VP8 заключались в создании эффективного кодека с открытым исходным кодом, способного конкурировать с проприетарными решениями, такими как H.264/AVC.

### Технические характеристики

- Разрешение: Поддерживает разрешение до 16383x16383 пикселей.
- Частота кадров: До 60 FPS.
- Битрейт: Переменная скорость потока данных, поддержка VBR (Variable Bit Rate).
- Цветовая субдискретизация: YUV 4:2:0.
- Профили: Один профиль – основной (Main Profile), поддерживающий все функции кодека.
- Типы кадров: I-кадры (intra-frames), P-кадры (predicted frames) и Golden/Silver-кадры (для улучшения предсказания).
- Контроль качества: VP8 поддерживает несколько уровней контроля качества (Q-levels), что позволяет настраивать качество видео в зависимости от битрейта.

### Применение

VP8 широко использовался в потоковом вещании через интернет благодаря своей поддержке в браузерах и на платформах YouTube. Он также применялся в таких проектах, как WebRTC для передачи видео в реальном времени между пользователями. Однако с появлением новых стандартов, таких как HEVC/H.265 и AV1, использование VP8 постепенно снижается.

### Сравнение с другими кодеками

#### H.264/AVC:

- Эффективность сжатия: H.264 обычно обеспечивает лучшее сжатие при том же качестве, особенно на высоких разрешениях и битрейтах.
- Патенты: H.264 является лицензируемым стандартом, требующим выплаты роялти за использование. VP8 – полностью свободный и открытый.
- Поддержка: VP8 получил широкую поддержку в веб-браузерах благодаря интеграции с HTML5, тогда как H.264 был менее универсальным решением для онлайн-платформ.

#### HEVC/H.265:

- Эффективность сжатия: HEVC значительно превосходит VP8 по эффективности сжатия, обеспечивая лучшее качество при меньшем битрейте.
- Совместимость: VP8 имеет лучшую обратную совместимость с устаревшими устройствами и платформами, так как требует меньше ресурсов для декодирования.
- Лицензионная политика: HEVC также является патентованным стандартом, хотя и предоставляет больше возможностей для свободного использования в некоторых случаях.

#### AV1:

- Эффективность сжатия: AV1 предлагает еще большую эффективность сжатия по сравнению с VP8, приближаясь к уровню HEVC.
- Открытый стандарт: Как и VP8, AV1 является свободным и открытым стандартом без лицензионных отчислений.
- Современность: AV1 разрабатывался позже VP8 и учитывает современные требования к качеству и производительности.

### Совместимость с ПО

VP8 поддерживается многими популярными мультимедийными фреймворками и библиотеками:

- FFmpeg: Используется для кодирования и декодирования VP8.
- GStreamer: Широко применяемый фреймворк для работы с медиа, включая VP8.
- WebRTC: Использует VP8 для передачи видео в реальном времени.
- HTML5: Интеграция с тегом <video> для воспроизведения видео в формате WebM с использованием VP8.

### Ограничения и уникальные особенности

- Ограничение на высокое разрешение: Хотя VP8 теоретически поддерживает очень высокие разрешения, на практике он редко используется для видео выше Full HD (1920x1080). Более высокие разрешения лучше обрабатываются современными кодеками, такими как HEVC и AV1.
- Качество на низких битрейтах: На низких битрейтах VP8 может демонстрировать заметные артефакты и потерю деталей, что делает его менее подходящим для приложений с ограниченными ресурсами.
- Задержки при кодировании: VP8 использует более простые методы кодирования, что приводит к увеличению задержек при обработке видео в реальном времени по сравнению с новыми поколениями кодеков.

### Алгоритм кодирования

Алгоритм кодирования VP8 основан на предсказаниях блоков пикселей (макроблоков) и преобразовании остаточных ошибок. Основные этапы включают:

1. Предсказание макроблока: Использование соседних блоков для предсказания текущего блока.
2. Трансформация и квантование: Преобразование остатков после предсказания с помощью дискретного косинусного преобразования (DCT) и квантования.
3. Энтропийное кодирование: Кодирование коэффициентов DCT с использованием энтропийных методов, таких как арифметическое кодирование.
4. Обратное квантование и обратное преобразование: Деквантование и обратное DCT для восстановления видео.

Отличия от предыдущих поколений кодеков:

- VP8 включает механизмы предсказания Golden/Silver-фреймов, что улучшает качество видео при низкой задержке.
- Простая структура кодека облегчает его реализацию и интеграцию в различные платформы.

Недостатки в наши дни:

- Меньшая эффективность сжатия по сравнению с более современными кодеками.
- Ограниченное применение на высоких разрешениях и при низких битрейтах.
- Устаревающие технологии, такие как отсутствие поддержки HDR и расширенного динамического диапазона.

### Примеры кодирования

#### FFmpeg

```bash
ffmpeg -i input.mp4 -c:v libvpx-vp8 -b:v 2M output.webm
```

Этот пример показывает, как использовать FFmpeg для конвертации MP4 файла в WebM с использованием кодека VP8 и битрейтом 2 Mbps.

#### GStreamer

```bash
gst-launch-1.0 filesrc location=input.mp4 ! decodebin ! vp8enc ! webmmux ! filesink location=output.webm
```

В этом примере GStreamer используется для декодирования входящего MP4 файла, кодирования его с помощью VP8 и сохранения результата в файл WebM.

Кодек VP9 рассмотрим в сравнении с его предшественником VP8 и альтернативным H.265.

### Эффективность кодирования

Эффективность кодирования измеряет, насколько хорошо кодек сжимает видео без значительного ухудшения качества. Обычно она оценивается по отношению битрейта к качеству (например, PSNR или SSIM). Рассмотрим каждый кодек отдельно:

#### VP9

- Битрейт: По сравнению с VP8, VP9 обычно требует примерно на 20–30% меньше битрейта при одинаковом качестве. Это означает, что при том же битрейте VP9 может предложить лучшее качество изображения.
- Качество: При одинаковых условиях VP9 обеспечивает заметно лучшую четкость деталей и меньшее количество блочных артефактов по сравнению с VP8.

#### VP8

- Битрейт: Для достижения того же уровня качества, что у VP9, требуется больший битрейт. Например, VP8 может требовать на 25–40% больше битрейта, чем VP9.
- Качество: Несмотря на хорошую производительность, VP8 уступает VP9 в сохранении мелких деталей и снижении артефактов.

#### H.265 (HEVC)

- Битрейт: H.265 является одним из самых эффективных современных кодеков. Он предлагает на 35–45% меньший битрейт по сравнению с VP9 при аналогичном качестве. Это делает его предпочтительным выбором для сверхвысокого разрешения (UHD) и приложений с высокой пропускной способностью.
- Качество: H.265 способен сохранять мелкие детали и снижать артефакты даже лучше, чем VP9, благодаря улучшенным алгоритмам предсказания и более сложным методам обработки изображений.

### Артефакты

Артефакты возникают вследствие потерь информации при сжатии видео. Они проявляются в виде блочности, размытости, шумов и других искажений. Рассмотрим, какие типы артефактов характерны для каждого кодека:

#### VP9

- Блочность: Минимальна за счет использования крупных блоков и продвинутых методов предсказания.
- Шумы: Шумоподавление в VP9 работает эффективно, уменьшая видимые шумы.
- Рингинг: Может проявляться вокруг резких переходов, но менее выражен по сравнению с VP8.

#### VP8

- Блочность: Более заметна, особенно при низких битрейтах.
- Шумы: Иногда проявляется остаточный шум, особенно в областях с низкой контрастностью.
- Рингинг: Часто возникает вдоль границ объектов, что приводит к появлению ореолов.

#### H.265 (HEVC)

- Блочность: Практически отсутствует благодаря использованию сложных структур блоков и предсказаний.
- Шумы: Очень маловероятно появление шума, так как HEVC использует продвинутые методы фильтрации.
- Рингинг: Редко встречается, поскольку HEVC обладает эффективными механизмами сглаживания краев.

### Отличия на алгоритмическом уровне

Рассмотрим ключевые алгоритмические различия между этими тремя кодеками:

#### VP9 vs VP8

- Размер блока: VP9 поддерживает блоки размером до 64x64 пикселей, тогда как VP8 ограничен блоками 16x16 пикселей. Большие блоки позволяют лучше обрабатывать крупные области однородного цвета, повышая общую эффективность компрессии.
- Многоуровневое предсказание: VP9 использует многоуровневую структуру предсказания, которая включает векторное движение, субпиксельные сдвиги и улучшенную интерполяцию. Это позволяет точнее восстанавливать кадры и снижает артефакты.
- Контекстное энтропийное кодирование: VP9 применяет контекстное энтропийное кодирование, которое учитывает окружение текущего блока для выбора наиболее подходящего метода сжатия. Это повышает эффективность компрессии по сравнению с VP8.

#### VP9 vs H.265 (HEVC)

- Поддерживаемые форматы: H.265 поддерживает более широкий спектр цветовых форматов, включая HDR и расширенный динамический диапазон, что делает его предпочтительным для высококачественного контента.
- Алгоритмы предсказания: H.265 использует еще более сложные схемы предсказания, такие как асимметричные блоки и улучшенные фильтры, что позволяет достичь лучшего качества при меньших битрейтах.
- Аппаратная поддержка: H.265 имеет значительно большую поддержку со стороны производителей оборудования, что упрощает его внедрение в устройства и системы.

### Заключение

VP9 представляет собой значительное улучшение по сравнению с VP8, предлагая более высокую эффективность кодирования и меньшие артефакты. Однако H.265 (HEVC) превосходит оба этих кодека по эффективности и качеству, хотя и требует большей вычислительной мощности для декодирования. Выбор конкретного кодека зависит от требований к качеству, доступности аппаратных средств и ограничений по пропускной способности сети.

Алгоритм кодирования ProRes основан на комбинации следующих ключевых технологий:

- внутрикадровое сжатие,
- вейвлет-преобразования и
- квантование.

### Интра-кадровое сжатие

ProRes использует внутрикадровое сжатие, что означает, что каждый кадр сжимается отдельно, без учета содержимого соседних кадров. Это отличается от межкадрового сжатия, применяемого в таких кодеках, как H.264, где информация о движении между кадрами используется для уменьшения размера файла.

Преимущества внутрикадрового сжатия включают:

- Простоту доступа к отдельным кадрам без необходимости декодирования всей последовательности.
- Более устойчивую обработку ошибок, поскольку повреждение одного кадра не влияет на остальные.
- Упрощение операций редактирования, такие как вставка, вырезание и замена кадров.

Недостатки:

- Больший размер файлов по сравнению с межкадровыми методами сжатия.

### Вейвлет-преобразования

Для выполнения сжатия ProRes использует дискретное косинусное преобразование (DCT). Этот метод заключается в том, чтобы разбить изображение на небольшие блоки (обычно 8x8 пикселей) и преобразовать пространственные данные в частотные коэффициенты. Затем происходит квантование этих коэффициентов, что приводит к удалению малозначимых деталей и снижению общего количества данных.

### Квантование

После применения DCT выполняется квантование с округлением значений коэффициентов до ближайших целых чисел. Степень квантования определяет конечное качество изображения и размер файла. Чем сильнее квантование, тем меньше файл, но и больше потеря качества.

### Потоковая структура

ProRes организует данные в формате, который включает заголовок, содержащий метаданные, и последовательность кадров. Каждый кадр состоит из серии макроблоков, сжатых с использованием DCT и квантованных коэффициентов. Такая структура облегчает доступ к конкретным кадрам и упрощает операции редактирования.

### Особенности разных профилей ProRes

Различные версии ProRes отличаются уровнем сжатия и поддерживаемыми характеристиками:

- ProRes 422: Базовый профиль, обеспечивающий хорошее соотношение качества и размера файла. Используется для стандартных задач монтажа и цветокоррекции.
- ProRes 4444: Профиль с поддержкой глубины цвета 12 бит и альфа-канала, что важно для композитинга и спецэффектов.
- ProRes 4444 XQ: Наивысший уровень качества среди всех профилей ProRes, предназначенный для наиболее требовательных задач.
- ProRes RAW: Формат, сохраняющий необработанные данные с камеры, но с применением сжатия для уменьшения размеров файлов.

### Заключение

Алгоритм кодирования ProRes сочетает в себе простоту внутрикадрового сжатия с эффективностью вейвлет-преобразований и квантования, что позволяет получать высококачественное видео с умеренным размером файла. Эта комбинация делает ProRes идеальным выбором для профессионального видеопроизводства, где важна возможность быстрого доступа к отдельным кадрам и высокая точность цветопередачи.

### AV1: Высокопроизводительный видеокодек нового поколения

Описание:  
AV1 (AOMedia Video 1) – это открытый видеокодек, разработанный альянсом Alliance for Open Media (AOM), который включает такие компании, как Google, Microsoft, Netflix, Amazon, Intel и другие. Он был создан с целью заменить существующие кодеки, такие как H.264/AVC и VP9, обеспечивая при этом лучшее качество видео при меньшем битрейте.

#### Основные характеристики:

- Битрейт: AV1 обеспечивает экономию до 30% битрейта по сравнению с HEVC и VP9 при одинаковом качестве видео.
- Поддержка HDR: Поддерживает расширенный динамический диапазон (HDR) и широкий цветовой охват (WCG).
- Форматы: Поддерживаются форматы 4:2:0, 4:2:2, 4:4:4 и YCbCr 10-bit.
- Разрешение: Максимальное разрешение видео составляет 8K UHD (7680x4320 пикселей).
- Частота кадров: До 120 FPS.
- Профили: Существуют три основных профиля: Main, High и Professional (Таблица 1).

#### Профили AV1

Таблица 1. Профили AV1.

| Профиль      | Формат | Глубина | FPS | Описание              |
|:-------------|--------|---------|-----|:----------------------|
| Main         | 4:2:0  | 8 bit   | 60  | По умолчанию          |
| High         | 4:2:2  | 10 bit  | 60  | Вещание и HDR-контент |
| Professional | 4:4:4  | 12 bit  | 120 | Кинематограф          |

#### Применение:

- Стриминговые сервисы: Netflix, YouTube, Twitch поддерживают AV1 для передачи контента с минимальными затратами трафика.
- Интернет-трансляции: AV1 используется для онлайн-трансляций спортивных событий, концертов и других мероприятий благодаря своей высокой эффективности сжатия.
- Видеоконференции: Некоторые платформы видеосвязи начинают внедрять поддержку AV1 для улучшения качества видео при низкой пропускной способности сети.

#### Сравнение с другими кодеками:

- H.264/AVC: AV1 превосходит H.264 по качеству видео при том же битрейте. Однако декодирование AV1 требует больше ресурсов процессора по сравнению с H.264.
- VP9: AV1 предлагает лучшую производительность по сравнению с VP9, но также требует большего времени на кодирование и декодирование.
- HEVC/H.265: AV1 демонстрирует схожую эффективность сжатия с HEVC, однако имеет преимущество в виде открытого лицензирования и отсутствия лицензионных отчислений.

#### Совместимость с ПО:

- FFmpeg: Поддерживается начиная с версии FFmpeg 4.0.
- GStreamer: Поддерживается начиная с версии GStreamer 1.18.
- WebRTC: Поддержка AV1 встроена в спецификацию WebRTC.
- VLC media player: Полная поддержка AV1 начиная с версии VLC 3.0.

#### Алгоритм кодирования:

- Блоки переменного размера: AV1 использует блоки размером от 4x4 до 128x128 пикселей, что позволяет лучше адаптироваться к различным структурам изображений.
- Внутрикадровое предсказание: Использует улучшенные методы предсказания внутри кадра, включая асимметричные фильтры и различные режимы предсказания.
- Межкадровое предсказание: Включает сложные механизмы предсказания движения, такие как объединение блоков, многокадровое предсказание и компенсация движения с субпиксельной точностью.
- Энтропийное кодирование: Применяется контекстное адаптивное бинарное арифметическое кодирование (CABAC), которое улучшает компрессию за счет учета статистических свойств данных.

#### Ограничения и недостатки:

- Высокие требования к ресурсам: Кодирование и декодирование AV1 требуют значительных вычислительных мощностей, что может ограничивать использование на устройствах с ограниченными ресурсами.
- Длительное время кодирования: Процесс кодирования AV1 занимает значительно больше времени по сравнению с предыдущими поколениями кодеков.
- Отсутствие аппаратного ускорения: На момент написания статьи аппаратное ускорение для AV1 поддерживается лишь несколькими графическими картами и процессорами.

#### Примеры использования:

##### Кодирование через FFmpeg:

```bash
ffmpeg -i input.mp4 -c:v libaom-av1 -crf 28 -b:v 0 -strict experimental output.av1
```

##### Кодирование через GStreamer:

```bash
gst-launch-1.0 filesrc location=input.mp4 ! decodebin ! videoconvert ! av1enc ! matroskamux ! filesink location=output.mkv
```

H.264, также известный как MPEG-4 Part 10 AVC (Advanced Video Coding), является одним из самых популярных стандартов сжатия видео. Он был стандартизирован ITU-T в 2003 году и стал основой для множества приложений, связанных со стримингом, хранением и передачей видео.

#### Основные характеристики:

- Профили: H.264 поддерживает несколько профилей, таких как Baseline, Main, Extended, High, High 10, High 4:2:2 и High 4:4:4. Каждый профиль предлагает разные уровни функциональных возможностей и требований к декодеру.
- Контроль качества: Поддержка CBR (Constant Bit Rate), VBR (Variable Bit Rate) и ABR (Average Bit Rate).
- Поддерживаемые разрешения: От QCIF (176x144) до 8K UHD (8192x4320).
- Частота кадров: До 120 FPS.
- Цветовые форматы: YUV 4:2:0, 4:2:2, 4:4:4.
- Потоковая передача: Поддерживает потоковую передачу по HTTP, RTSP, RTP/RTCP и другим сетевым протоколам.

Уровни и профили H.264

Таблица 1. Уровни и профили H.264 с их основными характеристиками:

| Уровень | Макс. разрешение | Частота кадров (FPS) | Макс. битрейт |
|---------|------------------|----------------------|---------------|
| 1       | 128x96           | 15                   | 64 Кбит/с     |
| 2       | 320x240          | 30                   | 2 Мбит/с      |
| 3       | 720x480          | 60                   | 20 Мбит/с     |
| 4       | 1920x1080        | 50                   | 40 Мбит/с     |
| 5       | 4096x2304        | 72                   | 135 Мбит/с    |
| 6       | 7680x4320        | 120                  | 300 Мбит/с    |

Таблица 2. Профили H.264 с их основными характеристиками:

| Профиль                       | Описание                                                                                                                                                                          |
|-------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Baseline Profile              | Подходит для мобильных устройств и веб-камер. Поддерживает I и P кадры, без B-кадров.                                                                                             |
| Main Profile                  | Расширяет функционал Baseline, добавляя поддержку B-кадров. Часто используется в телевизионном вещании.                                                                           |
| Extended Profile              | Включает дополнительные функции для улучшения производительности при передаче по каналам с потерями.                                                                              |
| High Profile                  | Самый распространенный профиль, используемый в большинстве приложений, включая Blu-ray и стриминговые сервисы. Поддерживает 8x8 трансформацию и расширенный диапазон квантования. |
| High 10 Profile               | Добавляет поддержку 10-битной глубины цвета.                                                                                                                                      |
| High 4:2:2 Profile            | Поддерживает субдискретизацию 4:2:2, что важно для профессионального использования.                                                                                               |
| High 4:4:4 Predictive Profile | Полностью поддерживает субдискретизацию 4:4:4, обеспечивая наилучшее качество для профессиональных применений.                                                                    |

#### Применение:

- Стриминг видео: CDN и видеоплатформы используют H.264 для передачи видео.
- Видеоконференции: Cервисы видеосвязи часто применяют H.264.
- Хранение видео: Используется для записи и хранения видео на DVD, Blu-ray и других носителях.
- Телевидение: Применяется в цифровом телевидении, включая кабельное, спутниковое и эфирное вещание.

#### Почему H.264 все еще используется?

Несмотря на появление новых кодеков, таких как H.265 (HEVC), AV1 и VP9, H.264 продолжает оставаться популярным по нескольким причинам:

1. Широкая поддержка: H.264 поддерживается практически всеми устройствами и платформами, начиная от смартфонов и заканчивая телевизорами и профессиональными камерами.
2. Совместимость: Большинство существующих аппаратных решений оптимизировано под работу с H.264, что делает его удобным выбором для разработчиков.
3. Производительность: Несмотря на то, что современные кодеки предлагают лучшее качество при меньшем битрейте, они требуют больше ресурсов для обработки, что может быть критично для старых устройств.
4. Стоимость лицензий: Хотя использование H.264 требует лицензионных отчислений, многие компании уже привыкли работать с этим кодеком и готовы платить за лицензию ради стабильности и совместимости.

#### Сравнение с другими кодеками:

##### H.265 (HEVC)

- Эффективность сжатия: HEVC обеспечивает примерно вдвое большую эффективность сжатия по сравнению с H.264 при том же качестве видео.
- Требования к ресурсам: Требует значительно больше вычислительной мощности для кодирования и декодирования.
- Применение: Используется в 4K-телевизорах, Ultra HD Blu-ray и некоторых сервисах стриминга.

##### AV1

- Эффективность сжатия: Обеспечивает на 30% лучшую компрессию по сравнению с H.265 при схожем качестве.
- Скорость работы: Медленнее H.265 и H.264 в плане кодирования, но быстрее в декодировании.

##### VP9

- Эффективность сжатия: Лучше, чем у H.264, но уступает H.265 и AV1.

#### Алгоритм кодирования:

Алгоритм кодирования H.264 основан на блочном предсказании движения (motion estimation) и компенсации движения (motion compensation). Ключевыми элементами являются:

- Макроблоки: Разделение кадра на блоки размером 16x16 пикселей для анализа движения.
- Интрапредсказание: Использование информации внутри текущего кадра для предсказания значений пикселей.
- Интерпредсказание: Использование информации из соседних кадров для предсказания движений объектов.
- Трансформация: Преобразование блоков данных с использованием дискретного косинусного преобразования (DCT) для уменьшения избыточности.
- Квантование: Квантизация коэффициентов DCT для дальнейшего сжатия.
- Энтропийное кодирование: Использование методов энтропийного кодирования, таких как CABAC (Context-Adaptive Binary Arithmetic Coding) и CAVLC (Context-Adaptive Variable-Length Coding), для дополнительной компрессии.

#### Недостатки:

1. Проприетарный кодек: есть лицензионные ограничения, действующие до 2028 года.
2. Ограниченная эффективность: По сравнению с новыми кодеками, такими как H.265 и AV1, H.264 менее эффективен в плане сжатия при высоком разрешении и битрейтах.
3. Ресурсоемкость: Хотя H.264 менее требователен к ресурсам, чем H.265, он все равно требует значительных вычислительных мощностей для кодирования и декодирования.

#### Пример кодирования через FFmpeg и GStreamer:

##### FFmpeg

```bash
ffmpeg -i input.mp4 -c:v libx264 -preset medium -crf 23 output.mp4
```

Здесь libx264 указывает на использование библиотеки x264 для кодирования видео в формат H.264, -preset medium устанавливает средний уровень предустановленных параметров, а -crf 23 определяет постоянный коэффициент качества (CRF).

##### GStreamer

```python
import gi
gi.require_version('Gst', '1.0')
from gi.repository import Gst

Gst.init(None)

pipeline = Gst.Pipeline.new("test-pipeline")

source = Gst.ElementFactory.make("filesrc", "source")
decoder = Gst.ElementFactory.make("decodebin", "decoder")
encoder = Gst.ElementFactory.make("x264enc", "encoder")
muxer = Gst.ElementFactory.make("mp4mux", "muxer")
sink = Gst.ElementFactory.make("filesink", "sink")

source.set_property("location", "input.mp4")
sink.set_property("location", "output.mp4")

pipeline.add(source, decoder, encoder, muxer, sink)

link_elements = [
    source.link(decoder),
    encoder.link(muxer),
    muxer.link(sink)
]

if not all(link_elements):
    print("Failed to link elements!")
else:
    pipeline.set_state(Gst.State.PLAYING)
    Gst.debug_bin_to_dot_file(pipeline, Gst.DebugGraphDetails.ALL, "h264_pipeline")
    bus = pipeline.get_bus()
    msg = bus.timed_pop_filtered(Gst.CLOCK_TIME_NONE, Gst.MessageType.ERROR | Gst.MessageType.EOS)
    
    if msg:
        t = msg.type
        if t == Gst.MessageType.ERROR:
            err, debug = msg.parse_error()
            print(f"Error: {err.message}")
        elif t == Gst.MessageType.EOS:
            print("End of stream reached.")
        else:
            print(f"Unexpected message received: {msg.type}")

    pipeline.set_state(Gst.State.NULL)
```

Этот скрипт использует библиотеку GStreamer для создания конвейера, который считывает файл input.mp4, декодирует его, перекодирует в H.264 с помощью элемента x264enc, мультиплексирует результат в контейнер MP4 и сохраняет его в файл output.mp4.

H.265, также известный как High Efficiency Video Coding (HEVC), является стандартом видеокодека, разработанным ITU-T и ISO/IEC MPEG в 2013 году. Он был создан как преемник H.264/AVC, чтобы обеспечить более высокую степень сжатия видео при сохранении высокого качества.

#### Основные характеристики

- Уровень сжатия: H.265 обеспечивает примерно вдвое большую эффективность сжатия по сравнению с H.264 при том же качестве видео. Это означает, что файлы будут занимать меньше места без заметной потери качества.
- Разрешение: Поддерживает разрешение до 8K UHD (8192x4320 пикселей), а также поддерживает форматы HDR10 и Dolby Vision.
- Частота кадров: До 300 кадров в секунду.
- Профили: Включает несколько профилей, каждый из которых оптимизирован под разные сценарии использования (см. Таблицу 1).
- Блоки кодирования: Размер блоков кодирования варьируется от 4x4 до 64x64 пикселей, что позволяет лучше адаптироваться к сложным сценам.
- Алгоритмы предсказания: Использует улучшенные методы внутрикадрового и межкадрового предсказания, включая асимметричное движение и улучшенное предсказание по образцу.
- Энтропийное кодирование: Применяет контекстно-адаптивное двоичное арифметическое кодирование (CABAC).

#### Профили H.265

Таблица 1. Профили H.265 (HEVC)

| Профиль                     | Описание                                                                                                                                                                                                                                |
|-----------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Main                        | Основной профиль, поддерживающий 8-битный цвет и прогрессивную развертку. Подходит для большинства приложений, включая широковещательное телевидение и интернет-стриминг.                                                               |
| Main 10                     | Расширенный профиль, который добавляет поддержку 10-битного цвета, что улучшает точность передачи оттенков и уменьшает артефакты сжатия. Часто используется в приложениях, требующих высокой точности цвета, таких как HDR-видео.       |
| Main Still Picture          | Специализированный профиль для статичных изображений, обеспечивающий высокую степень сжатия без потерь качества. Используется для хранения и передачи фотографий и других неподвижных графических файлов.                               |
| Multiview Main              | Профиль, предназначенный для работы с многокамерными системами и стереоскопическим контентом. Обеспечивает эффективное сжатие видео с несколькими ракурсами.                                                                            |
| Screen Content Coding (SCC) | Профиль, специально разработанный для кодирования экранного содержимого, такого как презентации, игры и другие приложения с большим количеством текста и графики. Отличается повышенной эффективностью сжатия для такого типа контента. |
| Scalable Main               | Профиль, позволяющий масштабируемую передачу видео, что полезно для адаптации к различным сетевым условиям и устройствам с разными возможностями воспроизведения.                                                                       |
| Range Extensions            | Набор дополнительных возможностей, включающих поддержку 12-битного и 16-битного цветов, HDR, и других расширенных функций. Используется в специализированных приложениях, требующих максимальной точности и качества.                   |

#### Применение

- Потоковая передача видео: Используется в потоковых сервисах, таких как Netflix, YouTube, IPTV, обеспечивая высокое качество видео при меньших требованиях к пропускной способности.
- Запись видео: Применяется в камерах видеонаблюдения, цифровых кинокамерах и профессиональных видеоредакторах.
- Телевидение высокой четкости: Широко используется в вещании контента UHD и HDR.

#### Актуальность H.265

Несмотря на появление новых стандартов, таких как AV1 и VVC (H.266), H.265 остается востребованным благодаря следующим причинам:

- Широкая поддержка аппаратного обеспечения: Многие устройства уже имеют встроенную поддержку декодирования H.265, что делает его удобным для массового применения.
- Зрелость технологии: Кодек хорошо изучен и оптимизирован, что снижает риски при внедрении.
- Производительность: Хотя новые стандарты обещают еще большее сжатие, их реализация может требовать значительных ресурсов процессора и памяти, что ограничивает их применение на менее мощных устройствах.

#### Сравнение с другими кодеками

##### H.264 vs H.265:

- Эффективность сжатия: H.265 примерно в два раза эффективнее H.264 при одинаковом качестве.
- Размер блока кодирования: В H.264 блоки фиксированы размером 16x16 пикселей, тогда как в H.265 они могут варьироваться от 4x4 до 64x64.
- Поддержка разрешений: H.264 ограничен разрешением до 4096x2304 (4K), в то время как H.265 поддерживает до 8K.

##### AV1 vs H.265:

- Открытый стандарт: AV1 является открытым стандартом, разрабатываемым альянсом AOMedia, и не требует лицензионных отчислений, в отличие от H.265.
- Эффективность сжатия: AV1 обещает еще большую эффективность сжатия по сравнению с H.265, но требует больше вычислительной мощности.
- Аппаратная поддержка: На момент написания AV1 имеет ограниченную аппаратную поддержку, в то время как H.265 широко поддерживается современными устройствами.

##### VP9 vs H.265:

- Открытость: VP9, как и AV1, является бесплатным и открытым стандартом, разработанным Google.
- Эффективность сжатия: VP9 находится между H.264 и H.265 по эффективности сжатия, но уступает последнему.
- Применение: Широко используется в онлайн-видео, особенно на платформе YouTube.

#### Совместимость с ПО

H.265 поддерживается большинством современных медиа-плееров, браузеров и операционных систем. Но за 12 лет существования этого кодека не все часто используемые сервисы и программы научились работать с ним.

::: warn
Обязательно проверяйте поддержку H.265 по всей предполагаемой производственной цепочке. Например, в видеонаблюдении вероятнее всего вы не встретите проблем с этим кодеком, а в обычном видеопроизводстве или работе даже с популярными видеоплатформами файлы, закодированные в H.265, могут где-нибудь да не приняться.

:::

#### Ограничения

- Патентные лицензии: Использование H.265 требует оплаты лицензионных сборов, что может стать препятствием для некоторых разработчиков.
- Высокие требования к ресурсам: Декодирование и кодирование H.265 требуют значительных вычислительных ресурсов, что может ограничить его использование на мобильных устройствах и старых компьютерах.

#### Уникальные особенности:

- Интеграция с HDR: H.265 поддерживает работу с расширенным динамическим диапазоном (HDR), что важно для высококачественного видео.
- Многоуровневое предсказание: Улучшенная система предсказаний позволяет достигать большей точности при сжатии сложных сцен.

#### Алгоритм кодирования:

Основной алгоритм кодирования H.265 включает следующие этапы:

1. Предсказание движения: Определение перемещений объектов между кадрами для уменьшения избыточности информации.
2. Трансформация: Преобразование остаточных данных после предсказания движения для улучшения компрессии.
3. Квантование: Уменьшение количества бит, необходимых для представления коэффициентов трансформации.
4. Энтропийное кодирование: Применение CABAC для дальнейшего сжатия данных.
5. Обратное квантование и обратная трансформация: Восстановление исходных данных на стороне декодера.

#### Примеры кодирования через FFmpeg и GStreamer:

##### FFmpeg:

```bash
ffmpeg -i input.mp4 -c:v libx265 -crf 28 -preset medium output.mp4
```

Где:

- -c:v libx265 – указывает использовать библиотеку x265 для кодирования в H.265,
- -crf 28 – устанавливает постоянный коэффициент качества (CRF),
- -preset medium – задает уровень оптимизации (может быть ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow).

##### GStreamer:

```bash
gst-launch-1.0 filesrc location=input.mp4 ! qtdemux ! h265parse ! avdec_h265 ! videoconvert ! autovideosink
```

Где:

- h265parse – парсер для потока H.265,
- avdec_h265 – декодер H.265.

MPEG-1, MPEG-2 и MPEG-4 представляют собой разные версии стандартов сжатия видео, разработанных Moving Picture Experts Group (MPEG). Эти стандарты были созданы в разное время и предназначены для различных целей. Рассмотрим ключевые различия между ними:

### MPEG-1 vs MPEG-2

Основные цели разработки:

- MPEG-1: Был создан для обеспечения приемлемого качества видео при низких битрейтах (около 1,5 Мбит/с) для CD-ROM и других носителей с ограниченной пропускной способностью.
- MPEG-2: Разработан для применения в цифровых системах телевещания, таких как DVB (Digital Video Broadcasting), DVD и кабельные системы. Он предназначен для работы с более высокими битрейтами и разрешениями.

Технические характеристики:

- Разрешение: MPEG-1 ограничен разрешением SIF (Standard Interchange Format), которое составляет 352x240 для NTSC и 352x288 для PAL. MPEG-2 поддерживает разрешение вплоть до Full HD (1920x1080).
- Битрейт: MPEG-1 работает на битрейте около 1,5 Мбит/с, тогда как MPEG-2 может работать с битрейтами до 50 Мбит/с и выше.
- Тип развертки: MPEG-1 поддерживает только прогрессивную развертку, в то время как MPEG-2 добавляет поддержку интерлейсного видео (чересстрочной развертки), что важно для телевизионных сигналов.
- Звук: MPEG-1 включает поддержку стерео-звука, тогда как MPEG-2 поддерживает многоканальные аудиоформаты, такие как Dolby Digital (AC-3).

Применение:

- MPEG-1: Использовался для компакт-дисков (Video CD), интернет-потоков низкого качества и ранних версий мультимедийных проигрывателей.
- MPEG-2: Широко использовался в цифровом телевидении (DVB), DVD-дисках и кабельном вещании.

### MPEG-2 vs MPEG-4

Основные цели разработки:

- MPEG-2: Как упоминалось ранее, был нацелен на высокое качество при достаточно большом объеме данных, подходящем для вещательных систем.
- MPEG-4: Создан для более эффективного сжатия видео и адаптации к различным сетевым условиям, таким как интернет-трансляции и мобильные устройства. Он также включает возможности для интерактивного медиа.

Технические характеристики:

- Алгоритмы сжатия: MPEG-2 основан на технологии предсказания движения и компенсации движения (motion compensation), которая хорошо работала для телевизионных потоков. MPEG-4 добавил новые методы сжатия, такие как улучшенные предсказание и компенсация движения, а также поддержку более гибких блоков (macroblocks) для повышения эффективности сжатия.
- Эффективность сжатия: MPEG-4 предлагает значительно лучшую компрессию при сохранении того же уровня качества, что делает его более подходящим для работы с ограниченными ресурсами, такими как интернет-соединение или мобильные устройства.
- Поддерживаемые разрешения: Оба формата поддерживают широкий диапазон разрешений, однако MPEG-4 изначально разрабатывался с учетом необходимости работы с различными разрешениями и масштабируемостью.
- Интерактивность: MPEG-4 включает функции для создания интерактивных мультимедиа-приложений, таких как VRML (Virtual Reality Modeling Language) и объектно-ориентированное представление медиа-данных.

Применение:

- MPEG-2: Эфирное и кабельное телевидение, DVD.
- MPEG-4: Интернет-видео, стриминговые сервисы, мобильные устройства, видеоконференции.

### Заключение

Каждый из этих стандартов был разработан для конкретных задач и условий своего времени. MPEG-1 предназначался для низкобитрейтных приложений, MPEG-2 — для высококачественного вещательного телевидения и DVD, а MPEG-4 — для более универсальных и эффективных решений, адаптированных под различные сетевые условия и интерактивные приложения.

WAV (Waveform Audio File Format) – аудиоконтейнерный формат, разработанный Microsoft и IBM в начале 1990-х годов для хранения несжатого линейного PCM-аудио (Pulse Code Modulation). Этот формат широко используется благодаря своей простоте и поддержке большинства операционных систем и мультимедийных приложений.

### Основные характеристики:

- Тип содержимого: Аудиофайлы.
- Контейнер: WAV может содержать аудио без сжатия (PCM), а также сжатые форматы, такие как ADPCM, GSM, MP3 и другие.
- Битрейт: Обычно варьируется от 8 до 32 бит на выборку.
- Частота дискретизации: От 8000 Гц до 192000 Гц (в зависимости от требований к качеству).
- Каналы: Поддерживает моно-, стерео- и многоканальные записи.
- Совместимые кодеки: WAV поддерживает широкий спектр кодеков, включая: 
  - PCM\*\* (без сжатия)\*\*
  - ADPCM (Adaptive Differential Pulse Code Modulation)
  - GSM (Global System for Mobile Communications)
  - MP3\*\* (MPEG-1 Layer III)\*\*
  - FLAC\*\* (Free Lossless Audio Codec)\*\*

### Применение:

- Профессиональная звукозапись: Из-за отсутствия потерь при хранении WAV часто используется в студийной работе и при мастеринге аудио.
- Редактирование звука: Многие программы для редактирования звука поддерживают WAV, так как он позволяет работать с чистым сигналом без необходимости декодирования.
- Обмен данными между приложениями: WAV легко интегрируется в различные приложения и системы, обеспечивая универсальность и совместимость.

### Сравнение с другими контейнерами:

- AIFF (Audio Interchange File Format): AIFF аналогичен WAV, но был создан Apple для MacOS. Оба формата могут хранить несжатый PCM-аудио, однако AIFF имеет несколько отличий в заголовке файла.
- FLAC\*\* (Free Lossless Audio Codec)\*\*: FLAC обеспечивает потерю качества, сохраняя меньший размер файла за счет сжатия данных без потерь. В отличие от WAV, который всегда содержит несжатый аудиопоток.
- MP3\*\* (MPEG-1 Layer III)\*\*: MP3 использует сильное сжатие с потерями, что делает файлы значительно меньше по размеру, чем WAV, но приводит к ухудшению качества звука.

### Ограничения:

- Размер файлов: Несжатый PCM-звук занимает значительное количество места на диске. Например, одна минута стереозвука с частотой дискретизации 44.1 кГц и разрядностью 16 бит будет занимать около 10 МБ.
- Поддержка кодеков: Хотя WAV теоретически может поддерживать множество различных кодеков, на практике многие программы ограничены поддержкой только PCM и некоторых других распространенных кодеков.

### Уникальные особенности:

- Простота структуры: Формат WAV очень прост, что облегчает его обработку различными программами и устройствами.
- Отсутствие потерь: Отсутствие сжатия означает отсутствие искажений и потерь качества звука, что особенно важно для профессионального использования.

### Примеры кодирования:

#### Кодирование через FFmpeg:

```bash
ffmpeg -i input.mp3 -acodec pcm_s16le -ar 44100 output.wav
```

Этот пример конвертирует MP3-файл (input.mp3) в WAV с частотой дискретизации 44.1 кГц и 16-битным разрешением (PCM).

#### Кодирование через GStreamer:

```bash
gst-launch-1.0 filesrc location=input.mp3 ! decodebin ! audioconvert ! wavenc ! filesink location=output.wav
```

Здесь filesrc считывает входной файл, decodebin декодирует его, audioconvert преобразует аудио в нужный формат, wavenc упаковывает данные в WAV-контейнер, а filesink сохраняет результат в выходной файл.

OGG – это мультимедийный контейнерный формат, разработанный Xiph.Org Foundation. Он предназначен для хранения аудио-, видео- и текстовой информации, а также метаданных. Формат является свободным и открытым стандартом, что делает его популярным среди разработчиков открытого программного обеспечения.

### Основные характеристики:

- Тип файла: Мультимедиа-контейнер.
- Расширение: .ogg, .ogv (для видео), .oga (для аудио).
- Поддержка потоков: Поддерживает несколько аудиопотоков, видеопотоков и субтитров одновременно.
- Кодеки: Поддерживается широкий спектр кодеков, включая Vorbis (аудио), Theora (видео), Opus (аудио), FLAC (аудио без потерь), Speex (речевое кодирование), Dirac (видео высокого качества).

### Применение:

- Потоковая передача медиа: Благодаря поддержке нескольких потоков и гибкости в управлении метаданными, OGG часто используется для потокового вещания аудио и видео контента.
- Веб-разработка: Контейнеры Ogg используются в веб-браузерах благодаря поддержке HTML5 <video> и <audio> тегов.
- Открытые проекты: Из-за своей открытости и свободы от лицензионных ограничений, OGG широко применяется в проектах с открытым исходным кодом, таких как игры, образовательные программы и мультимедийные приложения.

### Сравнение с другими контейнерами:

- MP4\*\* (H.264/AVC)\*\*: MP4 является наиболее распространенным форматом для видео в интернете. В отличие от OGG, он поддерживает больше устройств и платформ, но требует лицензий на использование некоторых кодеков.
- WebM\*\* (VP8/VP9)\*\*: WebM похож на OGG тем, что тоже основан на открытых стандартах. Однако WebM использует VP8/VP9 для видео и Vorbis/Opus для аудио, что делает его более эффективным для современных браузеров.
- MKV (Matroska): MKV предоставляет большую гибкость в хранении различных типов данных, однако менее популярен для потоковых приложений из-за больших размеров файлов.

### Совместимость с ПО:

- Браузеры: Firefox, Chrome, Opera поддерживают воспроизведение OGG-файлов через HTML5.
- Медиаплееры: VLC, MPlayer, Amarok, Totem, Rhythmbox и другие поддерживают OGG.
- Редакторы: Audacity, Avidemux, Kdenlive позволяют редактировать файлы в формате OGG.

### Ограничения:

- Низкая поддержка аппаратного декодирования: По сравнению с MP4 и WebM, OGG имеет меньшую поддержку аппаратного ускорения, что может приводить к увеличению нагрузки на процессор при воспроизведении.
- Ограниченная поддержка на мобильных устройствах: Многие мобильные устройства не имеют встроенной поддержки OGG, что ограничивает его применение в мобильной среде.

### Уникальные особенности:

- Свободность от патентов: Один из главных плюсов формата – отсутствие необходимости платить за лицензии на использование.
- Совместимость с HTML5: Благодаря нативной поддержке в большинстве современных браузеров, OGG стал важным инструментом для веб-разработчиков.

### Кодеки:

- Vorbis: Аудиокодек с потерями, обеспечивающий высокое качество звука при относительно низком битрейте.
- Theora: Видеокодек с открытыми исходниками, предназначенный для сжатия видео с приемлемым качеством.
- Opus: Современный аудиокодек, который сочетает в себе высокую эффективность и низкую задержку, что делает его идеальным для голосовых коммуникаций и стриминговых сервисов.

### Примеры использования:

#### Кодирование через FFmpeg:

```bash
ffmpeg -i input.mp4 -c:v libtheora -qscale:v 7 -c:a libvorbis -b:a 128k output.ogv
```

Здесь input.mp4 — входной файл, libtheora — видеокодек, qscale:v 7 — настройка качества видео, libvorbis — аудиокодек, b:a 128k — битрейт аудио, output.ogv — выходной файл.

#### Кодирование через GStreamer:

```bash
gst-launch-1.0 filesrc location=input.mp4 ! decodebin ! theoraenc ! oggmux ! filesink location=output.ogv
```

Здесь filesrc указывает на входной файл, decodebin выполняет декодирование, theoraenc кодирует видео с помощью Theora, oggmux упаковывает данные в контейнер OGG, а filesink сохраняет результат в файл output.ogv.

Таким образом, OGG представляет собой мощный и гибкий инструмент для работы с мультимедийным контентом, особенно в условиях, когда требуется свобода от патентных ограничений и высокая степень интеграции с веб-технологиями.

WebM – это открытый формат мультимедийного контейнера, разработанный компанией Google в 2010 году. Он предназначен для передачи видео через интернет, особенно в контексте потокового вещания. Контейнер поддерживает несколько аудиоформатов, но основным является VP8/VP9, а также AV1 для видео и Opus/Vorbis для аудио. WebM широко используется в таких сервисах, как YouTube, Vimeo и других платформах для стриминга видео.

## Основные характеристики WebM:

### Форматы сжатия видео:

- VP8: Предшественник VP9, первый видеокодек, поддерживаемый WebM. Разработка компании On2 Technologies, позже приобретенной Google. VP8 был выпущен под лицензией BSD, что сделало его бесплатным для использования.
- VP9: Усовершенствованный преемник VP8, который обеспечивает лучшее качество при меньшем размере файла. Этот кодек стал стандартом де-факто для потоковой передачи видео высокого разрешения.
- AV1: Новый кодек от альянса AOMedia, включающего такие компании, как Google, Microsoft, Netflix и другие. AV1 предлагает еще большее улучшение качества и эффективности сжатия по сравнению с VP9.

### Аудиоформаты:

- Vorbis: Открытый аудиокодек без лицензионных отчислений, часто используемый вместе с VP8/VP9.
- Opus: Современный аудиокодек, оптимизированный для передачи голоса и музыки через интернет. Обеспечивает высокое качество звука даже при низких битрейтах.

### Поддержка платформ:

WebM поддерживается всеми основными браузерами, такими как Chrome, Firefox, Opera и Edge. Однако Internet Explorer и Safari требуют установки дополнительных плагинов для воспроизведения контента в этом формате.

### Спецификация контейнера:

Контейнер WebM основан на стандарте Matroska (.mkv), что позволяет ему поддерживать различные потоки данных, включая субтитры, метаданные и главы. Вот структура заголовков WebM:

```
EBML Header
Segment
Tracks
Cluster
SimpleBlock
BlockGroup
Block
Frame
```

#### Конвертация MP4 в WebM в FFMPEG с использованием VP9 и Opus:

```bash
ffmpeg -i input.mp4 -c:v libvpx-vp9 -b:v 0 -crf 30 -c:a libopus output.webm
```

Здесь:

- -i input.mp4 указывает входной файл.
- -c:v libvpx-vp9 задает использование кодека VP9 для видео.
- -b:v 0 отключает фиксированный битрейт, позволяя использовать переменный битрейт.
- -crf 30 устанавливает параметр качества Constant Rate Factor (CRF). Чем ниже значение CRF, тем выше качество, но больше размер файла.
- -c:a libopus задает использование кодека Opus для аудио.
- output.webm – выходной файл.

#### Конвертация WebM в MP4 с использованием H.264 и AAC:

```bash
ffmpeg -i input.webm -c:v libx264 -preset slow -crf 22 -c:a aac -b:a 128k output.mp4
```

Здесь:

- -c:v libx264 задает использование кодека H.264 для видео.
- -preset slow устанавливает медленный пресет для лучшего качества, но увеличивает время обработки.
- -crf 22 устанавливает высокий уровень качества.
- -c:a aac задает использование кодека AAC для аудио.
- -b:a 128k устанавливает битрейт аудио 128 кбит/с.

#### Декодирование и воспроизведение WebM в GStreamer:

```bash
gst-launch-1.0 filesrc location=input.webm ! matroskademux name=demux \
demux.video_0 ! vp9dec ! autovideosink demux.audio_0 ! vorbisdec ! audioconvert ! autoaudiosink
```

Здесь:

- filesrc location=input.webm загружает входной файл.
- matroskademux разбирает контейнер WebM.
- vp9dec декодирует видео с помощью VP9.
- autovideosink выводит видео на экран.
- vorbisdec декодирует аудио с помощью Vorbis.
- audioconvert преобразует аудиопоток в нужный формат.
- autoaudiosink выводит звук на устройство вывода.

#### Создание WebM-файла из потока RTSP:

```bash
gst-launch-1.0 rtspsrc location=rtsp://example.com/live_stream ! rtph264depay ! h264parse ! vp9enc ! webmmux ! filesink location=output.webm
```

Здесь:

- rtspsrc получает поток RTSP.
- rtph264depay извлекает данные H.264 из RTP-пакетов.
- h264parse анализирует данные H.264.
- vp9enc перекодирует видео в VP9.
- webmmux собирает все потоки в контейнер WebM.
- filesink сохраняет результат в файл output.webm.

MPEG Program Stream (MPG) является одним из самых популярных в прошлом контейнерных форматов для хранения видео и аудио данных. Он использовался в DVD-дисках, а также в потоковом вещании цифрового телевидения. Формат MPG был стандартизирован Международной организацией по стандартизации (ISO/IEC) под номером ISO/IEC 13818-1 и впервые появился в начале 1990-х годов.

### Основные характеристики

#### Структура контейнера

- Видео: обычно использует формат сжатия MPEG-1 или MPEG-2.
- Аудио: чаще всего MP2 или AC-3.
- Подканалы: могут включать субтитры, дополнительные аудиодорожки и другие данные.

Каждый поток содержит заголовки и пакеты данных, упакованные в блоки фиксированной длины (188 байт). Эти блоки называются пакеты транспортного потока (TS packets).

#### Сжатие видео

Для сжатия видео в формате MPG используются алгоритмы MPEG-1 и MPEG-2. Они основаны на дискретном косинусном преобразовании (DCT), предсказании движения и интерполяции кадров. Например, в MPEG-2 применяются три типа кадров:

- I-кадр (Intra-coded frame): полностью закодированный кадр, который не зависит от других кадров.
- P-кадр (Predicted frame): кадры, которые используют информацию из предыдущих I- или P-кадров для предсказания текущего кадра.
- B-кадр (Bi-directional predicted frame): кадры, которые используют информацию как из предыдущих, так и из последующих кадров для предсказания.

#### Аудиосжатие

Аудио в формате MPG может использовать различные схемы сжатия, такие как MP2 (MPEG-1 Layer II) и AC-3 (Dolby Digital). MP2 обеспечивает хорошее качество звука при относительно низком битрейте, тогда как AC-3 поддерживает многоканальный звук и часто используется в киноиндустрии.

### Спецификация формата

Формат MPG включает следующие ключевые элементы:

- Система пакетов (Packetized Elementary Stream, PES): каждый элементарный поток (видео, аудио, субтитры) разбивается на пакеты PES, которые затем объединяются в транспортный поток.
- Транспортный поток (Transport Stream, TS): структура, состоящая из множества PES-пакетов, объединенных вместе. Каждый пакет имеет длину 188 байт и включает заголовок и полезную нагрузку.
- Синхронизация: обеспечивается за счет использования специальных маркеров синхронизации, которые позволяют декодеру правильно восстанавливать временные метки и последовательность кадров.

### Использование в практике

#### Работа с ffmpeg

ffmpeg — это мощный инструмент для работы с мультимедийными файлами, включая файлы формата MPG. Вот несколько примеров использования ffmpeg для обработки файлов MPG:

```bash
# Конвертация файла AVI в MPG
ffmpeg -i input.avi -c:v mpeg2video -b:v 4M -c:a mp2 -b:a 192k output.mpg

# Извлечение видео из MPG-файла
ffmpeg -i input.mpg -c copy video.mp4

# Извлечение аудио из MPG-файла
ffmpeg -i input.mpg -vn -acodec copy audio.mp3
```

#### Работа с gstreamer

gstreamer — это фреймворк для создания графов обработки медиа-данных. Вот пример использования gstreamer для воспроизведения MPG-файлов:

```bash
# Воспроизвести файл MPG
gst-launch-1.0 filesrc location=input.mpg ! tsdemux name=demux \
   demux.video_00 ! queue ! mpegvideoparse ! mpeg2dec ! xvimagesink \
   demux.audio_00 ! queue ! a52dec ! autoaudiosink
```

### 

MKV (Matroska Video, читается "матрёшка", а не "матроска") – это открытый контейнерный формат мультимедиа, разработанный в 2002 году. Он предназначен для хранения видео, аудио, субтитров и метаданных в одном файле. Формат является гибким и расширяемым, что позволяет использовать его для различных целей, включая потоковую передачу данных, создание Blu-ray дисков и многое другое. Основная цель разработки MKV заключалась в создании универсального контейнера, который мог бы поддерживать множество форматов видео и аудио без привязки к конкретным кодекам.

Несмотря на солидный возраст, MKV получил ограниченную поддержку. Вы не можете рассчитывать, что он откроется в произвольной программе. Поэтому он плохо подходит для хранения архивов и рабочих материалов. Но распространенные программные плееры его открывают хорошо, чего нельзя сказать про аппаратные плееры, веб-сервисы, оболочки NAS тд.

#### Основные характеристики MKV:

- Открытый стандарт: проект Matroska поддерживается сообществом разработчиков и доступен под лицензией LGPL.
- Поддержка множества потоков: может содержать несколько видеопотоков, аудиодорожек и субтитров одновременно.
- Расширяемость: благодаря модульному подходу, формат легко адаптируется под новые технологии и стандарты.
- Совместимость: поддерживает широкий спектр видео- и аудиоформатов, таких как H.264/AVC, HEVC/H.265, AAC, MP3 и многие другие.

### Структура файла MKV

Файл MKV состоит из блоков EBML (Extensible Binary Meta Language), которые определяют структуру контейнера. Вот основные элементы структуры:

- EBML Header: Заголовок, содержащий информацию о версии формата и глобальные настройки.
- Segment: Основной блок, включающий все остальные элементы.
- Cluster: Блок, содержащий фрагменты видео и аудио данных.
- Tracks: Описывают потоки видео, аудио и субтитры.
- Attachments: Дополнительная информация, такая как обложки альбомов, шрифты для субтитров и т.п.
- Chapters: Разделы внутри видео, позволяющие переходить между ними.
- Tags: Метаданные, такие как название фильма, автор, жанр и др.

Пример структуры файла MKV:

```bash
EBML Header
Segment
  SeekHead (информация для быстрого поиска)
  Info (общая информация о сегменте)
  Tracks (описание видеопотока, аудиопоотов и субтитров)
  Chapters (разделы видео)
  Attachments (вложенные файлы)
  Tags (метаданные)
  Cluster (видео и аудиофрагменты)
```

::: success
При записи MKV записывает метаданные параллельно с медиаданными. Это делает файл устойчивым к аварийному прерыванию записи -- уже записанные данные будут читаться, если запись неожиданно прервать.

:::

#### Преобразование видео в MKV c перекодированием в FFMPEG

Для преобразования видео из одного формата в другой с сохранением в контейнере MKV можно использовать следующую команду:

```bash
ffmpeg -i input.mp4 -c:v libx264 -crf 23 -c:a aac -b:a 128k output.mkv
```

Где:

- input.mp4 – исходный файл,
- libx264 – кодек для сжатия видео (H.264),
- crf 23 – параметр качества видео (чем меньше значение, тем выше качество),
- aac – кодек для сжатия аудио (Advanced Audio Coding),
- 128k – битрейт аудио,
- output.mkv – выходной файл в формате MKV.

#### Добавление нескольких аудиодорожек

Чтобы добавить несколько аудиодорожек в один файл MKV, можно воспользоваться следующей командой:

```bash
ffmpeg -i video.mp4 -i audio1.wav -i audio2.wav \
-map 0:v -map 1:a -map 2:a \
-c copy output.mkv
```

Здесь:

- video.mp4, audio1.wav, audio2.wav – исходные файлы,
- -map 0:v – копирование видеопотока из первого файла,
- -map 1:a и -map 2:a – добавление двух аудиодорожек из второго и третьего файлов,
- -c copy – копирование потоков без перекодирования,
- output.mkv – результирующий файл.

#### Извлечение отдельных дорожек

Для извлечения отдельной дорожки (например, субтитров) из файла MKV можно использовать такую команду:

```bash
ffmpeg -i input.mkv -map 0:s:0 subtitles.srt
```

Где:

- input.mkv – входной файл,
- -map 0:s:0 – выбор первой субтитровой дорожки,
- subtitles.srt – выходной файл с субтитрами в формате SRT.

#### Перенос потоков из MKV в MP4 без перекодирования

::: success
При записи внешних потоков лучше использовать контейнер MKV на случай аварийного прерывания записи (отключение питания, программный сбой) -- уже записанная до сбоя часть файла будет читаться. Но для большей совместимости удобнее хранить файлы в контейнере MP4. Следующая команда поможет переложить запись между контейнерами быстро и без потери качества, здесь не используется пережатие содержимого, только меняется контейнер.

:::

```bash
ffmpeg -i input.mkv -c copy output.mp4
```

Где:

- -i input.mkv: указывает путь к входному файлу в формате MKV.
- -c copy: сообщает ffmpeg о необходимости копирования всех потоков без их перекодирования.
- output.mp4: имя выходного файла в формате MP4.

### Работа с MKV через GStreamer

GStreamer – это фреймворк для обработки мультимедийных данных, также поддерживающий работу с файлами MKV. Рассмотрим пример создания простого плеера на основе GStreamer.

#### Простое воспроизведение видео

Для воспроизведения видео в формате MKV можно использовать следующий код на Python:

```python
import gi
gi.require_version('Gst', '1.0')
from gi.repository import GObject, Gst

Gst.init(None)

pipeline = Gst.Pipeline()
source = Gst.ElementFactory.make("filesrc", None)
source.set_property("location", "video.mkv")
demuxer = Gst.ElementFactory.make("matroskamux", None)
decoder = Gst.ElementFactory.make("decodebin", None)
sink = Gst.ElementFactory.make("autovideosink", None)

pipeline.add(source, demuxer, decoder, sink)
Gst.element_link_many(source, demuxer, decoder, sink)

loop = GObject.MainLoop()
pipeline.set_state(Gst.State.PLAYING)
try:
    loop.run()
except KeyboardInterrupt:
    pass
finally:
    pipeline.set_state(Gst.State.NULL)
```

Этот скрипт создает простой граф потока, состоящий из источника (filesrc), демультиплексора (matroskamux), декодера (decodebin) и вывода (autovideosink). При запуске он воспроизводит видео из файла video.mkv.

#### Демонстрация поддержки метаданных

GStreamer также позволяет работать с метаданными, содержащимися в файлах MKV. Например, можно получить информацию о названии фильма, жанре и других параметрах:

```python
import gi
gi.require_version('Gst', '1.0')
from gi.repository import GObject, Gst

def on_tag(bus, msg):
    taglist = msg.parse_tag()
    if taglist is not None:
        for key in ["title", "genre"]:
            value = taglist.get_string(key)[1]
            print(f"{key}: {value}")

Gst.init(None)

pipeline = Gst.Pipeline()
source = Gst.ElementFactory.make("filesrc", None)
source.set_property("location", "video.mkv")
demuxer = Gst.ElementFactory.make("matroskamux", None)
decoder = Gst.ElementFactory.make("decodebin", None)
sink = Gst.ElementFactory.make("autovideosink", None)

bus = pipeline.get_bus()
bus.add_signal_watch()
bus.connect("message::tag", on_tag)

pipeline.add(source, demuxer, decoder, sink)
Gst.element_link_many(source, demuxer, decoder, sink)

loop = GObject.MainLoop()
pipeline.set_state(Gst.State.PLAYING)
try:
    loop.run()
except KeyboardInterrupt:
    pass
finally:
    pipeline.set_state(Gst.State.NULL)
```

Этот скрипт выводит метаданные, такие как название и жанр, при воспроизведении файла video.mkv. Для этого используется сигнал message::tag шины сообщений GStreamer.

MP4 (MPEG-4 Part 14) – это формат мультимедийного контейнера, который используется для хранения видео, аудио, субтитров и других данных. Он основан на стандарте ISO/IEC 14496-12 (MPEG-4 Part 12), который определяет структуру контейнеров, используемых для цифрового мультимедиа. Формат MP4 широко применяется благодаря своей совместимости с различными устройствами и платформами, а также поддержке потоковой передачи через интернет.

## Основные характеристики MP4

### Структура файла MP4

Файл MP4 состоит из блоков, называемых атомами (atoms). Каждый атом имеет уникальный идентификатор (четырехбайтный код) и содержит определенный набор данных. Вот несколько ключевых атомов:

- ftyp: Указывает тип файла и его совместимость с другими версиями стандарта.
- moov: Содержит метаданные о файле, включая информацию о треках, их параметрах и времени воспроизведения.
- mdat: Хранит медиаданные (видео, аудио).
- trak: Описывает трек (например, видео или аудиодорожку).
- mvhd: Заголовок фильма, содержащий общую информацию о файле.

::: warn
При записи MP4 метаданные файла пишутся в конце. При аварийном обрыве записи до сохранения метаданных вся записанная информация становится нечитаемой!

:::

::: success
Для записи используйте MKV, потом переносите без пережатия потоки в контейнер MP4 для большей совместимости с различным ПО. Так делает OBS, если установить формат записи MKV.

:::

### Поддерживаемые кодеки

В MP4 могут использоваться различные кодеки для сжатия видео и аудио. Некоторые из наиболее распространенных:

- Видео: H.264 (AVC), H.265 (HEVC), VP9, AV1.
- Аудио: AAC, MP3, AC-3, Opus.

### Спецификация

Формат MP4 регламентируется стандартом ISO/IEC 14496-14, который описывает следующие аспекты:

- Треки: Файлы MP4 могут содержать несколько треков, каждый из которых может включать видео, аудио, текстовые данные (субтитры) или другие типы информации.
- Потоки: Внутри каждого трека могут находиться потоки, представляющие собой последовательности кадров (для видео) или пакетов (для аудио).
- Синхронизация: Для синхронизации потоков используются временные метки (timestamps), чтобы обеспечить правильное воспроизведение мультимедиаконтента.

### Использование FFmpeg

#### Конвертация файла в MP4

```bash
ffmpeg -i input.mov -c:v libx264 -crf 23 -pix_fmt yuv420p -c:a aac output.mp4
```

Здесь:

- input.mov — исходный файл.
- libx264 — кодек для сжатия видео (H.264).
- crf 23 — параметр качества (чем меньше значение, тем выше качество).
- yuv420p — цветовой формат.
- aac — кодек для сжатия аудио.
- output.mp4 — выходной файл.

#### Извлечение аудиодорожки из MP4

```bash
ffmpeg -i video.mp4 -vn -acodec copy audio.aac
```

Здесь:

- video.mp4 — входной файл.
- -vn — отключение видео.
- -acodec copy — копирование аудиопотока без перекодирования.
- audio.aac — выходной аудиофайл.

### Использование GStreamer

GStreamer предоставляет гибкий фреймворк для создания графов обработки мультимедийных данных. Вот пример простого проигрывателя MP4-файла:

```python
import gi
gi.require_version('Gst', '1.0')
from gi.repository import Gst

Gst.init(None)

pipeline = Gst.Pipeline.new("player")
source = Gst.ElementFactory.make("filesrc", None)
source.set_property("location", "video.mp4")
decoder = Gst.ElementFactory.make("decodebin", None)
sink = Gst.ElementFactory.make("autovideosink", None)

pipeline.add(source)
pipeline.add(decoder)
pipeline.add(sink)

source.link(decoder)
decoder.connect("pad-added", lambda d, p: decoder.link(sink))

pipeline.set_state(Gst.State.PLAYING)

bus = pipeline.get_bus()
msg = bus.timed_pop_filtered(Gst.CLOCK_TIME_NONE, Gst.MessageType.ERROR | Gst.MessageType.EOS)

if msg:
    t = msg.type
    if t == Gst.MessageType.ERROR:
        err, debug = msg.parse_error()
        print(f"Error: {err.message}")
    elif t == Gst.MessageType.EOS:
        print("End of stream reached.")
    else:
        print(f"Unexpected message received: {t}")

pipeline.set_state(Gst.State.NULL)
```

Этот скрипт воспроизводит файл video.mp4, используя элементы filesrc, decodebin и autovideosink.

MOV – это формат мультимедийного контейнера, разработанный компанией Apple Inc. в рамках технологии QuickTime. Он широко используется для хранения видео, аудио и других медиаданных, особенно в экосистемах MacOS и iOS. Формат поддерживает множество различных кодеков: H.264, HEVC, AAC и другие.

#### Структура файла MOV

Файл MOV состоит из серии атомов (atoms), каждый из которых содержит определённую информацию о содержимом файла. Атомы организованы иерархически, образуя древовидную структуру. Основные типы атомов:

- moov: Основной атом, содержащий метаданные о файле, такие как длительность, размеры кадра, количество треков и их характеристики.
- mdat: Содержит непосредственно данные (видео, аудио).
- trak: Атом-трек, который описывает поток медиа-данных (например, видео или аудио). Каждый трек может содержать свои собственные атомы, такие как: 
  - tkhd: Заголовок трека, включающий информацию о длительности, размерах кадра и других параметрах.
  - edts: Информация о редактировании трека.
  - mdia: Медиа-информация, которая включает в себя атомы minf, содержащие конкретные параметры кодеков и медиа-данных.

Каждый атом имеет фиксированную длину заголовка (8 байт), первые 4 байта которого указывают размер атома (включая сам заголовок), а следующие 4 байта содержат идентификатор типа атома.

#### Специфические особенности MOV

1. Интерливинг: MOV-файлы могут использовать интерливинг, когда аудиоданные чередуются с видеоданными внутри одного потока. Это позволяет синхронизировать звук и видео без необходимости внешнего тайм-кода.
2. Мульти-треки: Файлы MOV поддерживают несколько потоков данных одновременно. Например, файл может содержать два разных видеопотока (для разных разрешений) или несколько аудиопотоов (разная языковая дорожка).
3. Поддерживаемые кодеки: MOV поддерживает широкий спектр кодеков, включая MPEG-4 Part 10 (H.264/AVC), High Efficiency Video Coding (HEVC/H.265), Advanced Audio Coding (AAC), ProRes и многие другие.

---

#### Работа с MOV через ffmpeg

FFmpeg – это мощный инструмент для обработки медиафайлов, который отлично справляется с конвертацией, транскодированием и манипуляцией файлов MOV. Рассмотрим несколько примеров использования ffmpeg для работы с MOV.

##### Пример 1: Конвертация MOV в MP4

```bash
ffmpeg -i input.mov -c:v libx264 -crf 23 -pix_fmt yuv420p output.mp4
```

Здесь:

- -i input.mov: Указывает входной файл.
- -c:v libx264: Использует кодек x264 для сжатия видео.
- -crf 23: Устанавливает параметр качества Constant Rate Factor (CRF) равным 23 (чем меньше значение, тем выше качество).
- -pix_fmt yuv420p: Преобразует пиксельный формат в YUV 4:2:0, совместимый с большинством устройств.
- output.mp4: Выходной файл.

##### Пример 2: Извлечение аудио из MOV

```bash
ffmpeg -i input.mov -vn -acodec copy audio.aac
```

Здесь:

- -vn: Отключаем видео-потоки.
- -acodec copy: Копируем аудиопоток без перекодирования.
- audio.aac: Выходной аудиофайл.

##### Пример 3: Добавление субтитров к MOV

```bash
ffmpeg -i video.mov -i subtitles.srt -map 0:v -map 0:a -map 1:s -c copy -c:s mov_text output.mov
```

Здесь:

- -i video.mov: Входной видеофайл.
- -i subtitles.srt: Входной файл с субтитрами.
- -map 0:v -map 0:a -map 1:s: Указываем, какие потоки нужно включить в выходной файл.
- -c copy -c:s mov_text: Копируем все потоки без изменения, кроме субтитров, которые конвертируем в формат mov_text.
- output.mov: Выходной файл с добавленными субтитрами.

---

#### Работа с MOV через GStreamer

GStreamer – это фреймворк для создания графов обработки медиапотоков. Он предоставляет богатый набор плагинов для работы с различными форматами, включая MOV.

##### Пример 1: Воспроизведение MOV

```python
import gi
gi.require_version('Gst', '1.0')
from gi.repository import Gst

Gst.init(None)

pipeline = Gst.Pipeline.new("test-pipeline")
source = Gst.ElementFactory.make("filesrc", None)
source.set_property("location", "input.mov")
demuxer = Gst.ElementFactory.make("qtdemux", None)
decoder = Gst.ElementFactory.make("avdec_h264", None)
converter = Gst.ElementFactory.make("videoconvert", None)
sink = Gst.ElementFactory.make("autovideosink", None)

pipeline.add(source)
pipeline.add(demuxer)
pipeline.add(decoder)
pipeline.add(converter)
pipeline.add(sink)

source.link(demuxer)
pad = demuxer.get_static_pad("video_0")
pad.link(decoder.get_static_pad("sink"))
decoder.link(converter)
converter.link(sink)

pipeline.set_state(Gst.State.PLAYING)
bus = pipeline.get_bus()
msg = bus.timed_pop_filtered(Gst.CLOCK_TIME_NONE, Gst.MessageType.ERROR | Gst.MessageType.EOS)

if msg:
    t = msg.type
    if t == Gst.MessageType.ERROR:
        err, debug = msg.parse_error()
        print("Error: %s" % err, debug)
    elif t == Gst.MessageType.EOS:
        print("End of stream reached.")
    else:
        print("Unexpected message received.")

pipeline.set_state(Gst.State.NULL)
```

Этот пример демонстрирует создание графа для воспроизведения MOV-файла. Здесь используются элементы filesrc, qtdemux, avdec_h264, videoconvert и autovideosink. Граф обрабатывается пошагово, начиная от источника (filesrc) до вывода на экран (autovideosink).

##### Пример 2: Транскодирование MOV в WebM

```python
import gi
gi.require_version('Gst', '1.0')
from gi.repository import Gst

Gst.init(None)

pipeline = Gst.Pipeline.new("transcode-pipeline")
source = Gst.ElementFactory.make("filesrc", None)
source.set_property("location", "input.mov")
demuxer = Gst.ElementFactory.make("qtdemux", None)
parser = Gst.ElementFactory.make("h264parse", None)
encoder = Gst.ElementFactory.make("vp8enc", None)
muxer = Gst.ElementFactory.make("webmmux", None)
sink = Gst.ElementFactory.make("filesink", None)
sink.set_property("location", "output.webm")

pipeline.add(source)
pipeline.add(demuxer)
pipeline.add(parser)
pipeline.add(encoder)
pipeline.add(muxer)
pipeline.add(sink)

source.link(demuxer)
pad = demuxer.get_static_pad("video_0")
pad.link(parser.get_static_pad("sink"))
parser.link(encoder)
encoder.link(muxer)
muxer.link(sink)

pipeline.set_state(Gst.State.PLAYING)
bus = pipeline.get_bus()
msg = bus.timed_pop_filtered(Gst.CLOCK_TIME_NONE, Gst.MessageType.ERROR | Gst.MessageType.EOS)

if msg:
    t = msg.type
    if t == Gst.MessageType.ERROR:
        err, debug = msg.parse_error()
        print("Error: %s" % err, debug)
    elif t == Gst.MessageType.EOS:
        print("Transcoding completed successfully.")
    else:
        print("Unexpected message received.")

pipeline.set_state(Gst.State.NULL)
```

Этот пример показывает процесс транскодирования MOV-файла в формат WebM. Для этого используются элементы h264parse, vp8enc и webmmux.

### Видеоконтейнер AVI: Спецификация, особенности и работа с ним

AVI (Audio Video Interleave) – один из самых старых и широко используемых контейнерных форматов видео, разработанный Microsoft в 1992 году в рамках технологии Video for Windows. Он предназначен для хранения аудио- и видеоданных в одном файле, обеспечивая их синхронную передачу при воспроизведении. Формат основан на спецификации RIFF (Resource Interchange File Format), которая также используется в таких форматах, как WAV и CDA.

#### Основные характеристики формата AVI:

1. Контейнер: AVI является контейнерным форматом, который может содержать различные виды аудиокодеков (например, MP3, PCM, AC3) и видеокодеков (DivX, Xvid, MJPEG). Это позволяет комбинировать разные типы данных внутри одного файла.
2. RIFF структура: AVI-файл имеет структуру, аналогичную другим форматам RIFF. Она состоит из блоков данных, каждый из которых начинается с четырехбайтового идентификатора блока и размера этого блока. Внутри этих блоков могут находиться другие блоки, образуя иерархию.
3. Синхронизация потоков: Для синхронизации аудио и видео потоков используются временные метки (timestamps), а также информация о частоте кадров и длительности фрагментов.
4. Потоки: В одном AVI-файле может содержаться несколько потоков данных, включая основной поток видео, дополнительные потоки субтитров, аудио и других типов медиа.

#### Структура AVI-файла

AVI-файлы состоят из нескольких основных частей:

- Заголовок (Header): Содержит общую информацию о файле, такую как количество потоков, частота кадров, длительность и т.п.
- Индексы (Index): Указывают на расположение каждого кадра в файле, что упрощает произвольный доступ к данным.
- Данные (Data): Основная часть файла, содержащая непосредственно кадры видео и аудиоинформацию.

#### Ограничения AVI

Несмотря на свою популярность, у формата AVI есть ряд ограничений:

1. Максимальный размер файла: Из-за особенностей структуры RIFF максимальный размер AVI-файла ограничен 2 ГБ. Это ограничение связано с тем, что размеры блоков в структуре RIFF хранятся в 32-битном формате.
2. Отсутствие поддержки некоторых современных функций: Например, AVI не поддерживает некоторые современные функции, такие как chapters (разделы) или расширенную поддержку метаданных.
3. Ограниченная поддержка потокового вещания: Хотя AVI может использоваться для локального воспроизведения, он менее подходит для потоковой передачи данных через интернет из-за отсутствия встроенной поддержки сетевых протоколов.

#### Конвертация в AVI

1. Пример с использованием FFMPEG: конвертирование видео из формата MP4 в AVI с сохранением исходного качества:

```bash
ffmpeg -i input.mp4 -qscale 0 output.avi
```

Параметр -qscale 0 указывает на сохранение максимального качества видео.

1. Пример с использованием GStreamer gst-launch: конвертирование видео из формата WebM в AVI с использованием gst-launch:

```bash
gst-launch-1.0 filesrc location=input.webm ! decodebin ! avenc_msmpeg4v3 ! avienc ! filesink location=output.avi
```

Здесь decodebin автоматически определяет кодеки для декодирования входящего видео, avenc_msmpeg4v3 кодирует видео в формат MPEG-4 Part 2, а avienc упаковывает результат в контейнер AVI.

#### Работа с AVI в Python

Для работы с AVI-файлами в Python можно использовать библиотеку ffmpeg или gstreamer. Рассмотрим примеры использования каждой из них.

##### Использование библиотеки ffmpeg

```python
import subprocess

# Открываем файл и извлекаем информацию
subprocess.run(['ffprobe', '-v', 'error', '-show_streams', '-of', 'json', 'example.avi'], capture_output=True)
```

Этот пример использует утилиту ffprobe, входящую в состав пакета ffmpeg, чтобы извлечь информацию о потоке AVI-файла. Команда возвращает JSON-объект, содержащий данные о каждом потоке, включая разрешение видео, частоту кадров, битрейт и т.д.

Также можно воспользоваться ffmpeg для конвертации AVI-файлов в другой формат:

```python
import subprocess

# Конвертируем AVI в MP4
subprocess.run(['ffmpeg', '-i', 'input.avi', '-c:v', 'libx264', '-crf', '23', 'output.mp4'])
```

В этом примере происходит преобразование AVI-файла в MP4 с использованием кодека H.264 (libx264) и постоянным качеством (-crf 23).

##### Использование библиотеки gstreamer

GStreamer — это фреймворк для обработки мультимедийного контента, который предоставляет гибкий API для работы с различными медиаформатами, включая AVI.

Пример создания простого плеера для AVI-файлов:

```python
import gi
gi.require_version('Gst', '1.0')
from gi.repository import GObject, Gst

Gst.init(None)

pipeline = Gst.Pipeline.new("test-pipeline")
source = Gst.ElementFactory.make("filesrc", None)
source.set_property("location", "example.avi")
decoder = Gst.ElementFactory.make("avidecode", None)
sink = Gst.ElementFactory.make("autovideosink", None)

pipeline.add(source)
pipeline.add(decoder)
pipeline.add(sink)

source.link(decoder)
decoder.link(sink)

pipeline.set_state(Gst.State.PLAYING)

bus = pipeline.get_bus()
msg = bus.timed_pop_filtered(Gst.CLOCK_TIME_NONE, Gst.MessageType.ERROR | Gst.MessageType.EOS)

if msg:
    t = msg.type
    if t == Gst.MessageType.ERROR:
        err, debug = msg.parse_error()
        print(f'Error: {err.message}')
    elif t == Gst.MessageType.EOS:
        print('End of stream reached.')
    else:
        print(f'Unexpected message received: {msg}')

pipeline.set_state(Gst.State.NULL)
```

Этот скрипт создает простой плеер для воспроизведения AVI-файла с помощью GStreamer. Сначала создается конвейер (Pipeline), затем добавляются элементы для чтения файла (filesrc), декодирования видео (avidecode) и отображения видео (autovideosink). После этого запускается воспроизведение, и программа ожидает завершения потока или возникновения ошибки.

