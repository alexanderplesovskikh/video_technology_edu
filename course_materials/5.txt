# Протоколы медиастриминга

На вложенных страницах описаны различные медиапротоколы и их особенности. Протоколы, не относящиеся прямо к медиастримингу, описаны в разделе "Другие сетевые протоколы".

Основных приложений, рассматриваемых в курсе "Сетевые видеотехнологии", два:

1. Мультимедиа (видеостриминг в интернет, доставка контента, видеосвязь)
2. Телевизионное производство. Работа с потоками на съемочной площадке или в распределенном съемочном комплексе.

На этой странице вы найдете краткое обобщение, детальную информацию смотрите на страницах соответствующих протоколов и по ссылкам на дополнительные источники.

# Источник данных и протоколы передачи мультимедиа

Для передачи мультимедиа‑данных по сети можно использовать различные протоколы, например, RTSP или WebRTC.

RTSP — протокол прикладного уровня и используется не только для передачи мультимедиа данных, но также и для более общих задач управления потоком данных, работает поверх протоколов транспортного уровня RTP и RTCP. Также для управления сеансом пользователя RTSP использует протокол прикладного уровня SDP. Более подробно все эти протоколы приведены в таблице ниже:

| Уровень      | Описание                                                                                                                                      | Аналоги                        |
|--------------|-----------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------|
| прикладной   | RTSP\*\* – управление потоком данных (установление и контроль сеанса)\*\*:OPTIONS, DESCRIBE, SETUP, PLAY, TEARDOWN, PAUSE                         | HTTP:GET, POST, PUT, DELETE, … |
| транспортный | RTP – передача данных в реальном времени (основан на UDP)                                                                                     | UDP                            |
| транспортный | RTCP – контроль и синхронизация/ RTCP — Википедия.                                                                                            | UDP                            |
| прикладной   | SDP\*\* (session description protocol)\*\* – описание сессии (имя сессии, время доступности сессии, URI) Session Description Protocol — Википедия |                                |

При использовании RTSP или RTP одним из наиболее популярных источников и обработчиков данных потока является утилита FFMPEG.

Пример запуска потока с утилитой FFMPEG:

```
ffmpeg  -re  -i media/s16le-44100hz-example.wav  -c:a copy -f rtp "rtp://127.0.0.1:11111"
```

RTSP работает как пульт управления видеоплеером. Например: Воспроизведение, пауза и т. д. В этом участвуют два протокола: RTP отвечает за медиаданные, RTCP -- за команды.

RTP — это транспортный протокол, используемый RTSP (RTP использует UDP).

В UDP нельзя отследить, есть ли потеря пакетов. RTP работает с UDP, но предоставляет средства для отслеживания пропущенных пакетов, чтобы получатель мог действовать соответствующим образом.

Например, если есть потеря пакета на стороне получателя при передаче пакета (кадра) h.264, он может запросить у отправителя полный i‑й кадр.

RTCP — это просто протокол управления, который работает с RTP для QoS Metric (его основная цель — сбор статистики для сеанса RTP).

Сейчас все в браузерах. Можем ли мы транслировать мультимедиа в браузер? Да, именно здесь на сцену выходит WebRTC. WebRTC снова использует протокол RTP.

WebRTC — это стандарт, который помогает выполнять потоковую передачу мультимедиа из/в браузеры. Кроме того, он имеет дополнительные функции.

Несмотря на то, что WebRTC является peer‑to‑peer технологией, вам все равно придется управлять веб‑серверами и платить за них. Чтобы два одноранговых узла могли общаться друг с другом, вам необходимо использовать сигнальный сервер для настройки, управления и завершения сеанса связи WebRTC. В сценариях вещания WebRTC «один ко многим» вам, вероятно, понадобится медиа‑сервер WebRTC, который будет выступать в качестве промежуточного программного обеспечения для мультимедиа. С WebRTC сложно начать. Существует множество концепций, которые вам нужно изучить и освоить: различные интерфейсы WebRTC, кодеки и обработка мультимедиа, трансляция сетевых адресов (NAT) и брандмауэры, UDP (основной базовый протокол связи, используемый WebRTC) и многое другое.

# Телевизионное производство

Рассмотрим несколько наиболее популярных протоколов медиастриминга:

### RTSP\*\* (Real Time Streaming Protocol)\*\*

RTSP — это стандартный сетевой протокол, который используется для управления потоками мультимедиа. Он позволяет контролировать передачу видео и аудио данных. Разработан для систем видеонаблюдения и предполагает работу в локальных сетях. С этим протоколом мы работаем наиболее плотно при создании распределенных съемочных комплексов, работающих на легких потоках. Мы могли бы использовать более современный SRT, но далеко не всё оборудование его поддерживает и практика применения показывает, что с RTSP удаётся добиться меньших задержек в доставке потоков.

### SRT\*\* (Secure Reliable Transport)\*\*

SRT был создан компанией Haivision для обеспечения надежной и безопасной передачи медиаданных через ненадежные сети, такие как интернет. Этот протокол использует механизмы восстановления потерянных пакетов и шифрования, что делает его идеальным выбором для доставки высококачественного контента при работе в интернет. SRT также обеспечивает низкую задержку при передаче, что особенно важно для прямых трансляций. Это относительно молодой протокол, он, как и RTSP, работает со сжатыми потоками, но предполагает работу не только в локальной сети, но и в интернет. Выпускаются кодеры и камеры, поддерживающие SRT, но поддержка RTSP пока существенно шире. На уровне программной поддержки также не всё гладко: уже есть модули для FFMPEG и GStreamer, но обещанной разработчиками протокола минимальной задержки добиться не удаётся, в то время как RTSP, для которого работу в реальном времени (например, при многокамерном видеопроизводстве) никто и не заявлял, показывает лучшие результаты. Возможно, это связано с "сырыми" версиями соответствующего ПО.

SRT интересен также тем, что любая сторона может быть как клиентом, так клиентом, так и сервером.

### NDI\*\* (Network Device Interface)\*\*

NDI, разработанный компанией NewTek, представляет собой высокоскоростной протокол для передачи видео и аудиосигналов по IP-сетям. Он оптимизирован для использования в высокоскоростных (от 1 Гбит/с) локальных сетях и может передавать несколько потоков одновременно без кратного увеличения нагрузки на сеть. NDI широко применяется в студиях вещания и видеопродакшн-комплексах благодаря своей простоте настройки и высокой производительности. Потоки в "классическом" NDI тяжелые: FullHD видео потребляет больше 100 мбит/с и поддерживают цветовую субдискретизацию 4:2:2.

Также существуют версии этого протокола для работы со сжатым видео (от 6 мбит/с 4:2:0).

### SMPTE ST 2110

SMPTE ST 2110 — это набор стандартов, разработанных SMPTE, для передачи несжатых видео- и аудиопотоков по IP-сетям. Этот протокол требует высокоскоростную сетевую инфраструктуру (от 10 Гбит/с).  В отличие от предыдущих протоколов, ST 2110 делит видео, аудио и синхронизацию на отдельные потоки, что позволяет более гибко управлять ими. Это решение идеально подходит для крупных студий и производственных комплексов, где требуется высокая степень контроля над каждым элементом потока.

---

# Источники

1. Архитектура потоковой обработки медиа-данных. Хабр, блог Otus.
2. ГигаЧат.

# Дополнительная информация

1. Video Streaming Protocols: What Are They & How to Choose The Best One. Getstream.io

HLS (HTTP Live Streaming) — это коммуникационный протокол для потоковой передачи медиа на основе HTTP, разработанный компанией Apple как часть программного обеспечения QuickTime, Safari, OS X и iOS. В основе работы лежит принцип разбиения цельного потока на небольшие фрагменты, последовательно скачиваемые по HTTP. В начале сессии скачивается плей-лист в формате M3U, содержащий метаданные об имеющихся вложенных потоках.

Одним из преимуществ HLS является то, что все подключенные к Интернету устройства поддерживают протокол HTTP, что упрощает его реализацию, чем протоколы потоковой передачи, требующие использования специализированных серверов. Еще одно преимущество состоит в том, что поток HLS может повышать или понижать качество видео в зависимости от состояния сети без прерывания воспроизведения. Вот почему качество видео может улучшаться или ухудшаться в середине видео, когда пользователь его смотрит. Эта функция известна как «доставка видео с адаптивной скоростью передачи» или «адаптивный стриминг», и без нее медленные сетевые условия могут полностью остановить воспроизведение видео.

# Основная информация

HTTP Live Streaming состоит из трех частей: серверного компонента, компонента распространения и клиентского программного обеспечения.

Вначале кодер принимает аудио-видео и кодирует видео в HEVC, а аудио в AC-3. Всё это вкладывается в транспортный поток MPEG-2 для последующей доставки. Затем разделитель (software stream segmenter) разбивает контент в MPEG-2 TS на фрагменты одинаковой длины (с разрешением .ts), которые размещаются на веб-сервере. Разделитель также создает индексный файл, называемый manifest file (с разрешением .m3u8), который содержит список самих  медиафайлов. URL-адрес индексного файла публикуется на веб-сервере. Клиентское программное обеспечение считывает индекс, затем запрашивает перечисленные медиафайлы по порядку и отображает их без каких-либо пауз или промежутков между сегментами.

![Рисунок 1. Схема пути медиапотока до клиента.](.attachments.55919/image.png)

# Клиент

Клиент запрашивает и скачивает все файлы, собирая их воедино так, чтобы предоставить пользователю непрерывный поток видео. Клиентское ПО скачивает первый индексный файл через URL и далее несколько доступных файлов медиа. ПО для проигрывания собирает всё в последовательность для воспроизведения. Существует два режима работы HLS — «по запросу» и живая трансляция. В режиме «по запросу» плей-лист содержит ссылки на все фрагменты от первого до последнего. В режиме живой трансляции плей-лист содержит только ссылки на последние несколько фрагментов, кроме того при последующих обращениях к плей-листу, фрагменты будут меняться, отражая текущее состояние трансляции.

HLS предусматривает поддержку адаптивного битрейта, эта техника предусматривает наличие нескольких одновременно доступных потоков, каждый из которых может содержать одинаковый контент, закодированный в разных битрейтах, а также имеющий другие отличающиеся характеристики. По мере проигрывания клиент может выбирать из числа нескольких доступных потоков, что позволяет адаптировать сессию к внешним условиям передачи по сети.

# HLS Playlist

Манифесты (индексные файлы) HLS бывают двух типов – основные и дочерние. Чтобы понять, как они связаны, возьмем простой пример. Предположим, что вы закодировали фильм в 3 разных разрешениях – 1080p, 720p, 480p. После того, как вы упакуете пакет с использованием протокола HLS, вы получите один основной и 3 дочерних манифеста.

В главном манифесте будут описаны версии и их спецификации (кодеки, языки, битрейты), которые будут транслироваться как часть этого видео. В дочерних манифестах будут перечислены все сегменты (местоположение, имена, последовательность) для соответствующих разрешений. В этом случае у вас будет 3 дочерних манифеста – по одному для 1080p, 720p, 480p соответственно.

Посмотрим на пример основного манифеста:

```
#EXTM3U
#EXT-X-MEDIA:URI="subtitle/lang_en/subtitle_index.m3u8",TYPE=SUBTITLES,GROUP-ID="subtitles",LANGUAGE="en",NAME="English",DEFAULT=YES,AUTOSELECT=YES
#EXT-X-STREAM-INF:BANDWIDTH=893752,AVERAGE-BANDWIDTH=560289,RESOLUTION=854x480,CODECS="avc1.4D401F,mp4a.40.2",SUBTITLES="subtitles"
media-4/index.m3u8
#EXT-X-STREAM-INF:BANDWIDTH=1494976,AVERAGE-BANDWIDTH=891779,RESOLUTION=1280x720,CODECS="avc1.640028,mp4a.40.2",SUBTITLES="subtitles"
media-5/index.m3u8
#EXT-X-STREAM-INF:BANDWIDTH=3262928,AVERAGE-BANDWIDTH=1894009,RESOLUTION=1920x1080,CODECS="avc1.640028,mp4a.40.2",SUBTITLES="subtitles"
media-6/index.m3u8
#EXT-X-I-FRAME-STREAM-INF:BANDWIDTH=161304,RESOLUTION=854x480,CODECS="avc1.4D401F",URI="media-4/iframes.m3u8"
#EXT-X-I-FRAME-STREAM-INF:BANDWIDTH=241392,RESOLUTION=1280x720,CODECS="avc1.640028",URI="media-5/iframes.m3u8"
#EXT-X-I-FRAME-STREAM-INF:BANDWIDTH=532416,RESOLUTION=1920x1080,CODECS="avc1.640028",URI="media-6/iframes.m3u8"
```

- #EXTM3U – это обязательный тег, который указывает, что это файл для хранения плейлистов M3U8;
- #EXT-X-STREAM-INF – определяет три разных видеопотока с разным качеством, здесь содержится информация о пропускной способности, средней пропускной способности, разрешении, кодеках и расположении медиафайлов.

# Видео по запросу

В таком режиме, как видео по запросу (VOD) медиафайлы доступны в течение всей сессии. В данном случае сеанс предоставляет клиенту полный доступ ко всей программе.

Посмотрим на пример плейлиста для видео по запросу:

```
#EXTM3U
#EXT-X-PLAYLIST-TYPE:VOD
#EXT-X-TARGETDURATION:10
#EXT-X-VERSION:4
#EXT-X-MEDIA-SEQUENCE:0
#EXTINF:10.0,
http://example.com/movie1/fileSequenceA.ts
#EXTINF:10.0,
http://example.com/movie1/fileSequenceB.ts
#EXTINF:10.0,
http://example.com/movie1/fileSequenceC.ts
#EXTINF:9.0,
http://example.com/movie1/fileSequenceD.ts
#EXT-X-ENDLIST
```

Каждому URL-адресу медиафайла должен предшествовать тег EXTINF. Этот тег описывает число, которое определяет продолжительность медиасегмента в секундах. Это значение должно быть меньше или равно EXT-X-TARGETDURATION.

# Трансляция

В онлайн-трансляциях индексный файл обновляется путем удаления URL-адресов из файла по мере создания новых медиафайлов.

Посмотрим на пример плейлиста для онлайн-трансляции:

```
#EXTM3U
#EXT-X-TARGETDURATION:10
#EXT-X-VERSION:4
#EXT-X-MEDIA-SEQUENCE:1
#EXTINF:10.0,
fileSequence1.ts
#EXTINF:10.0,
fileSequence2.ts
#EXTINF:10.0,
fileSequence3.ts
#EXTINF:10.0,
fileSequence4.ts
#EXTINF:10.0,
fileSequence5.ts
```

Список воспроизведения продолжает обновляться по мере добавления новых мультимедиа-данных:

```
#EXTM3U
#EXT-X-TARGETDURATION:10
#EXT-X-VERSION:4
#EXT-X-MEDIA-SEQUENCE:4
#EXTINF:10.00,
fileSequence4.ts
#EXTINF:10.00,
fileSequence5.ts
#EXTINF:10.0,
fileSequence6.ts,
#EXTINF:10.0,
fileSequence7.ts,
#EXTINF:10.0,
fileSequence8.ts,
#EXTINF:10.0,
fileSequence9.ts
```

#EXT-X-MEDIA-SEQUENCE: указывает порядковый номер первого URL-адреса, который появляется в плейлисте. Каждый URL-адрес медиафайла в списке воспроизведения имеет уникальный целочисленный порядковый номер. Порядковый номер URL-адреса на 1 больше порядкового номера предшествующего ему URL-адреса. Порядковые номера носителей не имеют никакого отношения к названиям файлов.

HTTP dynamic streaming (HDS), - это метод потоковой передачи медиаданных, разработанный Adobe. HDS доставляет контент в формате MP4 по HTTP-соединениям. HDS можно использовать для потоковой передачи по запросу или в режиме реального времени. Поскольку они доставляются по протоколу HTTP, потоки HDS могут кэшироваться либо сетью доставки контента (CDN), либо другим сервером кэширования.

HDS был разработан для использования с Adobe Flash Player и Adobe AIR. Adobe Flash Player был прекращен, и сторонняя фирма теперь поддерживает AIR вместо Adobe. HDS не поддерживается устройствами Apple.

# Протокол видеостриминга HDS

Протокол HTTP Dynamic Streaming (HDS), разработанный компанией Adobe, является одним из популярных решений для потоковой передачи видео через интернет. Он был создан как альтернатива RTMP (Real Time Messaging Protocol), который использовался ранее для доставки медиаконтента в реальном времени.

## Основы работы

HDS основан на использовании HTTP для передачи данных, что позволяет ему легко интегрироваться с существующей инфраструктурой веб-серверов и прокси. Это делает его особенно удобным для масштабируемых систем видеостриминга. Как и другие современные протоколы, такие как HLS и MPEG-DASH, HDS использует принцип сегментирования контента на небольшие фрагменты, каждый из которых загружается отдельно.

Видеопоток разбивается на сегменты длительностью несколько секунд, которые затем передаются клиенту по запросу. Сервер отправляет манифестный файл (manifest.f4m), содержащий информацию о доступных сегментах и их характеристиках (разрешение, битрейт и т.д.). Клиентская сторона запрашивает эти сегменты последовательно, обеспечивая плавность воспроизведения.

## Поддержка адаптивного битрейта

Как и большинство современных протоколов видеостриминга, HDS поддерживает адаптивное изменение качества видео в зависимости от пропускной способности сети клиента. Это достигается за счет того, что сервер предоставляет несколько версий одного и того же фрагмента с разным качеством (битрейтом). Клиент выбирает наиболее подходящий вариант на основе текущих условий сети.

## Формат контейнера

Для хранения мультимедийных данных HDS использует контейнер F4F, который представляет собой расширение формата FLV (Flash Video). Этот формат включает аудио-, видеокодеки и метаданные, необходимые для синхронизации потоков. Контейнер F4F может содержать как аудиофрагменты, так и видеофрагменты, что упрощает обработку и доставку медиа.

# Отличия от HLS и MPEG-DASH

## HLS (HTTP Live Streaming)

HLS был разработан Apple и стал стандартным решением для потокового вещания на устройствах iOS. Его основным отличием от HDS является использование контейнера TS (Transport Stream) вместо F4F. Также HLS имеет другой формат манифеста (playlist.m3u8) и требует преобразования видеопотока в отдельные файлы, что может усложнить процесс обработки.

## MPEG-DASH

MPEG-DASH (Dynamic Adaptive Streaming over HTTP) – это открытый стандарт, разработанный консорциумом MPEG. Он отличается тем, что поддерживает множество различных форматов контейнеров, включая MP4, WebM и даже ISO BMFF (используемый в HDS). MPEG-DASH также предлагает большую гибкость в выборе кодеков и параметров сжатия, что делает его универсальным решением для разных платформ и устройств.

## Сравнение HDS, HLS и MPEG-DASH

| Характеристика           | HDS                 | HLS                 | MPEG-DASH                 |
|--------------------------|---------------------|---------------------|---------------------------|
| Контейнер                | F4F                 | TS                  | MP4, WebM, ISO BMFF и др. |
| Манифест                 | .f4m                | .m3u8               | .mpd                      |
| Адаптивный битрейт       | Да                  | Да                  | Да                        |
| Поддерживаемые платформы | Flash Player, HTML5 | iOS, Android, HTML5 | Все популярные платформы  |

## Технические особенности работы с HDS

### Генерация потоков

Для создания потока HDS необходимо использовать специальное программное обеспечение, такое как Adobe Media Server или сторонние решения, поддерживающие этот протокол. Процесс генерации включает следующие шаги:

1. Кодирование видео: Исходное видео должно быть закодировано в формате, совместимом с HDS (например, H.264 для видео и AAC для аудио).
2. Разбиение на сегменты: После кодирования видео разбивается на короткие сегменты (обычно длиной 2–10 секунд), которые сохраняются в файлах F4F.
3. Создание манифеста: На основании информации о сегментах создается манифестный файл (.f4m), который содержит ссылки на все доступные версии сегмента с разными битрейтами.
4. Публикация: Готовые сегменты и манифест размещаются на веб-сервере, откуда они могут быть доступны клиентам.

### Ограничения

- Зависимость от Flash Player: Изначально HDS требовал наличия Flash Player на клиентской стороне, что ограничивало его применение на мобильных устройствах и платформах без поддержки Flash.
- Поддержка браузеров: Современные браузеры отказались от поддержки Flash, что снижает актуальность HDS в пользу более универсальных решений, таких как MPEG-DASH.
- Совместимость с другими устройствами: Хотя HDS поддерживается многими популярными плеерами и платформами, он менее универсален, чем MPEG-DASH, который работает практически везде.

MPEG-DASH расшифровывается как динамическая адаптивная потоковая передача MPEG по протоколу HTTP. Это протокол потоковой передачи, который позволяет передавать видеоконтент через Интернет таким образом, чтобы он адаптировался к изменяющимся сетевым условиям зрителя. Это означает, что качество видео можно регулировать в режиме реального времени, в зависимости от доступной полосы пропускания зрителя и возможностей устройства.

# Потоковая передача по протоколу HTTP

Доставка видеоконтента через Интернет началась в 1990-х годах, главной проблемой в то время была своевременная доставка и потребление больших объемов данных. Протокол RTP, разработанный для передачи потоковых данных, позволял доставлять пакеты с низкими накладными расходами. RTP хорошо работает в управляемых IP-сетях. Однако в настоящее время управляемые сети заменены сетями доставки контента (CDN), многие из которых не поддерживают потоковую передачу по протоколу RTP. Кроме того, пакеты RTP часто не пропускаются через брандмауэры. Наконец, потоковая передача по протоколу RTP требует, чтобы сервер управлял отдельным сеансом потоковой передачи для каждого клиента, что является ресурсоемким.

Потоковая передача по протоколу HTTP имеет несколько преимуществ. Во-первых, инфраструктура интернета удобна для эффективной поддержки HTTP. Например, CDN предоставляют локализованные пограничные кэши, которые сокращают трафик на большие расстояния. HTTP пропускается фаерволлами, и соответственно, трафик, который использует HTTP, пропускается между сетями без проблем.

Во-вторых, под HTTP в контексте дистрибуции заточено множество механизмов, например, сети доставки контента, распределяющие нагрузку с источника на сеть распределенных и установленных на высокоскоростных каналах серверов. Таким образом, любой контент, использующий HTTP, не нуждается в дополнительных усилиях по оптимизации инфраструктуры доставки при массовом использовании – там работают механизмы, созданные и повсеместно используемые для обычных веб-страниц.

# Адаптивный стриминг

На рисунке 1 показан простой пример динамической адаптивной потоковой передачи по запросу. На этом рисунке мультимедийный контент состоит из видео- и аудиокомпонентов.

![Рисунок 1. Динамическая адаптивная передача по запросу.](.attachments.55890/image.png)

Источник видео кодируется с тремя различными альтернативными скоростями передачи данных: 5 Мбит, 2 Мбит и 500 килобит в секунду. Сопровождающий аудиоконтент доступен на двух языках: аудио 1 - это дублированная английская версия звуковой дорожки с альтернативами 128 Кбайт и 48 Кбит/с; в то время как аудио 2 - оригинальная французская версия.

Предположим, что устройство начинает потоковую передачу контента, запрашивая сегменты видеопотока в самом высоком доступном качестве (5 Мбит/с) и аудио на английском языке в 128 Кбит AAC. После потоковой передачи первых сегментов видео и аудио мониторинг пропускной способности сети понимает, что фактическая доступная пропускная способность ниже 5 Мбит/с. Итак, в следующей доступной точке переключения он переключает видео со скоростью 2 Мбит/с, транслируя следующие сегменты с дорожки среднего качества, продолжая при этом потоковую передачу 128-килобитного аудио AAC на английском языке (метка 2). Устройство продолжает отслеживать фактическую пропускную способность сети и понимает, что пропускная способность сети еще больше снизилась до значения ниже 2 Мбит/с. Следовательно, для поддержания непрерывного воспроизведения устройство дополнительно переключает потоки на видео со скоростью 500 Кбит/с и аудио со скоростью 48 Кбит/с (метка 3). Он продолжает воспроизводить контент с такой скоростью до тех пор, пока пропускная способность сети не увеличится, а затем переключает видео до 2 Мбайт (метка 4). Через некоторое время пользователь решает приостановить и перемотать назад. В этот момент устройство начинает потоковую передачу видео с дорожки trick-mode для воспроизведения видео в обратном порядке, при отключенном звуке (метка 5). В нужном месте пользователь нажимает, чтобы воспроизвести контент с оригинальным французским переводом аудио. На этом этапе устройство возобновляет потоковую передачу видео самого высокого качества (5 Мбит/с) и аудио со 128-килобитного французского аудио (метка 6).

Более продвинутые варианты использования могут включать переключение между просмотрами с нескольких камер, потоковую передачу мультимедийного контента в формате 3D, видеопотоки с субтитрами и титрами, динамическую вставку рекламы, прямую трансляцию с низкой задержкой, смешанную потоковую передачу и воспроизведение предварительно сохраненного контента и т.д.

# Область применения MPEG-DASH

На рисунке 2 показан простой сценарий потоковой передачи между HTTP-сервером и клиентом DASH. На этом рисунке мультимедийный контент захватывается и сохраняется на HTTP-сервере и доставляется с использованием HTTP.

![Рисунок 2.](.attachments.55890/image%20%282%29.png)

Контент расположен на сервере в двух частях:

1. Media Presentation Description (MPD) – тоже, что manifest file в HLS;
2. Фрагменты мультимедийных битовых потоков.

Чтобы воспроизвести контент, клиент DASH сначала получает MPD. MPD может быть доставлен с помощью HTTP, электронной почты, флэш-накопителя, широковещательной рассылки и т.п. Анализируя MPD, клиент DASH узнает о времени работы программы, доступности медиаконтента, типах носителей, разрешениях, минимальной и максимальной полосах пропускания, а также о существовании различных альтернативных кодированных мультимедийных компонентов и других параметрах.

Используя эту информацию, клиент DASH выбирает подходящий поток и начинает передачу контента, извлекая сегменты с помощью HTTP-запросов GET. После соответствующей буферизации, учитывающей изменения пропускной способности сети, клиент продолжает выборку последующих сегментов. В зависимости от своих измерений клиент решает, как адаптироваться к доступной полосе пропускания, выбирая сегменты из различных альтернатив (с более низким или более высоким битрейтом) для поддержания подходящего буфера.

# Multimedia Presentation Description

Динамическая потоковая передача по протоколу HTTP требует, чтобы на сервере были доступны различные варианты битрейта мультимедийного контента. Кроме того, контент может состоять из нескольких медиакомпонентов (например, аудио, видео и текст), каждый из которых может обладать различными характеристиками. В MPEG-DASH эти характеристики описываются с помощью MPD, который представляет собой XML-документ. На рисунке 3 показана иерархическая модель данных MPD. MPD состоит из одного или нескольких периодов, где период - это интервал вдоль временной оси.

![Рисунок 3. Структура MPD.](.attachments.55890/image%20%283%29.png)

Каждый период имеет время начала и продолжительность и состоит из одного или нескольких адаптационных наборов. Например, набор адаптаций может содержать различные битрейты видеокомпонента одного и того же мультимедийного контента. Другой набор адаптаций может содержать различные битрейты аудиокомпонента (например, стереозвук более низкого качества и объемный звук более высокого качества) одного и того же мультимедийного контента. Каждый набор адаптаций обычно включает в себя несколько представлений.

Представление - это закодированная альтернатива одного и того же медиакомпонента, отличающегося от других представлений скоростью передачи данных, разрешением, количеством каналов или другими характеристиками. Каждое представление состоит из одного или нескольких сегментов.

Сегменты - это фрагменты медиапотока. Каждый сегмент имеет URL, то есть адресуемое местоположение на сервере, которое может быть загружено с помощью HTTP GET. Чтобы использовать эту модель данных, клиент DASH сначала анализирует XML-документ MPD.

Видеоконференции, стриминговые платформы и онлайн-игры стали неотъемлемой частью нашей жизни. Одним из ключевых инструментов передачи видео и аудио через интернет, является WebRTC (Web Real-Time Communication). Этот открытый стандарт позволяет браузерам и мобильным приложениям передавать медиапотоки друг другу без необходимости установки дополнительных плагинов или приложений.

#### Предназначение и область применения

Протокол WebRTC был создан для того, чтобы обеспечить возможность обмена мультимедийными данными между устройствами в реальном времени через веб-браузеры и был призван заменить Adobe Flash. Он предназначен для передачи потокового видео, аудио и данных между пользователями без задержек даже при нестабильных условиях сети.

Основные области применения WebRTC:

1. Видеозвонки и видеоконференции: Платформы вроде Google Meet, Jitsi, Microsoft Teams используют WebRTC для организации видеокоммуникаций. Отчасти Zoom тоже использует WebRTC, но только веб-версии.
2. Онлайн-игры: Некоторые игры применяют WebRTC для реализации голосовых чатов и видеочатов среди игроков.
3. Стриминговые сервисы: Стриминговые платформы могут использовать WebRTC для прямой трансляции видео и аудио контента от пользователей к зрителям.
4. Удаленная работа и обучение: Приложения для удаленной работы и обучения, такие как Cisco Webex, также активно используют этот протокол.

#### Основные компоненты WebRTC

WebRTC представляет собой набор технологий для передачи медиаданных в реальном времени через браузерные приложения.

1. getUserMedia() – этот метод предоставляет возможность получения доступа к веб-камере и микрофону устройства пользователя, что позволяет захватить видеопотоки и аудиосигналы, а затем передать их другим участникам текущего сеанса связи.
2. RTCPeerConnection – данный компонент отвечает за создание и управление соединением между двумя пользователями, участвующими в общении. Он обеспечивает передачу мультимедийных данных с использованием протоколов ICE (Interactive Connectivity Establishment), STUN (Session Traversal Utilities for NAT) и TURN (Traversal Using Relays around NAT). Эти протоколы помогают установить соединение даже при наличии сетевых ограничений, таких как NAT (Network Address Translation).
3. RTCDataChannel – это механизм, позволяющий передавать любые типы данных между участниками сеанса, включая текстовые сообщения, файлы или координаты игровых объектов. Этот канал работает независимо от аудио- и видеоданных, что делает его удобным инструментом для обмена дополнительной информацией во время сеансов связи.
4. SRTP (Secure Real-time Transport Protocol) – этот протокол шифрует передаваемые данные, обеспечивая высокий уровень безопасности коммуникаций. SRTP защищает информацию от несанкционированного доступа и прослушивания, гарантируя конфиденциальность всех переданных данных.

Каждый из этих компонентов играет важную роль в обеспечении надежной и безопасной передачи медиаконтента в режиме реального времени, делая WebRTC мощным инструментом для создания современных коммуникационных приложений.

#### Технические особенности работы с WebRTC

##### Захват медиа-потоков

Для захвата видео и аудио потоков используется метод getUserMedia():

```javascript
navigator.mediaDevices.getUserMedia({ video: true, audio: true })
.then(stream => {
    // Полученный поток можно передать другому участнику
})
.catch(error => console.error('Ошибка получения доступа к камере/микрофону:', error));
```

Этот код запрашивает у пользователя разрешение на использование камеры и микрофона, после чего возвращает объект stream, содержащий захваченное видео и аудио.

##### Установление соединения

После захвата потока необходимо установить соединение с другим участником. Для этого используются объекты RTCPeerConnection и сигнальные серверы:

```javascript
const peerConnection = new RTCPeerConnection();
peerConnection.addStream(localStream);

// Генерация предложения о соединении
peerConnection.createOffer()
.then(offer => {
    peerConnection.setLocalDescription(offer);
    
    // Отправка предложения другому участнику
    sendToServer(offer);
});
```

После установления соединения между участниками начинается передача медиа-потока.

##### Ограничения и возможности

WebRTC имеет ряд ограничений и особенностей, которые следует учитывать при разработке:

- Зависимость от браузера: Поддержка WebRTC может различаться в разных браузерах. Например, Safari требует использования Secure Context (HTTPS) для работы с WebRTC.
- Ограничения пропускной способности: Качество видео и аудио зависит от скорости интернета и состояния сети. При плохих условиях сеть может адаптироваться, снижая битрейт и разрешение видео.
- Безопасность: Все данные передаются зашифрованными с использованием SRTP, что обеспечивает высокий уровень безопасности.
- Поддержка мобильных устройств: WebRTC поддерживается большинством современных мобильных платформ, включая iOS и Android.

#### Примеры использования WebRTC

WebRTC широко используется в различных продуктах и сервисах:

1. Google Meet: Эти сервисы позволяют пользователям проводить видеоконференции прямо в браузере, используя WebRTC для передачи видео и аудио.
2. Discord: Популярная платформа для геймеров использует WebRTC для голосовых и видеочатов.
3. Jitsi Meet: Открытая платформа для видеоконференций, полностью основанная на WebRTC.
4. Facebook Messenger: Видео- и аудиозвонки в этом мессенджере реализованы с использованием WebRTC.

RTSP (Real Time Streaming Protocol) – это прикладной уровень протокола, используемый для управления потоками мультимедиа в реальном времени. Он был стандартизирован IETF в RFC 2326 и является частью семейства протоколов TCP/IP. Протокол позволяет клиенту инициировать и контролировать передачу данных от сервера к клиенту через команды, такие как PLAY, PAUSE, RECORD, SETUP. Сервер может быть IP-камерой, кодером видеосигнала, видеорегистратором, медиа-сервером или другим устройством, поддерживающим RTSP.

### Основные особенности:

- Транспортный уровень: RTSP использует TCP для передачи команд и контроля состояния сессии. Для передачи самого медиапотока может использоваться как RTP/UDP, так и RTP/TCP. При этом, несмотря на кажущуюся логичность использования UDP для передачи медиаданных, стабильные результаты получаются при работе через TCP.
- Форматы данных: Поддерживает различные форматы видео и аудио потоков, включая H.264, MPEG-4, AAC, MP3 и другие.
- Коды ответов: Как HTTP, RTSP возвращает коды статуса, такие как 200 OK, 404 Not Found и др., что упрощает обработку ошибок.
- В отличие от RTMP, где сервером обычно является принимающая сторона, RTSP сервером является источник потока, клиент может выбирать поток на сервере и управлять его воспроизведением. Поэтому RTMP удобен для отправки потоков на видеоплатформы или CDN (отправитель может не иметь "белого" IP адреса), а RTSP -- для работы с камерами в системах видеонаблюдения и видеопроизводстве.

### Области применения

#### С IP камерами и другими устройствами видеонаблюдения:

RTSP широко используется для получения видеопотоков с камер наблюдения. Например, многие современные IP-камеры поддерживают RTSP для передачи видеоданных. Для работы с камерой можно использовать библиотеку OpenCV в Python:

```python
import cv2

# Подключение к камере по RTSP
cap = cv2.VideoCapture("rtsp://username:password@ip_address:554/cam/realmonitor")

while True:
    ret, frame = cap.read()
    
    if not ret:
        break
        
    # Отображение кадра
    cv2.imshow('Video', frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

#### Видеорегистраторы и кодеры:

Видеорегистраторы часто предоставляют доступ к потокам через RTSP. Кодеры могут передавать потоки на серверы для дальнейшей обработки или записи. Примером использования может служить передача потока на сервер с помощью FFmpeg:

```bash
ffmpeg -re -i input.mp4 -c copy -f rtsp rtsp://localhost/live/mystream
```

Здесь input.mp4 – исходный файл, который передается на локальный RTSP-сервер.

#### Программные микшеры (OBS, VMix):

Программы для создания стриминговых трансляций, такие как OBS Studio и VMix, также могут принимать входные данные через RTSP. Например, в OBS можно добавить источник «Media Source» и указать URL RTSP-потока:

```bash
rtsp://example.com/live/mycamera
```

Но такое подключение вряд ли даст стабильный поток в реальном времени. Чтобы работать с RTSP в реальном времени и стабильно, используйте плагин gstreamer. Вам понадобится умение писать пайплайны gstreamer для корректной работы с потоками.

#### Работа с GStreamer и FFmpeg:

GStreamer – мощный фреймворк для работы с мультимедийными данными, поддерживает прием и отправку RTSP-потоков. Пример воспроизведения RTSP-потока в GStreamer:

```bash
gst-launch-1.0 rtspsrc location="rtsp://example.com/live/mycamera" ! decodebin ! autovideosink
```

Пример захвата и перекодирования RTSP-потока с использованием FFmpeg:

```bash
ffmpeg -i "rtsp://example.com/live/mycamera" -vcodec libx264 -acodec aac output.mp4
```

### Границы применимости:

- Задержка: Хотя RTSP предназначен для реального времени, задержка между передачей и приемом данных может варьироваться в зависимости от сетевых условий и качества оборудования, но в большой степени она зависит от программ, используемых для кодирования и декодирования.
- Безопасность: По умолчанию RTSP передает данные без шифрования, поэтому для обеспечения безопасности рекомендуется использовать RTSP поверх TLS (RTSPS).
- Масштабируемость: При большом количестве клиентов нагрузка на сервер может возрастать, что требует оптимизации и балансировки нагрузки.

#### Применение RTSP

RTSP -- один из самых используемых протоколов в цифровом видео. Хотя бы потому, что его используют камеры видеонаблюдения, а их -- великое множество в мире. И в этом применении он используется самым корректным образом -- это работа в локальной (или корпоративной) сети, закрытой от лишних глаз. Системы видеонаблюдения в английской терминологии называются CCTV (Closed Circuit TeleVision), они не подразумевают вещания в интернет.  
Но у RTSP есть и другое применение, тоже в локальной или распределенной, но связанной через туннели VPN сети: телевизионное видеопроизводство. "Большое" телевидение использует для этого другие технологии (NDI, SMPTE ST 2100), но при работе со сжатыми потоками давно используемый и поддерживаемый множеством устройств и программ протокол RTSP показывает себя хорошо, но нужно уметь работать с ним. Бытующее мнение о том, что потоки RTSP имеют большую задержку или нестабильны, обычно основаны на работе с программами, которые плохо справляются с задачами работы с этими потоками в реальном времени. Например, если вы попытаетесь работать с RTSP в популярном коммерческом видеомикшере VMix, то поток действительно может быть нестабильным. В популярном среди стримеров OBS по умолчанию тоже стабильный результат не получится. Но при грамотном применении gstreamer вместе с OBS мы уже получим вполне стабильный видеокомплекс, работающий на протоколе RTSP, где источниками могут выступать IP камеры и кодеры HDMI/VGA/SDI.

Практика показывает, что при правильном использовании по стабильности работы в локальной сети в реальном времени RTSP показывает лучшие результаты, чем SRT и весьма близок к NDI.

#### Обращение к серверу

Сервером в RTSP выступает источник потока. Клиент (например, плеер) запрашивает доступные потоки и управляет воспроизведением выбранного потока (см. далее "Команды"). Строка подключения к серверу выглядит по-разному в зависимости от реализации сервера в различном оборудовании или ПО. Вот пример для IP камеры видеонаблюдения Hikvision:

```
rtsp://admin:12345@192.168.0.64:554/Streaming/Channels/101
```

- rtsp - тип используемого протокола
- admin - имя учетной записи по умолчанию
- 12345 - пароль используемой учетной записи
- 192.0.0.64 - IP-адрес камеры
- 554 RTSP порт камеры по умолчанию (может быть изменен в настройках)

#### Команды

- DESCRIBE - запрос описания контента
- OPTIONS - запрос поддерживаемых методов
- PLAY - запрос начала вещания контента
- PAUSE - запрос временной остановки вещания
- RECORD - запрос на записывание контента сервером
- REDIRECT - перенаправление на другой контент
- SETUP - запрос установки транспортного механизма для медиа-контента
- ANNOUNCE - обновление данных описания контента
- GET_PARAMETER - запрос указанных параметров у сервера
- SET_PARAMETER - установка параметров сервера
- TEARDOWN - остановка потока и освобождение ресурсов

![Рисунок 1. Работа протокола RTSP.](.attachments.55631/image%20%282%29.png)

#### Сетевая доступность серверов RTSP

Источник должен быть доступен по IP — нужно иметь публичный/глобальный/внешний адрес в сети. То есть, RTSP-камеры бесполезны, если мы не можем "достучаться" до них по сети.

Например, если такая камера находится в локальной сети, снаружи она доступна только если:

- На NAT проброшен порт. Network Address Translation — это механизм в сетях TCP/IP, позволяющий изменять IP адрес в заголовке пакета, проходящего через устройство маршрутизации трафика. Принимая пакет от локального компьютера, маршрутизатор смотрит на IP-адрес назначения. Если это локальный адрес, то пакет пересылается другому локальному компьютеру. Если нет, то пакет надо переслать наружу в интернет.

  Если таких камер несколько, то пробросить придется несколько разных портов.
- Вы подключаетесь в VPN и образуете тоннель в эту локальную сеть.

RTCP (Real-time Transport Control Protocol) – это вспомогательный протокол, который используется совместно с RTP (Real-time Transport Protocol) для управления качеством передачи мультимедийных данных в реальном времени через IP-сети. Он предоставляет механизмы обратной связи между участниками сеанса и позволяет контролировать качество обслуживания (QoS), а также обеспечивает синхронизацию и управление потоками данных.

### Основные функции RTCP:

1. Обратная связь о качестве сервиса: RTCP отправляет отчеты об уровне потерь пакетов, задержках, джиттере и пропускной способности канала. Эти данные позволяют источнику потока корректировать параметры передачи, такие как битрейт, частота кадров и другие.
2. Идентификация участников сессии: В каждом пакете RTCP содержится информация о каждом участнике сеанса, включая идентификатор источника SSRC (Synchronization Source Identifier). Это помогает различать потоки от различных источников в рамках одного сеанса.
3. Синхронизация аудио и видео потоков: RTCP передает информацию о временных метках (timestamps), которая необходима для синхронизации аудиопотоков с видеопотоками при воспроизведении.
4. Мониторинг загрузки сети: С помощью отчетов RTCP можно отслеживать загрузку сети и принимать решения о снижении качества передачи в случае перегрузки.

### Формат сообщений RTCP

Сообщения RTCP состоят из нескольких типов пакетов:

- SR (Sender Report): Отчеты отправителя, содержащие информацию о количестве переданных байтов и пакетов, а также временные метки для синхронизации.
- RR (Receiver Report): Отчеты получателя, включающие статистику о полученных пакетах, таких как количество потерянных пакетов, задержки и джиттер.
- SDES (Source Description): Описания источников, содержащие дополнительную информацию о каждом источнике, такую как имя участника, адрес электронной почты и т.п.
- BYE: Сообщение завершения сеанса, которое отправляется участником при выходе из сеанса.
- APP (Application-specific): Специальный тип пакета, предназначенный для использования приложениями, которые могут добавлять свои собственные сообщения.

### Области применения RTCP

1. Потоковая передача медиа-контента: Видеоконференции, онлайн-трансляции, VoIP-сервисы используют RTCP для мониторинга качества передачи и обеспечения синхронизации потоков (в составе RTSP).
2. Протоколы, использующие RTCP: RTSP (Real Time Streaming Protocol) использует RTCP для контроля за состоянием соединения и предоставления информации о состоянии сервера.
3. VoD (Video on Demand) системы: Здесь RTCP может использоваться для отслеживания состояния сети и управления буферизацией контента.
4. Мультимедиа-серверы: RTCP помогает серверам управлять передачей данных и адаптироваться к изменениям условий сети.

### Примеры задач, решаемых с использованием RTCP:

- Контроль качества связи: RTCP позволяет оценить уровень потерь пакетов, джиттера и задержек, чтобы принять меры по улучшению качества передачи.
- Управление нагрузкой на сеть: На основе статистики RTCP можно регулировать скорость передачи данных, чтобы избежать перегрузок сети.
- Синхронизация потоков: Использование временных меток из SR-пакетов для синхронизации аудио и видео потоков.
- Отслеживание активности участников: RTCP-сообщения помогают определить, кто участвует в сеансе и какие источники данных активны.

### Синхронизация потоков с помощью RTCP

Для того чтобы обеспечить синхронную передачу аудио и видео потоков, RTCP использует механизм временных меток (timestamps). Временные метки содержат информацию о времени создания каждого фрагмента данных, что позволяет воспроизводить их в правильной последовательности.

#### Шаги синхронизации:

1. Отправка Sender Reports (SR): Источник данных периодически отправляет SR-пакеты, которые содержат временные метки для всех передаваемых аудио и видеофрагментов.
2. Получение Receiver Reports (RR): Получатели данных отправляют RR-пакеты, которые включают информацию о полученных временных метках и статусе приема данных.
3. Корректировка временной шкалы: На основании полученной информации источник данных может скорректировать временную шкалу передачи, чтобы обеспечить правильную синхронизацию аудио и видео потоков у получателей.

### Пример использования команд

Рассмотрим простой пример использования команд для отправки и получения RTCP-сообщений.

#### Отправка SR-пакета:

```bash
# Команда для отправки SR-пакета
rtcp_send_sr -s src_ip -p src_port -d dst_ip -P dst_port -i ssrc_id -b bytes_sent -p packets_sent -n ntp_timestamp -r rtp_timestamp
```

Где:

- src_ip — IP-адрес источника,
- src_port — порт источника,
- dst_ip — IP-адрес назначения,
- dst_port — порт назначения,
- ssrc_id — идентификатор источника (SSRC),
- bytes_sent — количество переданных байт,
- packets_sent — количество переданных пакетов,
- ntp_timestamp — временная метка NTP,
- rtp_timestamp — временная метка RTP.

#### Получение RR-пакета:

```bash
# Команда для получения RR-пакета
rtcp_receive_rr -s src_ip -p src_port -d dst_ip -P dst_port -i ssrc_id -l loss_rate -j jitter -d delay
```

Где:

- loss_rate — процент потери пакетов,
- jitter — величина джиттера,
- delay — средняя задержка.

Эти команды являются упрощенными примерами и могут отличаться в зависимости от используемого программного обеспечения и среды выполнения.

Протокол реального времени (RTP) – это сетевой протокол транспортного уровня, предназначенный для передачи мультимедийных данных (видео, аудио) через IP-сети в реальном времени. Он был стандартизирован IETF в RFC 3550 и используется для потоковой передачи медиа в таких приложениях, как VoIP, видеоконференции, интернет-телевидение и другие сервисы, требующие синхронизации и доставки мультимедиа с минимальными задержками.

# Основные характеристики RTP:

- Порт: Обычно использует порты UDP в диапазоне от 16384 до 32767, хотя может работать и с TCP при необходимости.
- Формат пакета: Пакет RTP состоит из заголовка длиной 12 байт и полезной нагрузки, содержащей данные медиа-потока. Заголовок включает: 
  - Версию (2 бита)
  - Бит P (Padding, заполнение, 1 бит)
  - Бит X (Extension, расширение, 1 бит)
  - Бит CC (CSRC Count, количество источников смешанного потока, 4 бита)
  - Бит M (Marker, маркер начала новой единицы медиа-данных, 1 бит)
  - Тип полезного груза (Payload Type, 7 бит)
  - Номер последовательности (Sequence Number, 16 бит)
  - Временная метка (Timestamp, 32 бита)
  - Идентификатор источника синхронной связи (SSRC Identifier, 32 бита)
- Тип полезного груза (PT): Поле Payload Type определяет формат кодирования медиа-данных. Например, PT=0 означает использование формата PCMU (G.711 μ-law), а PT=8 указывает на использование формата PCMA (G.711 A-law).
- Синхронизация: Для синхронизации медиа-потоков используются временные метки (timestamps), которые позволяют ресиверу восстанавливать исходный временной порядок кадров даже после их возможной переупорядочивания в сети. Подробнее о синхронизации -- в конце этой статьи.
- Потеря пакетов: Потери пакетов могут происходить в сетях, но благодаря использованию временных меток и номеров последовательностей приемники могут корректно обрабатывать пропущенные пакеты и выполнять интерполяцию или маскировку потерь.

# Области применения RTP

## Видеоконференцсвязь и VoIP

В системах видеоконференций и телефонии RTP используется для передачи аудио- и видеоинформации между участниками. Например, в системе SIP (Session Initiation Protocol) сигналы управления вызовами передаются через SIP, а сами медиа-потоки идут через RTP поверх UDP.

## Интернет-телевидение (IPTV)

Для трансляции телевизионных каналов через интернет часто используют RTP в сочетании с RTCP (Real-time Transport Control Protocol) для контроля качества передачи.

## Мультимедийный контент в мобильных устройствах

RTP широко применяется в мобильных платформах для передачи голосовых сообщений, видео-звонков и потокового контента.

# Программная поддержка RTP

Программы и библиотеки, поддерживающие создание, коммутацию, воспроизведение и запись потоков RTP:

- FFmpeg: Популярная библиотека для работы с медиа-контентом, включая кодирование/декодирование, трансляцию и запись RTP-потоков.
- GStreamer: Фреймворк для создания приложений обработки мультимедиа, который поддерживает работу с RTP.
- libSRTP: Библиотека для защиты RTP-потоков с использованием SRTP (Secure Real-time Transport Protocol).
- VLC Media Player: Поддерживает передачу и приём RTP-потоков, а также их запись.
- WebRTC: Технология для веб-браузеров, которая позволяет передавать аудио и видео через RTP, используя механизмы WebSocket и ICE для установления соединений.

# Работа в сети

RTP обычно работает поверх UDP, поскольку этот транспортный протокол обеспечивает меньшую задержку и простоту реализации, чем TCP. Однако, при передаче через интернет возможны проблемы с маршрутизацией и пропускной способностью. Поэтому часто применяются дополнительные технологии:

- NAT\*\* Traversal\*\*: NAT-пробросы и механизмы вроде STUN/TURN помогают обходить ограничения межсетевых экранов и устройств NAT.
- QoS\*\* (Quality of Service)\*\*: Механизмы обеспечения качества обслуживания, такие как дифференциация сервисов (DiffServ) и управление очередями (CBWFQ), помогают улучшить качество передачи мультимедиа потоков.
- Jitter Buffers: Буферы джиттера на стороне получателя сглаживают неравномерность поступления пакетов, обеспечивая плавное воспроизведение.

# Взаимодействие с другими протоколами

## RTSP (Real Time Streaming Protocol)

Используется для управления потоковым контентом, таким как начало, пауза, остановка и перемещение внутри медиафайла. RTP отвечает за доставку самого медиа-потока, тогда как RTSP управляет сессией.

## SMPTE ST 2110

Стандарт для профессиональной вещательной индустрии, который описывает методы передачи несжатых видео- и аудиопотоков по IP-сетям. В этом стандарте RTP используется для передачи медиа-данных, обеспечивая высокую точность синхронизации и низкое время задержки.

## RTMP (Real-Time Messaging Protocol)

Применяется для передачи видео и аудио в Adobe Flash Player и некоторых других платформах. Хотя RTMP сам по себе является транспортным протоколом, он может использовать RTP для улучшения доставки мультимедиа.

Таким образом, RTP играет ключевую роль в современных мультимедийных технологиях, предоставляя гибкий механизм для передачи данных в реальном времени, и поддерживается множеством библиотек и фреймворков, облегчающих разработку мультимедийных приложений.

# Синхронизация

Поскольку в нестабильной сетевой среде синхронизация видеопотоков -- это серьезное испытание для видеопроизводственного комплекса, рассмотрим эту тему подробнее.

Синхронизация нескольких видеопотоков RTP в сети осуществляется несколькими ключевыми методами, которые обеспечивают правильное временное согласование между различными источниками данных. Вот основные подходы к синхронизации:

## 1. Использование временных меток (timestamp)

Каждый пакет RTP содержит временную метку (timestamp), которая отражает момент времени, когда данный фрагмент медиа-данных был захвачен источником. Эта метка помогает приемнику восстановить правильный временной порядок кадров независимо от порядка получения пакетов в сети.

Пример использования временных меток:

- Источник передает кадры видео с интервалом 30 мс, начиная с временной метки 0.
- Первый кадр имеет временную метку 0, второй — 30000 (30 мс × 1000 = 30 000 мкс), третий — 60000 и так далее.
- Приемник восстанавливает последовательность кадров согласно этим меткам, даже если пакеты приходят в другом порядке.

## 2. Синхронизация по идентификаторам SSRC (Synchronization Source Identifier)

Каждому источнику данных присваивается уникальный 32-битный идентификатор SSRC, который указывается в заголовке каждого RTP-пакета. Этот идентификатор позволяет приемникам различать разные источники и правильно группировать входящие пакеты по соответствующим потокам.

Пример использования SSRC:

- Один источник передает видео с SSRC = 12345678, другой — с SSRC = 87654321.
- Приемник может легко разделить эти два потока и обработать каждый из них отдельно.

## 3. Протокол управления передачей в реальном времени (RTCP)

RTCP (Real-time Transport Control Protocol) дополняет RTP и предоставляет информацию о качестве передачи, такую как потеря пакетов, задержка и джиттер. RTCP-сообщения отправляются периодически всеми участниками сессии и содержат сведения об отправленных и полученных пакетах.

Основные функции RTCP:

- Отправитель сообщает о количестве отправленных пакетов и байтов.
- Получатель отправляет отчеты о потерянных пакетах и задержках.
- Эти данные помогают адаптироваться к изменениям в сети и поддерживать синхронизацию потоков.

## 4. Jitter buffers (буферизация джиттера)

Буферы джиттера на стороне получателя сглаживают неравномерность поступления пакетов, вызванную задержкой и вариацией задержки (джиттером) в сети. Джиттер-буфер накапливает пакеты в течение определенного времени, чтобы обеспечить плавное воспроизведение без рывков и прерываний.

Пример работы jitter buffer:

- Если первый пакет приходит с задержкой 50 мс, а следующий — через 20 мс, буфер будет удерживать оба пакета некоторое время, прежде чем передать их на воспроизведение, чтобы избежать скачков в воспроизведении.

## 5. Межпоточная синхронизация (Inter-stream synchronization)

Когда необходимо синхронизировать несколько потоков (например, видео и аудио), используется межпоточная синхронизация. Она основана на сопоставлении временных меток разных потоков. Аудио и видео могут передаваться отдельными RTP-потоками, но приемник должен учитывать временные метки обоих потоков, чтобы воспроизвести их одновременно.

Пример межпоточной синхронизации:

- Видео и аудио имеют одинаковые временные метки для одного и того же момента времени.
- Приемник сравнивает метки и воспроизводит соответствующие фрагменты видео и аудио вместе.

## Введение

Secure Reliable Transport (SRT) — протокол, разработанный компанией Haivision в 2012 году. Протокол работает на базе UDT (UDP-based Data Transfer Protocol) и технологии восстановления пакетов ARQ.

UDT работает поверх транспортного протокола UDP, как показано в таблице 1. В текущей 4й версии протокола UDT есть система управления потоком, система контроля целостности данных и реализован механизм работы с клиентами за NAT:S

Таблица 1 – Расположение протокола UDT в протоколе TCP/IP

| 4 – Прикладной уровень   | UDT                                                           |
|--------------------------|---------------------------------------------------------------|
| 3 – Транспортный уровень | UDP                                                           |
| 2 – Сетевой уровень      | Для TCP/IP – это IP                                           |
| 1 – Канальный уровень    | Физическая среда (LAN/WiFi) и принципы кодирования информации |

Протокол устанавливает два UDP соединения (рисунок 1). Одно — для передачи данных получателю, второе — для передачи контрольной информации отправителю:

![Рисунок 1.](.attachments.55755/image.png)

Рисунок 1 – UDP-соединение между клиентом и сервером

В отличие от стандартного UDT, в SRT полностью переписана архитектура переотправки пакетов, чтобы реагировать сразу же, как только пакет потерян. Такая технология является вариацией selective repeat/reject ARQ. Selective Repeat (SR) и Selective Reject (SREJ) - это две разновидности протокола автоматического запроса повторной передачи (ARQ), используемого для обеспечения надежной передачи данных по ненадежной сети. Оба протокола используют метод скользящего окна для отслеживания отправленных и принятых пакетов данных. Принцип "скользящего окна" (sliding window), заключается в том, что каждая сторона может отправлять максимум столько байт, сколько отправитель указал в поле "размер окна" заголовка TCP-пакета, подтверждающего получение предыдущих данных.

## Соединение

На приведенной ниже диаграмме представлен обмен данными  между двумя одноранговыми узлами (рисунок 2):

![Рисунок 2 – Диаграмма рукопожатия.](.attachments.55755/image%20%282%29.png)

## Начало рукопожатия

Обмен файлами cookie MD5 – это функция, предназначенная для защиты потоков от DDoS-атак. DDoS-атака – это способ заблокировать работу сайта путем подачи большого количества запросов, превышающих пропускную способность сети. Для предотвращения этого SRT использует обмен cookie-файлами, над которыми выполняется функция хэширования с помощью алгоритма MD5.

Cookie-файл — небольшой фрагмент данных, отправленный веб-сервером и хранимый на компьютере пользователя. Веб-клиент (обычно веб-браузер) всякий раз при попытке открыть страницу соответствующего сайта пересылает этот фрагмент данных веб-серверу в составе запроса. Требуя от источника выполнения этой операции, обмен файлами cookie MD5 помогает предотвратить получение запросов от злоумышленников.

## Обмен возможностями

На данном этапе между сервером и клиентом происходит обмен информацией: размер буфера, информация о шифровании, версия рукопожатия (в SRT реализовано два механизма установления связи), идентификатор потока.

## Шифрование

SRT поддерживает сквозное шифрование с помощью AES. Сквозное шифрование — это когда сообщения шифруются на вашем устройстве и расшифровываются только на конечном устройстве. Весь путь от отправителя до получателя сообщение преодолевает в зашифрованном виде, поэтому его никто не может прочитать, кроме вашего собеседника.

Advanced Encryption Standard (AES) — симметричный алгоритм блочного шифрования. Основу алгоритма составляют замены, подстановки и линейные преобразования, каждое из которых выполняется блоками по 128 бит (цифры со значениями от 0 или 1), являющиеся основой структуры входных и выходных данных, поэтому он и носит называние блочного шифра. Повторение операций происходит неоднократно и в процессе каждой итерации (раунда) вычисляется уникальный ключ на основе ключа шифрования и встраивается в дальнейшие вычисления. Надежность шифрования обеспечивается тем, что изменение даже одного блока влечет за собой изменение последующих блоков и полное изменение конечных данных на выходе.

## Только точка-точка

В настоящее время невозможно создать зашифрованный поток SRT через какое-либо промежуточное устройство (например, шлюз). Это связано с тем, что ключи, используемые для шифрования, обмениваются во время первоначального рукопожатия между отправителем и получателем. Это тип соединения "точка-точка", что означает, что обмен ключами осуществляется только между двумя конечными точками и не может быть перехвачен или изменен каким-либо промежуточным устройством. Если бы в канал связи было введено промежуточное устройство, у него не было бы ключей шифрования, которыми обменивались во время первоначального рукопожатия. В результате промежуточное устройство не смогло бы расшифровать данные и переслать их на следующий переход по каналу связи. Это потребовало бы установления другого сеанса между промежуточным устройством и конечной точкой, что потребовало бы нового рукопожатия и новых ключей шифрования.

С точки зрения возможности маршрутизации зашифрованных потоков через промежуточные устройства, существует разница между RTSP и SRT. Потоки RTSP могут маршрутизироваться через промежуточные устройства при условии, что устройства способны должным образом обрабатывать пакеты RTP (Real-time Transport Protocol) и RTCP (Real-time Transport Control Protocol).

## Восстановление соединения

Как только поток запущен, протокол устанавливает соединение с регулярным подтверждением между узлами. По мере необходимости для поддержания соединения осуществляется обмен пакетами keepalive. При перерывах в работе сети продолжительностью менее 1 секунды соединение SRT может быть  восстановлено автоматически. Устройства будут пытаться повторно подключиться и повторять попытки до тех пор, пока пользователь не удалит соединение из своей конфигурации.

Шифрует ли SRT поток на пакетном уровне? Нет, шифрование происходит на уровне полезной нагрузки. Шифруются только те данные, которые передаются. Вся управляющая информация отправляется в открытом виде (это позволяет избежать повторяющихся шаблонов, которые ослабили бы шифрование). Обратите внимание, что шифрование не оказывают влияние на сам поток SRT – оно создает нагрузку на процессоры отправителя и получателя, которая пропорциональна количеству потоков и  их битрейтам.

Задержка

Существует временная задержка, связанная с отправкой пакетов по (обычно непредсказуемой) сети. Из-за этой задержки устройству-источнику SRT приходится помещать пакеты, которые оно отправляет, в очередь в буфере, чтобы убедиться, что они доступны для передачи и повторной передачи. С другой стороны, устройство назначения SRT должно поддерживать свой собственный буфер для хранения входящих пакетов (которые могут поступать в любом порядке), чтобы убедиться, что у него есть нужные пакеты в нужной последовательности для декодирования и воспроизведения. Задержка SRT - это фиксированное значение (от 80 до 8000 мс), не меньшее максимального размера буфера, доступный для управления пакетами SRT. Время задержки равно сумме используемого буфера (не обязательно максимального), пингов, времени кодирования и декодирования.

## Буфер задержки

Задержка – это время, определяющее насколько позже пришли пакеты после отправки. На отправителя задержка почти не влияет, т.к. она важна только если ACK-сообщение не дошло или потерялось. Со стороны получателя задержку можно представить как окно, которое скользит с течением времени, в течение которого выполняется ряд действий (рисунок 3):

![Рисунок 3 – Схематичное представление скользящего окна.](.attachments.55755/image%20%283%29.png)

Рассмотрим буфер получателя, в котором хранится серия пакетов. Допустим, мы определили задержку так, что она охватывает период, эквивалентный передаче шести пакетов. Возможность восстановления пакетов в пределах этого окна зависит от времени между пересылками (рисунок 4). С помощью параметра RTT окно задержки определяет, что подлежит восстановлению или сколько раз пакет может быть восстановлен. RTT — это время, затраченное на отправку сигнала, плюс время, которое требуется для подтверждения, что сигнал был получен. Теперь давайте посмотрим, что происходит, когда пакет не получен (пакет №4 в этом примере).

![Рисунок 4 – Отправка пакетов с учетом параметра RTT.](.attachments.55755/image%20%284%29.png)

Поскольку окно задержки перемещается, предполагается, что этот пакет готов к передаче, но если он недоступен, то он оказывается пропущен (рисунок 5). Он не может быть восстановлен, поэтому будет удален из списка утерянных.

![Рисунок 5 – Визуализация пропуска пакета №4.](.attachments.55755/image%20%285%29.png)

Скользящее окно можно рассматривать как зону, в которой приемник может восстанавливать (большинство) пакетов.

С другой стороны, буфер отправителя также имеет такое окно. С течением времени самые старые пакеты, которые выходят за пределы окна задержки, больше не подлежат восстановлению — даже если их каким-то образом отправят, они прибудут слишком поздно, чтобы быть успешно обработанными получателем.

Если скользящее окно задержки переместилось за пределы пакетов, которые еще не были доставлены (получение не было подтверждено), отправлять их нет смысла. Таким образом, эти пакеты могут быть удалены из буфера отправки.

Режимы caller, listener и rendezvous Как и его предшественник UDT, SRT поддерживает две конфигурации подключения:

1. Caller-Listener, где одна сторона ждёт, пока другая инициирует соединение. Вызывающая сторона (caller) - это клиент, которому потребуется адрес получателя (listener), и он попытается подключиться при инициализации.
2. Rendezvous, когда обе стороны пытаются установить соединение.

| Режим      | Что делает                                                                                                                                                   | Когда использовать                                                                                                                                                                                                                                                                                                                                                             |
|------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Caller     | Устанавливает источник или приемник в качестве инициатора подключения SRT. Источник должен знать публичный IP-адреси номер порта приемника.                  | Чтобы инициировать потоковую передачу "точка-точка":на источнике или приемнике, которые находятся за брандмауэром:  может потребоваться, чтобы сетевой администратор настроил параметры брандмауэрана источнике или приемнике, которые не находятся за брандмауэромна источнике или приемнике с динамическим IP-адресом (например, портативный кодировщик, использующий DHCP). |
| Listener   | Настраивает устройство на ожидание запроса на открытие SRT-соединения                                                                                        | Чтобы принять соединение "точка-точка", инициированное вызывающим абонентом:на источнике или приемнике, которые находятся за брандмауэром, у которого вы можете открыть порт.на источнике или приемнике, которые не находятся за брандмауэром и не подключены к Интернету.когда вы знаете, что другое устройство инициирует сеанс                                              |
| Rendezvous | Позволяет двум устройствам согласовывать подключение SRT по взаимно согласованному порту. И источник, и пункт назначения должны находиться в режиме рандеву. | Для установления соединения "точка-точка", когда одно или оба устройства находятся за брандмауэрами. Как только на брандмауэре установлены определенные настройки, SRT-соединение может быть инициированобез дальнейшего вмешательства сетевогоадминистратора. Это работает это при проброшенных портах и наличии белых IP при работе через фаерволы и интернет                |

## SRT и Firewall

Часто при передаче потока через Интернет, данные должны проходить через брандмауэр со стороны источника или  на стороне получателя или на обоих концах сразу. Чтобы разрешить это, сетевому администратору придется настроить определенные параметры брандмауэра: (NAT) и фильтрацию пакетов. Настройки будут отличаться в зависимости от того, в каком режиме (caller, listener, rendezvous) находятся устройства.

### Пример 1: Простой поток SRT

Рассмотрим простой пример, когда устройство-источник пытается передавать поток через Интернет в пункт назначения, находящийся за брандмауэром. Если мы рассмотрим случай, когда исходное устройство SRT находится в режиме вызывающего (caller), а устройство назначения - в режиме прослушивателя (listener), то для успешного завершения процесса установления связи должны быть выполнены определенные условия:

![Рисунок 6.](.attachments.55755/image%20%286%29.png)

* Исходное устройство SRT знает общедоступный IP-адрес брандмауэра и номер порта, который “прослушивает” устройство назначения.
* Брандмауэр должен разрешать доступ из Интернета определенному порту назначения, используемому SRT.
* Брандмауэр должен разрешать двунаправленный UDP-трафик.
* На брандмауэре должна быть включена переадресация портов, чтобы данные дошли до устройства назначения.
* Фильтрация пакетов должна быть отключена (чтобы разрешить прохождение пакетов SRT).

### Пример 2: Поток SRT через брандмауэры

![Рисунок 7.](.attachments.55755/image%20%287%29.png)

Рассмотрим более сложный пример, когда устройство-источник SRT за брандмауэром пытается передавать поток через Интернет к устройству назначения, находящемуся также за брандмауэром. Если мы рассмотрим случай, когда источник потока SRT находится в режиме вызывающего (caller), а устройство назначения - в режиме прослушивателя (listener), то должны быть выполнены определенные условия:

* Исходное устройство SRT знает общедоступный IP-адрес брандмауэра и номер порта, который “прослушивает” устройство назначения.
* Оба брандмауэра должны разрешать двунаправленный UDP-трафик.
* Переадресация портов (NAT) должна быть настроена на обоих брандмауэрах, чтобы обеспечить передачу данных между исходным и конечным устройствами.
* Фильтрация пакетов должна быть настроена на обоих брандмауэрах.

Получение потока

Для демонстрации получения SRT-потока воспользуемся VLC и кодером, поддерживающим данный протокол. На странице веб-интерфейса кодера нужно найти раздел с SRT. Далее включим эту функцию, выберем режим listener и в поле IP запишем свой локальный адрес. В режиме “слушателя” нам не надо указывать IP-адрес приемника, поскольку сам приемник будет “звонить” на наш адрес. Остальные поля без надобности заполнять не стоит.

![Рисунок 8.](.attachments.55755/image%20%288%29.png)

В VLC откроем сетевой ресурс:

![Рисунок 9.](.attachments.55755/image%20%289%29.png)

И вставим ссылку (srt://172.18.191.51:9001?mode=caller) с указанием режима соединения. Данный локальный IP-адрес и порт (заранее прописанный в веб-интерфейсе) принадлежит кодеру. После этого должен появиться поток ("No signal" -- это видеопоток от кодера, когда на него не подается входной HDMI сигнал).:

### Протокол NDI: Техническая сущность, применение и спецификация

Протокол NDI (Network Device Interface) — это сетевой протокол, разработанный компанией NewTek для передачи высококачественного видео и аудио в реальном времени через IP-сети. Он широко используется в сфере видеопроизводства и вещания благодаря своей гибкости, низкой задержке и высокой производительности.

---

#### Техническая сущность протокола NDI

NDI предоставляет возможность передавать видео с высоким разрешением и с высоким битрейтом через стандартные Ethernet-сети без необходимости использования дорогостоящего специализированного оборудования.

1. Кодирование и компрессия:
   - NDI использует собственный кодек для сжатия видео, обеспечивающий баланс между качеством изображения и сжатием. Этот кодек оптимизирован для работы с высокими разрешениями (4K), и способен поддерживать видеопотоки с высокой частотой кадров (до 120 кадров в секунду). Алгоритмы сжатия включают адаптивную обработку данных, что позволяет минимизировать задержку (до 16 мс) при сохранении высокого уровня детализации и сжатия видео. Это позволяет добиться компромисса между качеством изображения и эффективным использованием пропускной способности сети.
2. Сетевая архитектура:
   - NDI работает поверх стандартного сетевого стека TCP/IP, используя преимущественно TCP для передачи данных, обеспечивая надежность и порядок доставки потоков, а также UDP для некоторых задач, требующих минимальной задержки, таких как синхронизация потоков., что обеспечивает совместимость с большинством сетевых инфраструктур.
   - Протокол поддерживает как одноадресную (unicast), так и многоадресную (multicast) передачу данных, что позволяет оптимизировать использование сети в зависимости от конкретного сценария.
3. Автоматическое обнаружение устройств:
   - Устройства, поддерживающие NDI, автоматически обнаруживаются в локальной сети с использованием технологий mDNS (Multicast DNS) и Bonjour.
4. Синхронизация:
   - NDI обеспечивает точную синхронизацию видео и аудио потоков, что критично для профессионального использования.

---

#### Версии NDI: Сравнительный анализ

Существует несколько версий NDI, каждая из которых оптимизирована для различных сценариев использования. Основные версии:

| Версия   | Кодек        | Пропускная способность                        | Основные особенности                                    |
|----------|--------------|-----------------------------------------------|---------------------------------------------------------|
| NDI      | SpeedHQ2     | 100-250 Мбит/с, 4:2:2                         | Высокое качество, низкая задержка.                      |
| NDI\|HX  | H.264        | 9–30 Мбит/с, 4:2:0                            | Передача сжатых потоков (есть задержка)                 |
| NDI\|HX2 | H.265        | 6-21 Мбит/с, 4:2:0                            | HX с более низкой задержкой и оптимизированным кодеком. |
| NDI\|HX3 | H.264, H.265 | 26-110 Мбит/с, 4:2:0<br />20-84 Мбит/с, 4:2:0 | Задержка еще меньше                                     |

Ключевые различия:

- NDI|HX и NDI|HX2 используют более высокий уровень сжатия, что снижает требования к сети. Это полезно в ситуациях, где сеть ограничена по пропускной способности, например, в беспроводных или удаленных системах.
- NDI|HX2 отличается улучшенной производительностью, обеспечивая более низкую задержку и улучшенное качество по сравнению с NDI|HX.
- NDI|HX3 уменьшена задержка, несмотря на сжатие. Оборудование, заявляющее поддержку этой версии протокола, сертифицируется у NewTec

---

#### Применение NDI

Протокол NDI нашел применение в различных сферах, включая:

1. Видеопроизводство и вещание:
   - Используется для интеграции камер, видеомикшеров, графических систем и других устройств в единое решение.
   - Позволяет отказаться от традиционных SDI-кабелей в пользу стандартной Ethernet-сети.
2. Образование и конференции:
   - Видеолекции и трансляции могут легко интегрироваться с системами видеоконференций (например, Zoom, Microsoft Teams, Skype, Cisco Webex),  а также с программными видеомикшерами (VMix, OBS Studio).
   - Поддержка NDI в программных приложениях (например, OBS Studio) позволяет создавать студийные съемочные комплексы без создания отдельной сетевой инфраструктуры и с использованием обычных компьютеров.
3. Виртуальные студии и AR/VR:
   - NDI позволяет передавать видео для обработки в реальном времени в виртуальных или дополненных средах.
4. Игровая индустрия и киберспорт:
   - Используется для трансляции игрового процесса с минимальной задержкой.
   - Позволяет интегрировать графику и видеопотоки с высокой степенью надежности.

---

#### Спецификация NDI

1. Поддерживаемые форматы видео:
   - SD, HD, 4K и выше.
   - Поддержка различных частот кадров (например, 30, 60, 120 fps).
2. Пропускная способность:
   - Видео потоки NDI требуют порядка 125 Мбит/с для 1080p60 и около 250 Мбит/с для 4K60.
   - Протокол также поддерживает NDI|HX (High Efficiency Mode), использующий более высокую степень сжатия и снижающий требования к пропускной способности до 10–20 Мбит/с.
3. Совместимость:
   - NDI поддерживается на различных платформах, включая Windows, macOS и Linux, а также на одноплатных компьютерах, таких как Orange Pi, Raspberry Pi и NVIDIA Jetson Nano, благодаря доступности SDK и совместимости с ARM-архитектурой..
   - Существуют программные и аппаратные решения с поддержкой NDI, такие как TriCaster, OBS Studio, VLC Media Player.
4. API и SDK:
   - NewTek предоставляет бесплатный SDK, который позволяет интегрировать поддержку NDI в программные приложения.
   - С помощью API разработчики могут создавать собственные решения для обработки, передачи и записи видео.

---

# Работа с NDI

Для NDI требуется локальная сеть, которая представляет собой сеть компьютеров, подключенных к сетевому оборудованию. NDI может использовать стандартное сетевое оборудование, чтобы позволить вам отправлять и получать видео из различных источников в вашей сети.

Для начала необходимо скачать инструменты NDI (NDI Tools), которые используются для отправки и получения видео по стандартной локальной сети. Инструменты NDI позволяют любому начать использовать IP-видео и легко обойти старые технологии, которые раньше требовали дорогостоящих карт видеозахвата и коммутаторов.

Все программное и аппаратное обеспечение, совместимое с NDI, становится частью более широкой экосистемы, где все источники видны и доступны другим компьютерам в сети.

## NDI Tools

### Studio Monitor

Это приложение может быстро отображать все доступные для обнаружения источники NDI в вашей локальной сети. Studio Monitor обладает длинным списком функций.

> Вы можете просматривать любой источник NDI, и если источником является PTZ-камера, вы можете управлять PTZ-камерой с помощью экранного набора управления. {.is-info}

Студийный монитор, подключенный к PTZ-камере, покажет элементы управления PTZ-камерой.

Студийный монитор NDI также может управляться удаленно с помощью веб-сервера. IP-адрес этого веб-сервера можно найти в области настроек приложений. Как только вы введете этот IP-адрес в веб-браузер в той же локальной сети, вы сможете получить доступ к элементу управления Studio Monitor.

### Screen Capture

NDI Screen Capture может захватывать экран компьютера, на котором он установлен, и делать его доступным в качестве источника видео NDI. NDI Screen Capture поддерживает захват нескольких мониторов, а также включает в себя возможность захвата веб-камеры. Как только на компьютере будет запущен NDI Screen Capture, вы получите уведомление со словами: “Ваш экран теперь доступен в качестве источника NDI”. Вы также увидите значок NDI Screen Capture в системной области. Отсюда вы можете открыть настройки приложения, которые включают частоту кадров, настройки захвата, источник звука, источник видео с веб-камеры, источник звука с веб-камеры и включить управление KVM. Большинство из этих функций не требуют пояснений, но управление KVM - это интересная функция, которую вы можете использовать для удаленного управления компьютером с помощью клавиатуры и мыши. После включения приложение NDI Studio Monitor позволит вам удаленно управлять любым компьютером с включенной функцией управления KVM NDI Screen Capture.

### Screen Capture HX

NDI Screen Capture HX - это высокоэффективная версия NDI Screen Capture, которая обеспечивает новые уровни управления для оптимизации пропускной способности и аппаратного ускорения графического процессора (GPU). Когда приложение будет открыто, вы получите уведомление о том, что ваш экран становится доступным в сети в качестве источника NDI. NDI Screen Capture HX включает в себя четыре варианта уровней пропускной способности. Вы можете выбрать между ультра, высоким, средним и низким. NDI Screen Capture HX использует преимущества новой технологии сжатия видео с видеокарты, которая может поддерживать разрешение до 4K при удивительно низких требованиях к пропускной способности.

### Access Manager

NDI Access Manager позволяет администраторам ограничивать доступ к видеоисточникам NDI в своей сети. Приложение позволяет пользователям управлять видимостью и доступностью источников NDI для определенных компьютеров в сети. NDI Access Manager может легко группировать источники NDI вместе, чтобы сделать их общедоступными или доступными для частного обнаружения.

### Auto Direct

NDI Audio Direct - это инструмент, предназначенный для интеграции аудиоисточников NDI в программное обеспечение Digital Audio Workstation (DAW). Программные решения DAW используются для записи, редактирования и продюсирования аудио. Инструмент NDI Audio Direct использует два плагина, предназначенных для передачи звука в программные решения DAW и из них. NDI Audio Direct совместим с любым DAW, поддерживающим аудио-плагины VST3 или LV2.

### VLC Plugin

VLC - это бесплатный видеоплеер с открытым исходным кодом. Широкое внедрение VLC пользователями привело к тому, что NDI поддержала систему с помощью бесплатного плагина. Плагин обеспечивает прямой доступ к источникам видео NDI с помощью совместимого программного обеспечения VLC без необходимости перекодирования.

### HX Driver

Драйвер NDI|HX® требуется для подключения к определенным устройствам NDI| HX®, таким как PTZ-камеры или кодеры. Новым устройствам, поддерживающим NDIv4 или более позднюю версию, этот драйвер не потребуется.

## Студия

### Работа с кодером

NDI кодеры обычно используются для захвата изображения с компьютера (например, презентации докладчика на конференции), но также позволяют подключать классические SDI/HDMI видеокамеры по сети.

Необходимо ли подключить кодер с помощью HDMI-кабеля к компьютеру (камере, другому источнику HDMI сигнала).

![Рисунок 1. Подключение кодера HDMI-NDI](.attachments.55854/image.png)

Некоторые кодеры NDI имеют индикацию Tally. Индикатор загорается, когда поток с кодера выбран в видеомикшере в предпросмотр или в программу (соответственно зеленым и красным цветом). В RTSP кодерах таких возможностей не предусмотрено, т.к. протокол для этого не предназначен.

### Управление PTZ камерой через NDI

1. Установите NDI Tools (на студийных компьютерах уже есть). Откройте Studio Monitor.
2. Откройте меню нажав на иконку в левом верхнем углу или щелкнув правой кнопкой мыши в любом месте экрана. Выберите вашу камеру.

   ![Рисунок 2.](.attachments.55854/image%20%282%29.png)
3. Снова откройте меню, перейдите в раздел Settings, далее перейдите в раздел PTZ Settings, где необходимо нажать Show PTZ Control.

   ![Рисунок 3.](.attachments.55854/image%20%283%29.png)
4. На экране должна появиться навигационная панель. Движение камеры происходит с помощью зажатой левой кнопки мыши и движения курсора внутри круга. Прямо справа от круга находится панелька для приближения и отдаления изображения.

   ![Рисунок 4.](.attachments.55854/image%20%284%29.png)

Видео пример работы.

## Работа в OBS

### Получаем изображение с камеры

1. Установите NDI Tools (на студийных компьютерах уже есть).
2. Подключите кодер к камере как написано выше.
3. В OBS создайте новую сцену или выберите уже существующую.
4. Создайте новый источник NDI Source.

   ![Рисунок 5.](.attachments.55854/image%20%285%29.png)
5. Задайте имя источнику.

   ![Рисунок 6.](.attachments.55854/image%20%286%29.png)
6. Во вкладке Source name выберите свой кодер.

   ![Рисунок 7.](.attachments.55854/image%20%287%29.png)
7. Получите изображение.

   ![Рисунок 8.](.attachments.55854/image%20%288%29.png)

### Получаем изображение с компьютера

1. Установите NDI Tools (на студийных компьютерах уже есть).
2. Подключите кодер к компьютеру, с которого хотите получить изображение.
3. На компьютере, с которого хотите получить изображение, включите screen capture.
4. В OBS создайте новую сцену или выберите уже существующую.
5. Создайте новый источник NDI Source.

   ![Рисунок 9.](.attachments.55854/image%20%289%29.png)
6. Задайте имя источнику.

   ![Рисунок 10.](.attachments.55854/image%20%2810%29.png)
7. Во вкладке Source name выберите свой компьютер.

   ![Рисунок 11.](.attachments.55854/image%20%2811%29.png)
8. Получите изображение.

   ![Рисунок 12.](.attachments.55854/image%20%2812%29.png)

# Источники

1. Cтатья из Wiki МИЭМ
2. GigaChat

# Полезные ссылки:

(все статьи на английском языке)

- Что такое NDI?
- История NDI
- Работа с сетью для NDI
- Какая должна быть пропускная способность сети, чтобы работать  с NDI?
- Видео дисплеи, использующие NDI
- Как работать с NDI в OBS?
- Как работать с NDI  в vMix?
- Почему важно научится работать с IP видео?
- Как пользоваться NDI камерами?
- Как использовать NDI для создания графики?
- Как использовать NDI вместе с Wi-fi?
- Как использовать NDI Studio Monitor и NDI Screen Capture?
- NDI - как не запутаться в стандартах

### Глава 6. Протокол SMPTE ST 2110

SMPTE ST 2110 — это семейство стандартов, разработанное Обществом инженеров кино и телевидения (Society of Motion Picture and Television Engineers, SMPTE), которое определяет методы передачи несжатых видео- и аудиосигналов по IP-сетям. Этот стандарт был создан для перехода с "сигнальной" архитектуры SDI на IP-ориентированную архитектуру, это позволяет реализовать современные сетевые решения с повышенной гибкостью и масштабируемостью.

#### Технические характеристики SMPTE ST 2110

SMPTE ST 2110 состоит из следующих основных документов:

- ST 2110-10: Спецификация транспортировки несжатого видео по IP-сетям.
- ST 2110-20: Передача несжатого аудио.
- ST 2110-21: Синхронизация временных меток с использованием Precision Time Protocol (PTP).
- ST 2110-30: Транспортировка метаданных, связанных с видео и аудио.
- ST 2110-40: Управление событиями и состоянием системы.

Основные принципы работы SMPTE ST 2110:

1. Разделение видео, аудио и метаданных на независимые потоки RTP (Real-time Transport Protocol). Это позволяет обрабатывать и маршрутизировать различные типы данных отдельно.
2. Использование PTP (IEEE 1588) для синхронизации всех устройств в сети. Точность синхронизации достигает микросекунд, что критично для корректного воспроизведения медиаконтента.
3. Поддержка различных форматов видео и аудио. Стандарт поддерживает разрешение до 2160p (UHD) с частотой кадров до 120 Гц, а также многоканальный звук (до 16 каналов).
4. Высокая пропускная способность. Несжатые данные требуют значительных ресурсов сети. Например, для передачи видео 1080p60 с глубиной цвета 10 бит требуется полоса порядка 3 Гбит/с.

---

#### Архитектура съемочных комплексов с использованием SMPTE ST 2110

Типичная архитектура съемочного комплекса, работающего по стандарту SMPTE ST 2110, включает следующие элементы:

1. Источники сигнала – видеокамеры, микрофоны и другие устройства ввода, передающие данные в формате SMPTE ST 2110.
2. Коммутационное оборудование – сетевые коммутаторы, способные обрабатывать RTP-пакеты и обеспечивать синхронизацию по PTP. Эти устройства маршрутизируют потоки данных между источниками и приёмниками.
3. Приёмники и декодеры – устройства, принимающие и обрабатывающие видеопотоки и аудиосигналы. К ним относятся мониторы, серверы записи, микшеры и другие компоненты производственной цепочки.
4. Синхрогенераторы – устройства, отвечающие за генерацию точных временных меток PTP, необходимых для синхронизации всей системы.

#### Требования к инфраструктуре

Для эффективной работы SMPTE ST 2110 требуется высокопроизводительное сетевое окружение, удовлетворяющее следующим требованиям:

1. Пропускная способность сети. Минимальная скорость передачи данных должна составлять 3 Гбит/с для видео 1080p60, и значительно выше для Ultra HD (до 12 Гбит/с).
2. Задержка и джиттер. Задержка должна быть минимальной (< 100 мс), а джиттер — менее 50 мкс для предотвращения рассинхронизации между видео и аудио.
3. Поддержка PTP. Все устройства должны поддерживать IEEE 1588 для обеспечения точной временной синхронизации.
4. Мониторинг и управление. Инфраструктура должна предоставлять средства для мониторинга состояния сети и управления потоками данных.

#### Основные области применения и ограничения

SMPTE ST 2110 применяется в следующих сферах:

- Профессиональное ТВ и радио. Используется для построения студийных комплексов, требующих высокого качества и надежности передачи медиасигналов.
- Трансляции спортивных событий. Обеспечивает сложную многокамерную съёмку с минимальной задержкой и высоким разрешением.

Однако стандарт имеет ряд ограничений:

- Высокие требования к полосе пропускания. Передача несжатых данных требует значительных ресурсов сети.
- Необходимость поддержки PTP. Не все сети способны обеспечить требуемый уровень точности синхронизации.
- Отсутствие встроенных средств защиты данных. SMPTE ST 2110 не предоставляет механизмов шифрования и аутентификации, что требует дополнительных мер безопасности.

---

#### Сравнение с другими протоколами

Рассмотрим, как SMPTE ST 2110 сравнивается с другими популярными протоколами передачи медиаконтента:

##### NDI (Network Device Interface)

- Преимущества NDI: Низкая задержка, простота настройки, поддержка сжатия данных.
- Недостатки NDI: Ограниченная совместимость с оборудованием сторонних производителей, меньшая гибкость по сравнению с SMPTE ST 2110.

##### SRT (Secure Reliable Transport)

- Преимущества SRT: Высокая надёжность передачи данных, встроенное шифрование и защита от потерь пакетов.
- Недостатки SRT: Сложнее в настройке по сравнению с SMPTE ST 2110, ограниченная поддержка оборудования.

##### RTSP (Real Time Streaming Protocol)

- Преимущества RTSP: Широкая распространённость, поддержка множества устройств и платформ.
- Недостатки RTSP: Отсутствие синхронизации времени. Не предназначен для больших потоков.

---

#### Программная поддержка SMPTE ST 2110

Существуют разнообразные программные решения для работы с потоками SMPTE ST 2110:

1. Программы для захвата и обработки видео:
   - vMix: Поддерживает захват и обработку потоков SMPTE ST 2110.
   - OBS Studio: Может использоваться для захвата и стриминга видео в формате SMPTE ST 2110.
2. Программные микшеры:
   - NewTek TriCaster: Поддерживает работу с потоками SMPTE ST 2110.
   - Ross Video Carbonite Black Solo: Включает поддержку SMPTE ST 2110 для обработки видео и звука.
3. Оборудование для коммутации и маршрутизации:
   - Evertz EQX Series: Линейка коммутаторов, поддерживающих SMPTE ST 2110.
   - Grass Valley Sirius 800: Профессиональный маршрутизатор с поддержкой SMPTE ST 2110.

### Протокол описания сеансов (SDP)

Протокол описания сеансов (Session Description Protocol, SDP) — это формат описания мультимедийных сессий, который используется для передачи информации о потоках данных между участниками сетевых коммуникаций. Этот протокол широко применяется в системах VoIP (Voice over IP), видеоконференцсвязи и стриминговых сервисах.

#### Основные компоненты SDP

SDP-сообщение состоит из нескольких полей:

- v=: Версия протокола (всегда 0).
- o=: Идентификатор сессии (origin), включающий версию, идентификатор пользователя, идентификатор сессии и IP-адрес.
- s=: Название сессии.
- i=: Информационное описание сессии.
- u=: URI для получения дополнительной информации.
- e=: Электронная почта организатора.
- p=: Телефонный номер организатора.
- c=: Информация о соединении (адрес, тип сети).
- b=: Указание полосы пропускания.
- t=: Время начала и окончания сессии.
- m=: Медиа-параметры (тип медиа, порт, транспортный протокол, форматы кодеков).
- a=: Атрибуты, определяющие дополнительные параметры.

Пример простого SDP-сообщения:

```
v=0
o=- 1234567890 987654321 IN IP4 192.168.1.100
s=My Session
c=IN IP4 192.168.1.101
t=36000000 37000000
m=audio 5004 RTP/AVP 0
a=rtpmap:0 PCMU/8000
```

#### Применение SDP

##### Видеостриминг и передача медиапотоков

SDP играет ключевую роль в установлении соединения между клиентом и сервером для передачи медиаконтента. Например, в случае RTSP (Real Time Streaming Protocol), клиент отправляет запрос на получение потока видео, а сервер отвечает SDP-сообщением, которое содержит информацию о параметрах потока, таких как кодеки, порты и типы транспорта.

##### SIP-сигнализация

В системах VoIP и видеоконференций SDP часто используется совместно с протоколом SIP (Session Initiation Protocol). SIP обеспечивает сигнализацию для установления, изменения и завершения сеанса связи, тогда как SDP предоставляет детальную информацию о самом потоке данных.

##### Обработка медиафайлов

При работе с медиасерверами, такими как gstreamer или ffmpeg, SDP может использоваться для настройки параметров декодирования и обработки потоков. Например, если вы хотите настроить трансляцию видеопотока через UDP, вам нужно будет указать соответствующие параметры в SDP-сообщении.

#### Примеры использования SDP

##### Использование SDP в Python

Для работы с SDP в Python можно использовать библиотеку python-sdp, которая позволяет парсить и генерировать SDP-сообщения.

```python
from sdp import *

# Парсим SDP-сообщение
sdp = parse_sdp('''\
v=0
o=- 1234567890 987654321 IN IP4 192.168.1.100
s=My Session
c=IN IP4 192.168.1.101
t=36000000 37000000
m=audio 5004 RTP/AVP 0
a=rtpmap:0 PCMU/8000
''')

print(sdp.origin.version)  # Версия протокола
print(sdp.media[0].type)   # Тип медиа (например, audio или video)
print(sdp.media[0].port)   # Порт для приема медиапотока
```

##### Работа с SDP в gstreamer

GStreamer поддерживает работу с SDP для создания и обработки медиапотоков. Например, чтобы создать источник RTP-потока на основе SDP, можно использовать элемент udpsrc.

```bash
gst-launch-1.0 udpsrc port=5004 caps="application/x-rtp,media=(string)audio,clock-rate=(int)8000,encoding-name=(string)PCMU,payload=(int)0" ! rtpjitterbuffer latency=50 ! rtppcmudepay ! alsasink
```

Этот пример показывает, как можно принимать аудиопоток через UDP на порт 5004, используя кодек PCMU со скоростью 8 кГц.

#### Ограничения и особенности SDP

- Формат сообщений: SDP использует простой текстовый формат, что делает его удобным для чтения и анализа человеком, но также увеличивает вероятность ошибок при ручной генерации.
- Безопасность: SDP сам по себе не обеспечивает безопасность передачи данных. Для защиты медиапотоков обычно используются другие механизмы, такие как SRTP (Secure Real-time Transport Protocol).
- Масштабируемость: SDP предназначен для описания небольших наборов медиапотоков. При большом количестве участников или сложных сценариях могут возникнуть проблемы с производительностью и управлением ресурсами.

### Протокол SIP (Session Initiation Protocol)

SIP (Session Initiation Protocol) – это сигнальный протокол, который используется для установления, изменения и завершения сеансов мультимедийных коммуникаций между двумя или несколькими участниками. Он применяется в системах IP-телефонии, видеоконференций и других формах передачи медиаданных через интернет.

#### Основные функции протокола SIP:

1. Инициализация и завершение сеанса: SIP управляет процессом установки соединения между устройствами, включая телефонные звонки, видеозвонки и другие формы обмена медиаинформацией.
2. Обмен информацией о сессиях: SIP позволяет обмениваться данными о параметрах сессии, таких как кодеки, форматы данных, адреса участников и другие параметры, необходимые для успешной коммуникации.
3. Управление вызовами: Протокол поддерживает такие операции, как удержание вызова, перевод звонка, добавление новых участников в сессию и изменение параметров уже установленного соединения.
4. Поддержка дополнительных сервисов: Например, управление конференциями, передача мгновенных сообщений, интеграция с другими системами связи.

#### Структура SIP-запросов

Протокол SIP основан на HTTP-подобной структуре запросов и ответов. Основные типы запросов включают:

- INVITE: Запрос на установление нового сеанса связи.
- ACK: Подтверждение получения INVITE.
- BYE: Завершение текущего сеанса.
- CANCEL: Отмена ранее отправленного запроса.
- REGISTER: Регистрация устройства на сервере.
- OPTIONS: Запрос информации об устройствах и их возможностях.

Ответы на запросы имеют коды состояния, аналогичные HTTP-кодам, начиная от 100 до 600, например:

- 200 OK: Успешная обработка запроса.
- 401 Unauthorized: Необходима авторизация.
- 404 Not Found: Адресат не найден.

#### Применение SIP в видеопроизводстве и видеосвязи

##### Примеры использования SIP в реальных сценариях:

1. Видеоконференции: В системах видеоконференцсвязи SIP может использоваться для управления подключением участников, настройки качества видео и звука, а также для координации работы различных устройств, участвующих в конференции.

   Пример на Python:

   ```python
   from sipsimple.core import Engine, SIPURI, Registration, Route
   from sipsimple.configuration.settings import SIPSimpleSettings
   from sipsimple.account import AccountManager
   
   # Настройка учетной записи
   settings = SIPSimpleSettings()
   account_manager = AccountManager()
   account = account_manager.new_account('sip', 'example.com')
   account.identities = ['sip:alice@example.com']
   account.sip.outbound_proxy = Route('sip:proxy.example.com')
   account.save()
   
   # Инициализация движка SIP
   engine = Engine()
   registration = Registration(account)
   registration.register()
   
   # Отправка приглашения другому участнику
   uri = SIPURI.parse('sip:bob@example.com')
   invite = engine.create_invite_request(uri, account)
   invite.send()
   ```
2. Телефония: В IP-телефонии SIP используется для маршрутизации звонков, управления вызовами и интеграции с традиционными телефонными сетями (PSTN).

   Пример конфигурации Asterisk:

   ```bash
   [general]
   context=default            ; Default context for incoming calls
   allowoverlap=no            ; Disable overlapping invites
   udpbindaddr=0.0.0.0        ; Listen on all interfaces
   tcpenable=yes              ; Enable TCP support
   tcpbindaddr=0.0.0.0        ; Listen on all interfaces for TCP
   
   [myphone]
   type=friend                ; Allow both inbound and outbound calls
   host=dynamic               ; The phone will register with us
   secret=mypassword          ; Password to authenticate with
   context=internal           ; Context for incoming calls from this device
   disallow=all               ; Disallow all codecs
   allow=ulaw                 ; Allow ulaw codec
   allow=alaw                 ; Allow alaw codec
   dtmfmode=rfc2833           ; Use RFC 2833 for DTMF
   directmedia=no             ; Force media through the server
   nat=force_rport,comedia    ; Handle NAT issues
   qualify=yes                ; Check if the phone is reachable
   canreinvite=no             ; Do not allow re-invites directly between devices
   ```
3. Стриминговые сервисы: После установления при помощи SIP соединения (пример рассмотрен выше) возможно проведение прямых трансляций и стриминга медиаконтента. Например, для передачи видео и аудио потоков между серверами или клиентскими приложениями.

#### Технические характеристики SIP

1. Транспортный уровень: SIP использует UDP или TCP для передачи сообщений. Обычно UDP предпочтительнее благодаря меньшим задержкам, но TCP обеспечивает большую надежность доставки.
2. Кодеки: Поддерживаются различные аудиокодеки (G.711, G.722, Opus) и видеокодеки (H.264, VP8), которые могут быть согласованы в процессе установки сессии.
3. Качество обслуживания (QoS): Для обеспечения высокого качества связи используются механизмы QoS, такие как дифференцированное обслуживание (DiffServ) и резервирование ресурсов (RSVP).
4. Безопасность: SIP поддерживает шифрование трафика с использованием TLS/SRTP для защиты от перехвата и подмены данных.

#### Границы применимости SIP

1. Задержки и потеря пакетов: При использовании в сетях с высокой задержкой или потерей пакетов качество связи может ухудшаться. В таких случаях могут потребоваться дополнительные меры, такие как буферизация и использование механизмов восстановления потерянных пакетов.
2. Масштабируемость: В больших сетях с множеством пользователей и устройств нагрузка на серверы SIP может стать значительной. Необходимо учитывать возможности масштабирования инфраструктуры.
3. Совместимость с устаревшими системами: Интеграция с традиционными телефонными сетями (PSTN) требует использования шлюзов и специальных адаптеров.

#### Альтернативы SIP

1. WebRTC: Этот стандарт предназначен для реализации P2P-коммуникаций в браузерах без необходимости установки дополнительного ПО. WebRTC включает в себя множество технологий, таких как SRTP, DTLS и ICE, обеспечивающих безопасность и совместную работу с различными сетевыми конфигурациями.
2. RTSP\*\* (Real Time Streaming Protocol)\*\*: Используется для управления потоковым мультимедиа, особенно в системах видеонаблюдения и вещания. RTSP предоставляет больше возможностей для контроля над воспроизведением и передачей медиапотоков.
3. RTP\*\* (Real-time Transport Protocol)\*\*: Основной транспортный протокол для передачи медиаданных в реальном времени. RTP часто используется совместно с SIP для передачи аудио и видео потоков.

RTMP – это протокол передачи потокового видео, например с камеры на стриминговый сервис. Расшифровывается как Real Time Messaging Protocol. Разработан компанией Adobe изначально для Flash Media Server. Обобщенно всё стриминговое производство описывается так:

![Рисунок 1.](.attachments.55642/image.png)

* Capture – создать потоки на источниках (камерах, кодерах)
* Contribution – собрать потоки с источников, доставить их в микшер
* Processing – обработка, линейный монтаж, титрование, кодирование для стриминга, управление источниками
* Distribution – отправить выходной поток (программу) на платформу, с нее раздать зрителям.
* Consuming – получение зрителями потоков со стриминговой платформы.

RTMP изначально предназначался для потоковой передачи мультимедиа с помощью Adobe Flash Player, но  Flash перестал поддерживаться браузерами в 2020 году.

И, хотя потоковые протоколы вроде HLS и MPEG-DASH, теперь используются для отправки выходного потока с платформы зрителям (distribution), RTMP по-прежнему играет важную роль в отправке потока на стриминговую платформу (Contribution).

RTMP - это протокол L7 (прикладного уровня), который работает поверх TCP и по умолчанию использует порт 1935. Существует также несколько разновидностей протокола, таких как:

* RTMPE (которая зашифрована с использованием механизмов безопасности Adobe),
* RTMPT (инкапсулированный в HTTP для обхода брандмауэров),
* RTMPS - это тот же RTMP, но через соединение TLS/ SSL.

RTMP инкапсулирует и может передавать несколько мультиплексированных медиапотоков FLV. Но обычно он используется для потоковой передачи одного видеопотока H.264 (AVC) и одного аудиопотока AAC. Кодеки, поддерживаемые RTMP, ограничены форматом медиаконтейнера FLV. В контейнер FLV бывают упакованы видеопотоки: FLV1 (Sorenson Spark), VP6, H.264, а аудиопотоки: MPEG Layer-3 или HE-AAC.

RTMP не поддерживает современные кодеки. Если вы захотите транслировать H.265 (HEVC) или VP8/9, то такая возможность не предусмотрена.

# Как работает потоковая передача RTMP?

Основная идея RTMP заключается в установлении и поддержании постоянного соединения между источником и устройством воспроизведения. Сначала клиент инициирует TCP-соединение с сервером. Как правило, прежде чем начать потоковую передачу, вы должны сначала получить URL RTMP. Он имеет следующую структуру: rtmp://host:port/app/stream-key. В случае RTMPS URL-адрес будет начинаться с rtmps://. Клиентское приложение будет обрабатывать URL и подключаться к соответствующему хосту и порту, предоставляя серверу RTMP "имя приложения" и "ключ потока". "Ключ потока" используется для уникального выделения вашей сессии прямой трансляции среди других.

После процедуры рукопожатия клиент и сервер обмениваются данными, отправляя друг другу RTMP-сообщения. Эти сообщения мультиплексируются в небольшие блоки (Chunks), а далее эти блоки обратно как бы разъединяются (т.е. происходит демультиплексирование) на отдельные потоки (Chunk Stream).

Chunk Stream - это абстракция, которая используется для представления мультиплексирования и пакетирования сообщений RTMP. Это позволяет обеспечить разделение и чередование больших сообщений. Например, если нам нужно передать видеопакет размером 1 Мб через наше TCP-соединение, мы не сможем ничего отправить до тех пор, пока 1 Мб данных нашего видеопакета не будет отправлен полностью. Но если мы разделим наше сообщение размером 1 Мб на фрагменты, например, по 50 Кб, мы могли бы легко отправить что-то еще между этими фрагментами размером 50 Кб. Таким образом, меньшее сообщение имеет более высокий приоритет.

Размер блока по умолчанию в потоке блоков RTMP составляет 128 байт, и его можно изменить.

![Рисунок 2.](.attachments.55642/image%20%282%29.png)

Каждый Chunk Stream имеет свой собственный числовой идентификатор. Обычно нам нужен один поток для видео и один для аудио. У каждого потока есть заголовок, куда включен данный идентификатор. Кроме того, заголовок блока содержит Chunk Type ID, который влияет на то, как должен обрабатываться оставшийся заголовок (если он существует).

Например, несколько последующих блоков с одинаковым Chunk Type ID являются частями одного и того же сообщения, и они совместно используют некоторые свойства этого сообщения, например timestamp. В этом случае мы можем сэкономить несколько байт для каждого блока, опуская все остальные данные заголовка.

Итак, нам нужно отправить несколько RTMP-сообщений. Мы разбиваем их на блоки (Chunk) и передаем с разными Chunk Type ID. Но что именно представляют собой эти сообщения? Каждое сообщение имеет идентификатор, указывающий на значение сообщения. Это может быть одно из управляющих сообщений протокола, например SET_CHUNK_SIZE (которое используется для указания изменения размера блока отправителя).

Это также может быть VIDEO (видеосообщение), AUDIO (аудиосообщение), DATA_AMF0/DATA_AMF3 или COMMAND_AMF0/COMMAND_AMF3. AMF (Action Message Format, формат сообщений о действиях) — бинарный формат обмена данными. Построен на основе протокола SOAP (Simple Object Access Protocol) и используется, преимущественно, для обмена информацией между Adobe Flash и базами данных. Большинство реализаций используют версию AMF0. Содержимое видео и аудиосообщений интерпретируется как теги VIDEODATA и AUDIODATA FLV соответственно.

Еще одним важным свойством RTMP-сообщения является временная метка (timestamp). Это время, когда данные должны быть декодированы и представлены пользователю. Временные метки ауидо- и видеосообщений синхронизированы друг с другом и имеют ту же начальную эпоху, которая согласована во время рукопожатия.

Так выглядит схема доставки контента от источника до конечного пользователя:

![Рисунок 3.](.attachments.55642/image%20%283%29.png)

1. Захват камерой. Камера выполняет работу по захвату света и звука и преобразованию этих аналоговых входных сигналов в необработанный (несжатый) цифровой формат, которые затем должны быть сжаты (закодированы) перед потоковой передачей.
2. Кодирование. Кодек сжимает необработанные аудио- и видеоданные в поток меньшего битрейта.
3. Загрузка. Далее RTMP устанавливает постоянное соединение между устройством захвата (клиентом) и стриминговой площадкой (сервером).  
   Медиасервер выполняет невидимую зрителю работу по перекодированию, чтобы сделать возможным плавное кроссплатформенное взаимодействие. В процессе транскодирования, сервер перепаковывает исходное медиа в версии с различным разрешением, качеством и битрейтом, и даже выводит несколько протоколов доставки, таких как HLS, для удовлетворения потребностей различных устройств воспроизведения. Например, когда вы переключаетесь с 480p на 720p во время просмотра видео на YouTube, вы фактически просите сервер YouTube воспроизвести другой файл (того же видео), который был закодирован в другом разрешении. Но это не один файл, а последовательность кусков (chunks), и поэтому воспроизведение может начинаться со следующего куска в другом разрешении, если изменились условия в канале передачи.
4. Сеть доставки контента (CDN). CDN (Content Delivery Network) — это географически распределённая сетевая инфраструктура, обеспечивающая быструю доставку контента пользователям веб-сервисов и сайтов. Входящие в состав CDN cерверы географически располагаются таким образом, чтобы сделать время ответа для пользователей сайта/сервиса минимальным.
5. Воспроизведение на компьютере зрителя.

RTMP имеет два основных метода транспортировки - Push, при котором кодер доставляет RTMP на RTMP-сервер или CDN, и Pull, при котором клиент извлекает поток и воспроизводит его обратно.

Рассмотрим Push стриминг с RTMP-камеры:

1. Включаем RTMP-камеру или кодер.
2. Заходим в youtube в настройки прямого эфира:

   ![Рисунок 4.](.attachments.55642/image%20%284%29.png)

Здесь мы видим Stream URL и ключ стрима (Stream key).

1. Теперь в веб-настройках камеры находим RTMP settings и в качестве ссылки вставляем stream URL, а затем через “/” ключ, который является идентификатором стрима. После перезагрузки (reboot) камеры стрим должен начаться.

   ![Рисунок 5.](.attachments.55642/image%20%285%29.png)

Собственный сервер RTMP на базе Nginx:

Допустим, нам нужно организовать трансляцию на Youtube и проанализировать поток, идущий на стриминговый сервис. В таком случае можно создать свой rtmp-сервер, на который будет отправляться поток, который оттуда уже пойдёт к зрителям.

В бытовых условиях источником потока могут быть OBS, ffmpeg или смартфон с соответствующим приложением (например, Larix Broadcaster, работает на андроиде и айфоне). Просматривать его и отправлять на Youtube будем через OBS.  Но OBS не является сервером RTMP, чтобы на него стримить, придется поставить промежуточный сервер.

Для создания своего сервера, можно использовать веб-сервер Nginx, включающий в себя модуль, который позволяет вам предоставлять поток RTMP с простой конфигурацией с выделенного URL-адреса, точно так же, как он обеспечивает HTTP-доступ к веб-страницам по умолчанию.

Для начала нужно обновить систему и установить веб-сервер nginx, а также его rtmp дополнение:

```
sudo apt-get update
sudo apt-get upgrade\n\nsudo apt install nginx-full
sudo apt install libnginx-mod-rtmp     
```

В файле конфигурации прописываем сам сервер:

```
sudo nano /etc/nginx/nginx.conf  
```

```
rtmp { 	
server {
        listen 1935;
        chunk_size 4096;
    application live {
        live on;
        record off;
             }
         }
     }
```

* listen 1935 означает, что RTMP-сервер будет ожидать подключения по порту 1935, являющимся стандартным;
* chunk_size 4096 определяет, что RTMP будет отправлять данные блоками по 4 КБ. Это значение не может быть меньше 128Б;
* application live определяет application block that will be available at the /live URL path;
* record off отключает функцию записи, так что по умолчанию потоки не сохраняются на диск отдельно.

  ![Рисунок 6.](.attachments.55642/image%20%286%29.png)

Для сбора статистики настроим http-сервер. Теперь статистика будет доступна по адресу http://localhost:8080/stat:

![Рисунок 7.](.attachments.55642/image%20%287%29.png)

Следующим шагом отправляем на rtmp-сервер поток с мобильного телефона. base1 – идентификатор конкретного поток, задаём это значение произвольно. Главное, чтобы у каждого источника был уникальный ключ:

![Рисунок 8.](.attachments.55642/image%20%288%29.png)

Чтобы проверить картинку заходим в OBS и добавляем в источники Media Source, и прописываем URL с учётом ключа стрима:

![Рисунок 9.](.attachments.55642/image%20%289%29.png)

Также есть возможность добавления потока со второго телефона (но ключ стрима нужно указать другой):

![Рисунок 10.](.attachments.55642/image%20%2810%29.png)

Уже сейчас можно просматривать статистику, в которой отображается количество потоков, ауидо- и видеокодеки, битрейт:

